## Project Context

- Root Path: C:\Users\vosahlo_martin\Downloads\new gui tracklist_extractor2
- Timestamp: 20251025-013716
- Total Files: 61
- Total Size: 229392 bytes

## Summary Table

| Relative Path | Bytes | Lines |
|---------------|-------|-------|
| AGENTS.md | 660 | 18 |
| assets\README.md | 4791 | 134 |
| CLAUDE.md | 660 | 18 |
| docs\pm\fluent_gui-removal.md | 572 | 12 |
| fonts\dejavu-fonts-ttf-2.37\README.md | 2556 | 68 |
| CHANGELOG.md | 1450 | 41 |
| openspec\AGENTS.md | 14982 | 457 |
| openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\proposal.md | 714 | 16 |
| openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\specs\ui\spec.md | 1127 | 26 |
| openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\tasks.md | 517 | 10 |
| openspec\changes\archive\2025-10-18-add-analysis-auto-export\proposal.md | 772 | 14 |
| openspec\changes\archive\2025-10-18-add-analysis-auto-export\specs\export\spec.md | 1030 | 29 |
| openspec\changes\archive\2025-10-18-add-analysis-auto-export\tasks.md | 744 | 17 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\design.md | 3218 | 83 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\proposal.md | 1593 | 28 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\analysis\spec.md | 1696 | 44 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\extraction\spec.md | 1468 | 40 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\ui\spec.md | 750 | 18 |
| openspec\changes\archive\2025-10-18-refactor-architecture-layering\tasks.md | 2637 | 48 |
| openspec\changes\archive\2025-10-19-refactor-presentation-layer\design.md | 10499 | 229 |
| openspec\changes\archive\2025-10-19-refactor-presentation-layer\proposal.md | 3061 | 44 |
| openspec\changes\archive\2025-10-19-refactor-presentation-layer\specs\ui\spec.md | 9205 | 183 |
| openspec\changes\archive\2025-10-19-refactor-presentation-layer\tasks.md | 10949 | 180 |
| openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\proposal.md | 1521 | 18 |
| openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\analysis\spec.md | 1421 | 37 |
| openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\export\spec.md | 874 | 21 |
| openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\extraction\spec.md | 826 | 20 |
| openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\tasks.md | 2634 | 40 |
| openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\proposal.md | 2791 | 27 |
| openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\analysis\spec.md | 2919 | 64 |
| openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\export\spec.md | 1894 | 48 |
| openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\extraction\spec.md | 1115 | 25 |
| openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\tasks.md | 5391 | 63 |
| openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\proposal.md | 2586 | 24 |
| openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\specs\extraction\spec.md | 3192 | 72 |
| openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\tasks.md | 6682 | 85 |
| openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\proposal.md | 2090 | 34 |
| openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\specs\ui\spec.md | 1472 | 28 |
| openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\tasks.md | 1449 | 30 |
| openspec\changes\archive\2025-10-22-fix-waveform-path-matching\proposal.md | 959 | 11 |
| openspec\changes\archive\2025-10-22-fix-waveform-path-matching\specs\ui\spec.md | 463 | 9 |
| openspec\changes\archive\2025-10-22-fix-waveform-path-matching\tasks.md | 429 | 7 |
| openspec\changes\archive\2025-10-22-refactor-phase4-export-service\proposal.md | 2371 | 26 |
| openspec\changes\archive\2025-10-22-refactor-phase4-export-service\specs\export\spec.md | 1696 | 41 |
| openspec\changes\archive\2025-10-22-refactor-phase4-export-service\tasks.md | 4944 | 57 |
| openspec\changes\archive\2025-10-22-refactor-phase4-export-service\VERIFICATION_COMPLETE.md | 17825 | 387 |
| openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\proposal.md | 3444 | 34 |
| openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\specs\analysis\spec.md | 5752 | 112 |
| openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\tasks.md | 12058 | 119 |
| openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\design.md | 3609 | 64 |
| openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\proposal.md | 4530 | 64 |
| openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\specs\analysis\spec.md | 3770 | 72 |
| openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\specs\extraction\spec.md | 2320 | 47 |
| openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\tasks.md | 3673 | 49 |
| openspec\project.md | 4642 | 71 |
| openspec\specs\analysis\spec.md | 8828 | 182 |
| openspec\specs\export\spec.md | 4864 | 112 |
| openspec\specs\extraction\spec.md | 7129 | 156 |
| openspec\specs\ui\spec.md | 12233 | 245 |
| README.md | 6154 | 116 |
| tests\README.md | 3191 | 88 |

## File Contents

### AGENTS.md

``n<!-- OPENSPEC:START -->
# OpenSpec Instructions

These instructions are for AI assistants working in this project.

Always open `@/openspec/AGENTS.md` when the request:
- Mentions planning or proposals (words like proposal, spec, change, plan)
- Introduces new capabilities, breaking changes, architecture shifts, or big performance/security work
- Sounds ambiguous and you need the authoritative spec before coding

Use `@/openspec/AGENTS.md` to learn:
- How to create and apply change proposals
- Spec format and conventions
- Project structure and guidelines

Keep this managed block so 'openspec update' can refresh the instructions.

<!-- OPENSPEC:END -->
``n
### assets\README.md

``n# GZ Media Assets

Tento adresář obsahuje grafické assety pro GZ Media branding aplikace Final Cue Sheet Checker.

## Požadované logo soubory

### `gz_logo_white.png`
- **Formát:** PNG s průhledným pozadím
- **Barva:** Bílá varianta GZ Media loga
- **Rozměry:** Doporučeno 128x32 pixelů (4:1 poměr)
- **Umístění:** Levý horní roh hlavního okna
- **Pozadí:** Průhledné pro správné zobrazení na různých barvách

### `gz_logo_dark.png` (volitelné)
- **Formát:** PNG s průhledným pozadím
- **Barva:** Tmavá varianta pro světlé pozadí
- **Rozměry:** Stejné jako bílá varianta
- **Použití:** Automatické přepínání podle theme modu

## UI Icons

### `icons/check.svg`
- **Formát:** SVG
- **Rozměry:** 16x16 pixelů
- **Barva:** Zelená (#10B981)
- **Použití:** Indikace úspěšného match v tabulce (sloupec Match)
- **Design:** Checkmark symbol s kulatými konci

### `icons/cross.svg`
- **Formát:** SVG
- **Rozměry:** 16x16 pixelů
- **Barva:** Červená (#EF4444)
- **Použití:** Indikace neúspěšného match v tabulce (sloupec Match)
- **Design:** Cross symbol s kulatými konci

### `icons/play.svg`
- **Formát:** SVG
- **Rozměry:** 16x16 pixelů
- **Barva:** Modrá (#3B82F6)
- **Použití:** Tlačítko pro zobrazení waveform (sloupec Waveform)
- **Design:** Play triangle symbol

## Fallback chování pro Ikony

Pokud se vlastní SVG ikony (`check.svg`, `cross.svg`, `play.svg`) nepodaří načíst z Qt resources ani ze souborového systému, aplikace se pokusí použít ikony poskytované systémovým tématem. Toto zajišťuje, že aplikace zůstane funkční i v případě chybějících assetů.

Konkrétní mapování fallbacků je následující:
- **`check`**: `QStyle.StandardPixmap.SP_DialogApplyButton` (obvykle ikona zaškrtnutí)
- **`cross`**: `QStyle.StandardPixmap.SP_DialogCancelButton` (obvykle ikona křížku)
- **`play`**: `QStyle.StandardPixmap.SP_MediaPlay` (standardní ikona pro přehrávání)

Aplikace zaznamená varování do logu, pokud dojde k použití fallbacku.

## Technické požadavky

- **Formát:** PNG s průhledností (RGBA)
- **Velikost:** Optimalizované pro rychlé načítání (< 50KB)
- **Rozměry:** Šířka max 200px, výška max 40px
- **Kvalita:** Ostré hrany, žádné kompresní artefakty

## Fallback chování pro Logo

Pokud logo soubory nejsou nalezeny, aplikace zobrazí textový fallback:
- **Text:** "GZ Media"
- **Font:** Poppins Bold
- **Barva:** GZ Primary Blue (#1E3A8A)

## Claim

Claim "Emotions. Materialized." se zobrazuje v pravém dolním rohu okna:
- **Font:** Poppins Italic
- **Velikost:** 8pt
- **Barva:** GZ Gray (#6B7280)
- **Konfigurace:** Lze zapnout/vypnout v settings

## Packaging

Custom SVG icons are bundled using Qt's resource search path system for cross-platform compatibility.

### Qt Resource Approach (Recommended)

Icons are made available via Qt's resource system:

1. **Resource File**: `assets/icons.qrc` declares the SVG files under the `/icons` prefix
2. **Resource Module**: `ui/_icons_rc.py` registers the assets directory as a Qt resource search path
   - **Development**: Loads icons directly from filesystem via `QResource.addSearchPath()`
   - **PyInstaller**: Automatically handles bundled assets via `sys._MEIPASS`
3. **Import**: The module is imported at startup in `app.py` (line 30)
4. **Loading**: `get_custom_icon()` in `ui/theme.py` attempts to load from `:/icons/<name>.svg` (Qt resources) with filesystem fallback

### Build/Compilation

**Option A: Using pyrcc6 (Standard Qt Tool)**
```bash
pyrcc6 assets/icons.qrc -o ui/_icons_rc.py
```

**Option B: Using the Build Script (Fallback)**
```bash
python tools/build_resources.py
```

This generates `ui/_icons_rc.py` which registers resource search paths for both development and packaged builds.

### PyInstaller Bundling

For PyInstaller, ensure assets are included:

**Option 1: Data files (via `.spec` or CLI)**
```bash
pyinstaller --add-data "assets/icons;assets/icons" app.py
```

**Option 2: Include in analysis**
Add to `.spec` file:
```python
datas=[('assets/icons', 'assets/icons')]
```

The resource search path system handles both approaches automatically through `sys._MEIPASS` detection.

## Přidání nových assetů

1. Uložte logo soubory do tohoto adresáře
2. Aktualizujte `config.py` - `gz_logo_path` konfiguraci
3. Restartujte aplikaci pro načtení nových assetů

## Brand Guidelines

Všechny assety musí být v souladu s GZ Media brand guidelines:
- ✅ Pouze oficiální GZ Media logo
- ✅ Správné proporce a barevnost
- ✅ Profesionální kvalita
- ❌ Žádné modifikace nebo úpravy loga
``n
### CLAUDE.md

``n<!-- OPENSPEC:START -->
# OpenSpec Instructions

These instructions are for AI assistants working in this project.

Always open `@/openspec/AGENTS.md` when the request:
- Mentions planning or proposals (words like proposal, spec, change, plan)
- Introduces new capabilities, breaking changes, architecture shifts, or big performance/security work
- Sounds ambiguous and you need the authoritative spec before coding

Use `@/openspec/AGENTS.md` to learn:
- How to create and apply change proposals
- Spec format and conventions
- Project structure and guidelines

Keep this managed block so 'openspec update' can refresh the instructions.

<!-- OPENSPEC:END -->
``n
### docs\pm\fluent_gui-removal.md

``n# PM Ticket: Plan for fluent_gui.py Removal

- Context: fluent_gui.py is a backward-compatibility wrapper. New development uses app.py and ui/ package.
- Decision: Keep deprecation in place, plan removal in a future minor/major release.
- Steps:
  1) Monitor external/internal imports of fluent_gui.py for one release cycle.
  2) Announce removal in CHANGELOG one version ahead.
  3) Provide migration note: use app.py entry point and ui/ components.
- Owner: maintainers
- Status: planned
- Related change: openspec/changes/archive/2025-10-24-refactor-unified-audit-plan

``n
### fonts\dejavu-fonts-ttf-2.37\README.md

``n[![Build Status](https://travis-ci.org/dejavu-fonts/dejavu-fonts.svg)](https://travis-ci.org/dejavu-fonts/dejavu-fonts)

DejaVu fonts 2.37 (c)2004-2016 DejaVu fonts team
------------------------------------------------

The DejaVu fonts are a font family based on the Bitstream Vera Fonts
(http://gnome.org/fonts/). Its purpose is to provide a wider range of
characters (see status.txt for more information) while maintaining the
original look and feel.

DejaVu fonts are based on Bitstream Vera fonts version 1.10.

Available fonts (Sans = sans serif, Mono = monospaced):

DejaVu Sans Mono
DejaVu Sans Mono Bold
DejaVu Sans Mono Bold Oblique
DejaVu Sans Mono Oblique
DejaVu Sans
DejaVu Sans Bold
DejaVu Sans Bold Oblique
DejaVu Sans Oblique
DejaVu Sans ExtraLight (experimental)
DejaVu Serif
DejaVu Serif Bold
DejaVu Serif Bold Italic (experimental)
DejaVu Serif Italic (experimental)
DejaVu Sans Condensed (experimental)
DejaVu Sans Condensed Bold (experimental)
DejaVu Sans Condensed Bold Oblique (experimental)
DejaVu Sans Condensed Oblique (experimental)
DejaVu Serif Condensed (experimental)
DejaVu Serif Condensed Bold (experimental)
DejaVu Serif Condensed Bold Italic (experimental)
DejaVu Serif Condensed Italic (experimental)
DejaVu Math TeX Gyre

All fonts are also available as derivative called DejaVu LGC with support
only for Latin, Greek and Cyrillic scripts.

For license information see LICENSE. What's new is described in NEWS. Known
bugs are in BUGS. All authors are mentioned in AUTHORS.

Fonts are published in source form as SFD files (Spline Font Database from
FontForge - http://fontforge.sf.net/) and in compiled form as TTF files
(TrueType fonts).

For more information go to http://dejavu.sourceforge.net/.

Characters from Arev fonts, Copyright (c) 2006 by Tavmjong Bah:
---------------------------
U+01BA, U+01BF, U+01F7, U+021C-U+021D, U+0220, U+0222-U+0223,
U+02B9, U+02BA, U+02BD, U+02C2-U+02C5, U+02d4-U+02D5,
U+02D7, U+02EC-U+02EE, U+0346-U+034E, U+0360, U+0362,
U+03E2-03EF, U+0460-0463, U+0466-U+0486, U+0488-U+0489, U+04A8-U+04A9,
U+0500-U+050F, U+2055-205E, U+20B0, U+20B2-U+20B3, U+2102, U+210D, U+210F,
U+2111, U+2113, U+2115, U+2118-U+211A, U+211C-U+211D, U+2124, U+2135,
U+213C-U+2140, U+2295-U+2298, U+2308-U+230B, U+26A2-U+26B1, U+2701-U+2704,
U+2706-U+2709, U+270C-U+274B, U+2758-U+275A, U+2761-U+2775, U+2780-U+2794,
U+2798-U+27AF, U+27B1-U+27BE, U+FB05-U+FB06

DejaVu Math TeX Gyre
--------------------
TeX Gyre DJV Math by B. Jackowski, P. Strzelczyk and P. Pianowski
(on behalf of TeX users groups).

$Id$

``n
### CHANGELOG.md

``n# Changelog

## [Refactoring Complete] - 2025-10-22

### Architecture
- **COMPLETED**: 5-phase strategic refactoring to hexagonal architecture
- **Phase 1**: Stabilization - type safety, characterization tests, quality tooling
- **Phase 2**: Dependency Injection - settings dataclasses, no global config
- **Phase 3**: I/O Modularization - adapters for ZIP/WAV reading
- **Phase 4**: Export Service - centralized export
- **Phase 5**: AI Port - AudioModeDetector protocol

### Quality Improvements
- Test coverage: 97% (55 passing tests)
- Type safety: mypy --strict passes
- Code quality: ruff clean, zero dead code
- Domain layer: Zero infrastructure dependencies

### Testing
- Characterization tests with golden JSON outputs
- Fake adapters for deterministic tests
- No external API calls in test suite

### Developer Experience
- Added tools/check.sh for local quality gates
- OpenSpec-driven development
- Clear layer boundaries with explicit dependencies

### Non-Breaking Changes
- All phases maintained behavioral parity
- No user-facing changes
- Internal architecture improvements only

## [0.0.1] - 2025-10-21
### Fixed
- Refactor stabilization phase 1: internal type-safety, test coverage >=85%, dead code removal.
- Check script finalized with unified coverage run and clear success message.
- Documentation: replaced QConfig with QSettings, removed PyQt-Fluent-Widgets.
- Added Purpose sections to specs (analysis/export/extraction).


``n
### openspec\AGENTS.md

``n# OpenSpec Instructions

Instructions for AI coding assistants using OpenSpec for spec-driven development.

## TL;DR Quick Checklist

- Search existing work: `openspec spec list --long`, `openspec list` (use `rg` only for full-text search)
- Decide scope: new capability vs modify existing capability
- Pick a unique `change-id`: kebab-case, verb-led (`add-`, `update-`, `remove-`, `refactor-`)
- Scaffold: `proposal.md`, `tasks.md`, `design.md` (only if needed), and delta specs per affected capability
- Write deltas: use `## ADDED|MODIFIED|REMOVED|RENAMED Requirements`; include at least one `#### Scenario:` per requirement
- Validate: `openspec validate [change-id] --strict` and fix issues
- Request approval: Do not start implementation until proposal is approved

## Three-Stage Workflow

### Stage 1: Creating Changes
Create proposal when you need to:
- Add features or functionality
- Make breaking changes (API, schema)
- Change architecture or patterns  
- Optimize performance (changes behavior)
- Update security patterns

Triggers (examples):
- "Help me create a change proposal"
- "Help me plan a change"
- "Help me create a proposal"
- "I want to create a spec proposal"
- "I want to create a spec"

Loose matching guidance:
- Contains one of: `proposal`, `change`, `spec`
- With one of: `create`, `plan`, `make`, `start`, `help`

Skip proposal for:
- Bug fixes (restore intended behavior)
- Typos, formatting, comments
- Dependency updates (non-breaking)
- Configuration changes
- Tests for existing behavior

**Workflow**
1. Review `openspec/project.md`, `openspec list`, and `openspec list --specs` to understand current context.
2. Choose a unique verb-led `change-id` and scaffold `proposal.md`, `tasks.md`, optional `design.md`, and spec deltas under `openspec/changes/<id>/`.
3. Draft spec deltas using `## ADDED|MODIFIED|REMOVED Requirements` with at least one `#### Scenario:` per requirement.
4. Run `openspec validate <id> --strict` and resolve any issues before sharing the proposal.

### Stage 2: Implementing Changes
Track these steps as TODOs and complete them one by one.
1. **Read proposal.md** - Understand what's being built
2. **Read design.md** (if exists) - Review technical decisions
3. **Read tasks.md** - Get implementation checklist
4. **Implement tasks sequentially** - Complete in order
5. **Confirm completion** - Ensure every item in `tasks.md` is finished before updating statuses
6. **Update checklist** - After all work is done, set every task to `- [x]` so the list reflects reality
7. **Approval gate** - Do not start implementation until the proposal is reviewed and approved

### Stage 3: Archiving Changes
After deployment, create separate PR to:
- Move `changes/[name]/` → `changes/archive/YYYY-MM-DD-[name]/`
- Update `specs/` if capabilities changed
- Use `openspec archive [change] --skip-specs --yes` for tooling-only changes
- Run `openspec validate --strict` to confirm the archived change passes checks

## Before Any Task

**Context Checklist:**
- [ ] Read relevant specs in `specs/[capability]/spec.md`
- [ ] Check pending changes in `changes/` for conflicts
- [ ] Read `openspec/project.md` for conventions
- [ ] Run `openspec list` to see active changes
- [ ] Run `openspec list --specs` to see existing capabilities

**Before Creating Specs:**
- Always check if capability already exists
- Prefer modifying existing specs over creating duplicates
- Use `openspec show [spec]` to review current state
- If request is ambiguous, ask 1–2 clarifying questions before scaffolding

### Search Guidance
- Enumerate specs: `openspec spec list --long` (or `--json` for scripts)
- Enumerate changes: `openspec list` (or `openspec change list --json` - deprecated but available)
- Show details:
  - Spec: `openspec show <spec-id> --type spec` (use `--json` for filters)
  - Change: `openspec show <change-id> --json --deltas-only`
- Full-text search (use ripgrep): `rg -n "Requirement:|Scenario:" openspec/specs`

## Quick Start

### CLI Commands

```bash
# Essential commands
openspec list                  # List active changes
openspec list --specs          # List specifications
openspec show [item]           # Display change or spec
openspec diff [change]         # Show spec differences
openspec validate [item]       # Validate changes or specs
openspec archive [change] [--yes|-y]      # Archive after deployment (add --yes for non-interactive runs)

# Project management
openspec init [path]           # Initialize OpenSpec
openspec update [path]         # Update instruction files

# Interactive mode
openspec show                  # Prompts for selection
openspec validate              # Bulk validation mode

# Debugging
openspec show [change] --json --deltas-only
openspec validate [change] --strict
```

### Command Flags

- `--json` - Machine-readable output
- `--type change|spec` - Disambiguate items
- `--strict` - Comprehensive validation
- `--no-interactive` - Disable prompts
- `--skip-specs` - Archive without spec updates
- `--yes`/`-y` - Skip confirmation prompts (non-interactive archive)

## Directory Structure

```
openspec/
├── project.md              # Project conventions
├── specs/                  # Current truth - what IS built
│   └── [capability]/       # Single focused capability
│       ├── spec.md         # Requirements and scenarios
│       └── design.md       # Technical patterns
├── changes/                # Proposals - what SHOULD change
│   ├── [change-name]/
│   │   ├── proposal.md     # Why, what, impact
│   │   ├── tasks.md        # Implementation checklist
│   │   ├── design.md       # Technical decisions (optional; see criteria)
│   │   └── specs/          # Delta changes
│   │       └── [capability]/
│   │           └── spec.md # ADDED/MODIFIED/REMOVED
│   └── archive/            # Completed changes
```

## Creating Change Proposals

### Decision Tree

```
New request?
├─ Bug fix restoring spec behavior? → Fix directly
├─ Typo/format/comment? → Fix directly  
├─ New feature/capability? → Create proposal
├─ Breaking change? → Create proposal
├─ Architecture change? → Create proposal
└─ Unclear? → Create proposal (safer)
```

### Proposal Structure

1. **Create directory:** `changes/[change-id]/` (kebab-case, verb-led, unique)

2. **Write proposal.md:**
```markdown
## Why
[1-2 sentences on problem/opportunity]

## What Changes
- [Bullet list of changes]
- [Mark breaking changes with **BREAKING**]

## Impact
- Affected specs: [list capabilities]
- Affected code: [key files/systems]
```

3. **Create spec deltas:** `specs/[capability]/spec.md`
```markdown
## ADDED Requirements
### Requirement: New Feature
The system SHALL provide...

#### Scenario: Success case
- **WHEN** user performs action
- **THEN** expected result

## MODIFIED Requirements
### Requirement: Existing Feature
[Complete modified requirement]

## REMOVED Requirements
### Requirement: Old Feature
**Reason**: [Why removing]
**Migration**: [How to handle]
```
If multiple capabilities are affected, create multiple delta files under `changes/[change-id]/specs/<capability>/spec.md`—one per capability.

4. **Create tasks.md:**
```markdown
## 1. Implementation
- [ ] 1.1 Create database schema
- [ ] 1.2 Implement API endpoint
- [ ] 1.3 Add frontend component
- [ ] 1.4 Write tests
```

5. **Create design.md when needed:**
Create `design.md` if any of the following apply; otherwise omit it:
- Cross-cutting change (multiple services/modules) or a new architectural pattern
- New external dependency or significant data model changes
- Security, performance, or migration complexity
- Ambiguity that benefits from technical decisions before coding

Minimal `design.md` skeleton:
```markdown
## Context
[Background, constraints, stakeholders]

## Goals / Non-Goals
- Goals: [...]
- Non-Goals: [...]

## Decisions
- Decision: [What and why]
- Alternatives considered: [Options + rationale]

## Risks / Trade-offs
- [Risk] → Mitigation

## Migration Plan
[Steps, rollback]

## Open Questions
- [...]
```

## Spec File Format

### Critical: Scenario Formatting

**CORRECT** (use #### headers):
```markdown
#### Scenario: User login success
- **WHEN** valid credentials provided
- **THEN** return JWT token
```

**WRONG** (don't use bullets or bold):
```markdown
- **Scenario: User login**  ❌
**Scenario**: User login     ❌
### Scenario: User login      ❌
```

Every requirement MUST have at least one scenario.

### Requirement Wording
- Use SHALL/MUST for normative requirements (avoid should/may unless intentionally non-normative)

### Delta Operations

- `## ADDED Requirements` - New capabilities
- `## MODIFIED Requirements` - Changed behavior
- `## REMOVED Requirements` - Deprecated features
- `## RENAMED Requirements` - Name changes

Headers matched with `trim(header)` - whitespace ignored.

#### When to use ADDED vs MODIFIED
- ADDED: Introduces a new capability or sub-capability that can stand alone as a requirement. Prefer ADDED when the change is orthogonal (e.g., adding "Slash Command Configuration") rather than altering the semantics of an existing requirement.
- MODIFIED: Changes the behavior, scope, or acceptance criteria of an existing requirement. Always paste the full, updated requirement content (header + all scenarios). The archiver will replace the entire requirement with what you provide here; partial deltas will drop previous details.
- RENAMED: Use when only the name changes. If you also change behavior, use RENAMED (name) plus MODIFIED (content) referencing the new name.

Common pitfall: Using MODIFIED to add a new concern without including the previous text. This causes loss of detail at archive time. If you aren’t explicitly changing the existing requirement, add a new requirement under ADDED instead.

Authoring a MODIFIED requirement correctly:
1) Locate the existing requirement in `openspec/specs/<capability>/spec.md`.
2) Copy the entire requirement block (from `### Requirement: ...` through its scenarios).
3) Paste it under `## MODIFIED Requirements` and edit to reflect the new behavior.
4) Ensure the header text matches exactly (whitespace-insensitive) and keep at least one `#### Scenario:`.

Example for RENAMED:
```markdown
## RENAMED Requirements
- FROM: `### Requirement: Login`
- TO: `### Requirement: User Authentication`
```

## Troubleshooting

### Common Errors

**"Change must have at least one delta"**
- Check `changes/[name]/specs/` exists with .md files
- Verify files have operation prefixes (## ADDED Requirements)

**"Requirement must have at least one scenario"**
- Check scenarios use `#### Scenario:` format (4 hashtags)
- Don't use bullet points or bold for scenario headers

**Silent scenario parsing failures**
- Exact format required: `#### Scenario: Name`
- Debug with: `openspec show [change] --json --deltas-only`

### Validation Tips

```bash
# Always use strict mode for comprehensive checks
openspec validate [change] --strict

# Debug delta parsing
openspec show [change] --json | jq '.deltas'

# Check specific requirement
openspec show [spec] --json -r 1
```

## Happy Path Script

```bash
# 1) Explore current state
openspec spec list --long
openspec list
# Optional full-text search:
# rg -n "Requirement:|Scenario:" openspec/specs
# rg -n "^#|Requirement:" openspec/changes

# 2) Choose change id and scaffold
CHANGE=add-two-factor-auth
mkdir -p openspec/changes/$CHANGE/{specs/auth}
printf "## Why\n...\n\n## What Changes\n- ...\n\n## Impact\n- ...\n" > openspec/changes/$CHANGE/proposal.md
printf "## 1. Implementation\n- [ ] 1.1 ...\n" > openspec/changes/$CHANGE/tasks.md

# 3) Add deltas (example)
cat > openspec/changes/$CHANGE/specs/auth/spec.md << 'EOF'
## ADDED Requirements
### Requirement: Two-Factor Authentication
Users MUST provide a second factor during login.

#### Scenario: OTP required
- **WHEN** valid credentials are provided
- **THEN** an OTP challenge is required
EOF

# 4) Validate
openspec validate $CHANGE --strict
```

## Multi-Capability Example

```
openspec/changes/add-2fa-notify/
├── proposal.md
├── tasks.md
└── specs/
    ├── auth/
    │   └── spec.md   # ADDED: Two-Factor Authentication
    └── notifications/
        └── spec.md   # ADDED: OTP email notification
```

auth/spec.md
```markdown
## ADDED Requirements
### Requirement: Two-Factor Authentication
...
```

notifications/spec.md
```markdown
## ADDED Requirements
### Requirement: OTP Email Notification
...
```

## Best Practices

### Simplicity First
- Default to <100 lines of new code
- Single-file implementations until proven insufficient
- Avoid frameworks without clear justification
- Choose boring, proven patterns

### Complexity Triggers
Only add complexity with:
- Performance data showing current solution too slow
- Concrete scale requirements (>1000 users, >100MB data)
- Multiple proven use cases requiring abstraction

### Clear References
- Use `file.ts:42` format for code locations
- Reference specs as `specs/auth/spec.md`
- Link related changes and PRs

### Capability Naming
- Use verb-noun: `user-auth`, `payment-capture`
- Single purpose per capability
- 10-minute understandability rule
- Split if description needs "AND"

### Change ID Naming
- Use kebab-case, short and descriptive: `add-two-factor-auth`
- Prefer verb-led prefixes: `add-`, `update-`, `remove-`, `refactor-`
- Ensure uniqueness; if taken, append `-2`, `-3`, etc.

## Tool Selection Guide

| Task | Tool | Why |
|------|------|-----|
| Find files by pattern | Glob | Fast pattern matching |
| Search code content | Grep | Optimized regex search |
| Read specific files | Read | Direct file access |
| Explore unknown scope | Task | Multi-step investigation |

## Error Recovery

### Change Conflicts
1. Run `openspec list` to see active changes
2. Check for overlapping specs
3. Coordinate with change owners
4. Consider combining proposals

### Validation Failures
1. Run with `--strict` flag
2. Check JSON output for details
3. Verify spec file format
4. Ensure scenarios properly formatted

### Missing Context
1. Read project.md first
2. Check related specs
3. Review recent archives
4. Ask for clarification

## Quick Reference

### Stage Indicators
- `changes/` - Proposed, not yet built
- `specs/` - Built and deployed
- `archive/` - Completed changes

### File Purposes
- `proposal.md` - Why and what
- `tasks.md` - Implementation steps
- `design.md` - Technical decisions
- `spec.md` - Requirements and behavior

### CLI Essentials
```bash
openspec list              # What's in progress?
openspec show [item]       # View details
openspec diff [change]     # What's changing?
openspec validate --strict # Is it correct?
openspec archive [change] [--yes|-y]  # Mark complete (add --yes for automation)
```

Remember: Specs are truth. Changes are proposals. Keep them in sync.

``n
### openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\proposal.md

``n## Why
The project successfully migrated from qfluentwidgets to pure PyQt6, but `openspec/project.md` still references "PyQt-Fluent-Widgets (QFluentWidgets)" and "QFluentWidgets QConfig". This creates confusion for developers and AI assistants working on the codebase.

## What Changes
- Update `openspec/project.md` Tech Stack section to reflect pure PyQt6 usage
- Remove references to QFluentWidgets and QConfig
- Document custom `FolderSettingCard` implementation in `settings_page.py`
- Update configuration description to mention QSettings

## Impact
- Affected specs: `specs/ui/spec.md` (minor clarification)
- Affected code: None (documentation only)
- User Experience: No change
- Dependencies: No change


``n
### openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\specs\ui\spec.md

``n## MODIFIED Requirements

### Requirement: Main Window Interface
The application SHALL provide a main window using pure PyQt6 components (QMainWindow, QTableView, QPushButton) with GZ Media branding and intuitive controls for cue sheet analysis.

#### Scenario: Application startup
- **WHEN** the application starts
- **THEN** it displays the main window with GZ Media logo, control buttons, and dual table layout using standard PyQt6 widgets

#### Scenario: File opening
- **WHEN** user clicks on PDF or ZIP file icons in the top table
- **THEN** the corresponding file opens in the default system application

## ADDED Requirements

### Requirement: Settings Management
The application SHALL provide a settings interface using custom PyQt6 components and QSettings for persistence.

#### Scenario: Settings dialog display
- **WHEN** user opens settings
- **THEN** the application displays a settings page with custom `FolderSettingCard` widgets implemented in pure PyQt6

#### Scenario: Settings persistence
- **WHEN** user saves settings
- **THEN** configuration is persisted via QSettings to the platform-specific location

``n
### openspec\changes\archive\2025-10-17-update-docs-pyqt6-reality\tasks.md

``n## 1. Documentation Updates
- [x] 1.1 Update `openspec/project.md` Tech Stack section (lines 8-9)
- [x] 1.2 Update `openspec/project.md` Architecture Patterns section (line 27)
- [x] 1.3 Add note about custom `FolderSettingCard` in settings_page.py
- [x] 1.4 Validate with `openspec validate update-docs-pyqt6-reality --strict`

## 2. Verification
- [x] 2.1 Confirm no qfluentwidgets references remain in documentation
- [x] 2.2 Verify accuracy against actual code in `fluent_gui.py`, `settings_page.py`, `config.py`

``n
### openspec\changes\archive\2025-10-18-add-analysis-auto-export\proposal.md

``n## Why
Users need consistent, machine-readable records of each analysis run for downstream QA and archiving. Today exports are manual/implicit; adding automatic JSON export improves reliability and traceability.

## What Changes
- Add automatic JSON export of analysis results after each run.
- Respect `export.auto` flag; write into `export.default_dir`.
- Create timestamped filenames: `analysis_YYYYMMDD_HHMMSS.json`.
- Serialize `SideResult` items with JSON-safe fields (string paths, seconds totals, track diffs).
- Minimal UX: status label confirms export file name on completion.

## Impact
- Affected specs: `export` capability (new requirement: auto-export on completion).
- Affected code: `fluent_gui.py` (export helper + integration), `README.md` (usage docs).

``n
### openspec\changes\archive\2025-10-18-add-analysis-auto-export\specs\export\spec.md

``n## ADDED Requirements

### Requirement: Auto Export Analysis Results
The system SHALL automatically export analysis results to JSON after each analysis run when `export.auto` is true.

#### Scenario: Success
- WHEN an analysis run completes with one or more `SideResult` items
- AND `export.auto` is true
- THEN the app writes a JSON file to `export.default_dir`
- AND the filename matches `analysis_YYYYMMDD_HHMMSS.json`
- AND each `SideResult` entry contains string paths and numeric durations

#### Scenario: Disabled
- GIVEN `export.auto` is false
- WHEN an analysis run completes
- THEN no JSON export is written

#### Scenario: Directory Creation
- GIVEN `export.default_dir` does not exist
- WHEN an analysis run completes and export is enabled
- THEN the directory is created automatically
- AND the JSON export is written

#### Scenario: Write Failure
- GIVEN the app cannot write to `export.default_dir`
- WHEN an analysis run completes and export is enabled
- THEN the app logs an error and continues without crashing


``n
### openspec\changes\archive\2025-10-18-add-analysis-auto-export\tasks.md

``n## 1. Implementation
- [x] 1.1 Add JSON export helper gated by `export.auto`
- [x] 1.2 Ensure `export.default_dir` is created if missing
- [x] 1.3 Serialize `SideResult` with JSON-safe fields
- [x] 1.4 Integrate export on analysis completion
- [x] 1.5 Update README with export behavior

## 2. Validation
- [x] 2.1 Run an analysis with `export.auto=true` and verify JSON written
- [x] 2.2 Set `export.auto=false` and verify no file is written
- [x] 2.3 Point `export.default_dir` to a new folder and confirm auto-creation
- [x] 2.4 Open JSON and verify fields/structure

**Validace dokončena pomocí:** Automatizované pytest testy v `test_export_auto.py`
**Všechny testy prošly:** 6/6 testů úspěšných
**Datum dokončení:** 2025-10-13

``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\design.md

``n## Context
The current monolithic `fluent_gui.py` (1468 lines) mixes GUI, domain logic, and I/O. This refactoring separates concerns following Clean Architecture principles while maintaining behavior parity.

## Goals / Non-Goals
**Goals:**
- Separate domain logic (comparison, extraction) from GUI
- Improve testability through dependency injection
- Maintain 100% behavior parity (no user-visible changes)
- Enable future feature development without touching GUI

**Non-Goals:**
- Changing UI appearance or user workflows
- Adding new features (pure refactoring)
- Modifying external APIs (PDF/WAV extraction interfaces)

## Decisions

### Decision 1: Three-layer architecture
**What:** Organize code into `core/` (domain logic), `services/` (orchestration), `adapters/` (I/O), with GUI as presentation layer.

**Why:** 
- Domain logic becomes testable without Qt dependencies
- Services provide clear API for GUI to consume
- Adapters isolate filesystem/ZIP operations

**Alternatives considered:**
- Keep monolith: Rejected - testing and maintenance too difficult
- Full DDD with repositories: Rejected - over-engineering for this app size

### Decision 2: Extract functions, not classes initially
**What:** Move pure functions from `fluent_gui.py` to modules, keep existing function signatures.

**Why:**
- Minimal risk - functions are already well-defined
- Easy to verify behavior parity
- Can introduce classes later if needed

**Alternatives considered:**
- Create service classes immediately: Rejected - adds complexity without clear benefit yet

### Decision 3: Keep Pydantic models in core/models/
**What:** Move `TrackInfo`, `WavInfo`, `SideResult` from `fluent_gui.py` to `core/models/`.

**Why:**
- These are domain models, not GUI concerns
- Already well-defined with Pydantic validation
- Shared between domain and GUI layers

### Decision 4: AnalysisService as orchestrator
**What:** Create `services/analysis_service.py` that coordinates file discovery, extraction, comparison.

**Why:**
- GUI's `AnalysisWorker` (QThread) becomes thin wrapper around service
- Service can be tested without Qt event loop
- Clear separation: service = what to do, worker = how to do it in background

## Risks / Trade-offs

**Risk:** Breaking behavior during extraction
- **Mitigation:** P1 retro-spec defines parity scenarios; verify after each phase

**Risk:** Import cycles between layers
- **Mitigation:** Strict dependency direction: GUI → services → core → adapters (no reverse)

**Trade-off:** More files to navigate
- **Benefit:** Each file has single responsibility, easier to understand

## Migration Plan

**Phase P2 - Vrstvení:**
1. Create directory structure
2. Move pure functions (no Qt dependencies) first: `extract_numeric_id`, `discover_and_pair_files`
3. Move models to `core/models/`
4. Create `AnalysisService` wrapping moved functions
5. Update `AnalysisWorker` to delegate to service
6. Verify: run analysis, compare results with pre-refactor baseline

**Rollback:** Git revert if any parity scenario fails

## Open Questions
- Should `pdf_extractor.py` and `wav_extractor_wave.py` move to `adapters/` or stay at root? **Decision:** Move in future PR to keep this refactoring focused.


``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\proposal.md

``n## Why
The current `fluent_gui.py` (1468 lines) is a monolith mixing domain logic (PDF/WAV extraction, comparison), I/O operations, and GUI presentation. This makes testing difficult, reduces code reusability, and violates separation of concerns. The user's P0-P5 strategy provides a proven methodology for safe, auditable refactoring.

## What Changes
- **P2 - Vrstvení monolitu:** Extract domain logic from GUI
  - Move PDF/WAV/compare functions from `fluent_gui.py` (lines 183-402) to `core/domain/` modules
  - Move I/O operations (ZIP reading, file discovery) to `adapters/filesystem/`
  - Create `services/analysis_service.py` for orchestration
  - GUI keeps only presentation logic (models, views, signals)
- **P3 - Qt6 API modernization:** Update deprecated patterns
  - Replace `.exec_()` with `.exec()` throughout
  - Verify High-DPI attributes (lines 1422-1451 in `fluent_gui.py`)
  - Modernize enum usage (Qt.AlignmentFlag, QAbstractItemView.SelectionMode)
- **P4 - Quality gates:** Establish verification at each phase
  - Zero Critical/Major issues in Traycer Verify
  - OpenSpec validate --strict passes
  - Behavior parity scenarios pass

**BREAKING:** None - internal refactoring only, no API changes

## Impact
- Affected specs: `specs/ui/spec.md`, new `specs/analysis/spec.md`, new `specs/extraction/spec.md`
- Affected code: `fluent_gui.py`, `pdf_extractor.py`, `wav_extractor_wave.py`, new modules in `core/`, `services/`, `adapters/`
- User Experience: No visible changes
- Dependencies: No new dependencies
- Testing: Improved testability through dependency injection


``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\analysis\spec.md

``n## ADDED Requirements

### Requirement: File Discovery and Pairing
The system SHALL discover PDF and ZIP files in configured directories and pair them by numeric ID.

#### Scenario: Successful pairing
- **WHEN** PDF directory contains `12345_tracklist.pdf` and ZIP directory contains `12345_masters.zip`
- **THEN** the system creates a pair with ID "12345" linking both files

#### Scenario: Ambiguous pairing
- **WHEN** multiple PDFs or ZIPs share the same numeric ID
- **THEN** the system logs a warning and skips the ambiguous pair

#### Scenario: No matches
- **WHEN** no PDF-ZIP pairs share numeric IDs
- **THEN** the system returns an empty pairs dictionary

### Requirement: Numeric ID Extraction
The system SHALL extract numeric IDs from filenames based on configurable digit length and ignore list.

#### Scenario: ID filtering by length
- **WHEN** filename is "test_12345_master.zip" and min_digits=3, max_digits=6
- **THEN** the system extracts ID 12345

#### Scenario: Ignored numbers
- **WHEN** filename contains "2024" and ignore_numbers includes "2024"
- **THEN** the system excludes 2024 from extracted IDs

### Requirement: Track Comparison
The system SHALL compare PDF tracklist durations with WAV file durations and classify mismatches.

#### Scenario: Perfect match
- **WHEN** PDF track duration is 240s and WAV duration is 240.1s
- **THEN** the system classifies as "OK" (within tolerance)

#### Scenario: Warning threshold
- **WHEN** difference exceeds tolerance_warn (2s) but below tolerance_fail (5s)
- **THEN** the system classifies as "WARN"

#### Scenario: Failure threshold
- **WHEN** difference exceeds tolerance_fail (5s)
- **THEN** the system classifies as "FAIL"


``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\extraction\spec.md

``n## ADDED Requirements

### Requirement: PDF Tracklist Extraction
The system SHALL extract track information from PDF cue sheets using Vision LLM and consolidate by side.

#### Scenario: Multi-page PDF extraction
- **WHEN** PDF contains multiple pages with track listings
- **THEN** the system renders each page, sends to LLM, and consolidates tracks by side

#### Scenario: Side detection
- **WHEN** PDF contains headers like "Side A" or "SIDE B"
- **THEN** the system correctly assigns tracks to their respective sides

### Requirement: WAV Duration Extraction
The system SHALL extract WAV file durations from ZIP archives using wave module or soundfile fallback.

#### Scenario: Standard WAV extraction
- **WHEN** ZIP contains valid WAV files
- **THEN** the system reads frame count and sample rate to calculate duration

#### Scenario: Corrupted WAV fallback
- **WHEN** wave module fails to read WAV header
- **THEN** the system attempts soundfile extraction via temporary file

#### Scenario: Side inference from filename
- **WHEN** WAV filename is "A1_track.wav"
- **THEN** the system infers side="A" and position=1

### Requirement: Audio Mode Detection
The system SHALL detect audio mode (stereo/mono) from WAV files with AI fallback.

#### Scenario: Stereo detection
- **WHEN** WAV file has 2 channels
- **THEN** the system reports mode as "stereo"

#### Scenario: Mono detection
- **WHEN** WAV file has 1 channel
- **THEN** the system reports mode as "mono"


``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\specs\ui\spec.md

``n## MODIFIED Requirements

### Requirement: File Analysis Controls
The application SHALL provide controls for running analysis via a service layer that orchestrates domain operations.

#### Scenario: Analysis execution
- **WHEN** user clicks "Run analysis" button
- **THEN** the application invokes `AnalysisService` which coordinates file discovery, extraction, and comparison through domain modules

#### Scenario: Progress reporting
- **WHEN** analysis is running
- **THEN** the service emits progress signals that update the GUI status bar and progress indicator

#### Scenario: Result display
- **WHEN** analysis completes
- **THEN** the service returns structured results that populate the table models without GUI knowing domain logic details


``n
### openspec\changes\archive\2025-10-18-refactor-architecture-layering\tasks.md

``n﻿## P0 - ZahĹ™ĂˇtĂ­ motorĹŻ (Prerequisites)
- [x] 0.1 Confirm Track 1 (documentation update) is completed and archived
- [x] 0.2 Verify Traycer VS Code extension is installed and configured
- [x] 0.3 Confirm IDE agent (Cursor or Claude Code) for Hand-Off
- [x] 0.4 Run `openspec validate refactor-architecture-layering --strict`

## P1 - Retro-specifikace (Behavior Contract)
- [x] 1.1 Document current behavior scenarios in delta specs
- [x] 1.2 Create `specs/analysis/spec.md` delta for domain logic
- [x] 1.3 Create `specs/extraction/spec.md` delta for PDF/WAV extraction
- [x] 1.4 Define parity scenarios: file discovery, pairing, extraction, comparison
- [x] 1.5 Validate with `openspec validate --strict`
- [x] 1.6 Traycer: Generate Phases Workflow and visualize plan

## P2 - VrstvenĂ­ monolitu (Architecture Separation)
- [x] 2.1 Create directory structure: `core/domain/`, `core/models/`, `services/`, `adapters/filesystem/`
- [x] 2.2 Extract domain functions from `fluent_gui.py` (lines 183-225: `extract_numeric_id`, `discover_and_pair_files`)
- [x] 2.3 Move to `adapters/filesystem/file_discovery.py`
- [x] 2.4 Extract WAV/PDF extraction logic to `core/domain/extraction.py`
- [x] 2.5 Extract comparison logic (lines 340-402) to `core/domain/comparison.py`
- [x] 2.6 Create `services/analysis_service.py` to orchestrate domain operations
- [x] 2.7 Update `fluent_gui.py` to use service layer (AnalysisWorker class, lines 484-518)
- [x] 2.8 Traycer: Verify Changes in Workspace â†’ Fix forward â†’ Re-verify
- [x] 2.9 Quality gate: 0 Critical, 0 Major issues

## P3 - Qt6 API modernization
- [x] 3.1 Search for `.exec_()` calls and replace with `.exec()`
- [x] 3.2 Review High-DPI setup in `fluent_gui.py` (lines 1422-1451)
- [x] 3.3 Verify enum usage: Qt.AlignmentFlag, QAbstractItemView.SelectionMode, QHeaderView.ResizeMode
- [x] 3.4 Check QVariant usage in table models (TopTableModel, BottomTableModel)
- [x] 3.5 Traycer: Analyze Changes â†’ Propose fixes â†’ Apply â†’ Re-verify
- [x] 3.6 Quality gate: 0 Critical, 0 Major issues

## P4 - Ăšklid a verifikace
- [x] 4.1 Remove unused imports from refactored files
- [x] 4.2 Run `ruff` linter and fix issues
- [x] 4.3 Run `mypy` type checker and address warnings
- [x] 4.4 Verify all parity scenarios from P1 pass
- [x] 4.5 Traycer: Final Verify Changes in Workspace
- [x] 4.6 Quality gate: `openspec validate --strict` passes

## P5 - Archivace
- [x] 5.1 Run `openspec archive refactor-architecture-layering --yes`
- [x] 5.2 Verify deltas applied correctly to main specs
- [x] 5.3 Final validation: `openspec validate --strict`



``n
### openspec\changes\archive\2025-10-19-refactor-presentation-layer\design.md

``n## Context
The `fluent_gui.py` file has grown to 1161 lines and violates multiple SOLID principles. The refactoring aims to create a clean, testable, maintainable architecture while preserving all existing functionality. Key stakeholders are developers working on UI features (especially the upcoming `redesign-gz-media-ui` change) and QA engineers writing tests.

## Goals / Non-Goals

### Goals
- Achieve 100% backward compatibility with existing `fluent_gui.py` imports
- Enable isolated unit testing of all UI components with mock dependencies
- Implement Dependency Inversion Principle (DIP) throughout UI layer
- Separate worker/thread lifecycle management from MainWindow (SRP)
- Create clear, documented module boundaries
- Prepare architecture for upcoming UI redesign

### Non-Goals
- Changing any user-facing functionality or behavior
- Modifying the service layer (`AnalysisService`) or domain logic
- Introducing new UI frameworks or libraries
- Performance optimization (unless it emerges as a side benefit)
- Changing the configuration file format or storage mechanism

<h2>Decisions</h2>

<h3>Decision 1: Dependency Injection via Constructor Parameters</h3>
<p><strong>What</strong>: All components receive their dependencies (configuration, services) through constructor parameters rather than importing global objects.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Enables testing with mock objects</li>
<li>Makes dependencies explicit and visible</li>
<li>Follows Dependency Inversion Principle</li>
<li>Reduces coupling to global state</li>
</ul>
<p><strong>Alternatives considered</strong>:</p>
<ul>
<li><strong>Service Locator pattern</strong>: Rejected because it hides dependencies and makes testing harder</li>
<li><strong>Property injection</strong>: Rejected because it allows components to be in invalid state after construction</li>
<li><strong>Keep global config imports</strong>: Rejected because it prevents isolated testing</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Create typed configuration models in <code>ui/config_models.py</code> (Pydantic or dataclasses)</li>
<li>Each component declares its config needs in constructor</li>
<li><code>app.py</code> loads global config and creates specific config objects</li>
<li><code>MainWindow</code> receives all dependencies and passes them to child components</li>
</ul>

<h3>Decision 2: AnalysisWorkerManager for Thread Lifecycle</h3>
<p><strong>What</strong>: Create a dedicated manager class that encapsulates all QThread and AnalysisWorker lifecycle management.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>MainWindow has too many responsibilities (SRP violation)</li>
<li>Thread management is error-prone and should be centralized</li>
<li>Easier to test worker behavior in isolation</li>
<li>Cleaner MainWindow code focused on UI concerns</li>
</ul>
<p><strong>Alternatives considered</strong>:</p>
<ul>
<li><strong>Keep thread management in MainWindow</strong>: Rejected due to SRP violation and testing difficulty</li>
<li><strong>Use Qt's QThreadPool</strong>: Rejected because we need more control over worker lifecycle and signals</li>
<li><strong>Create abstract WorkerManager interface</strong>: Deferred to future if multiple worker types emerge</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li><code>AnalysisWorkerManager</code> owns QThread and AnalysisWorker instances</li>
<li>Provides high-level API: <code>start_analysis()</code>, <code>is_running()</code>, <code>stop_analysis()</code>, <code>cleanup()</code></li>
<li>Forwards worker signals to MainWindow</li>
<li>Handles all thread safety concerns internally</li>
</ul>

<h3>Decision 3: Configuration Abstractions with Typed Models</h3>
<p><strong>What</strong>: Create small, focused configuration classes (e.g., <code>ToleranceSettings</code>, <code>ExportSettings</code>) instead of passing entire config object.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Interface Segregation Principle - components only see what they need</li>
<li>Type safety and IDE autocomplete</li>
<li>Clear documentation of component dependencies</li>
<li>Easier to mock in tests</li>
</ul>
<p><strong>Alternatives considered</strong>:</p>
<ul>
<li><strong>Pass entire config object</strong>: Rejected because it hides actual dependencies</li>
<li><strong>Use dictionaries</strong>: Rejected because it loses type safety</li>
<li><strong>Environment variables</strong>: Rejected because it's less flexible and harder to test</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Define dataclasses/Pydantic models in <code>ui/config_models.py</code></li>
<li>Create <code>load_*_settings(cfg)</code> factory functions to convert from global config</li>
<li>Components declare specific settings type in constructor</li>
</ul>

<h3>Decision 4: Compatibility Wrapper for fluent_gui.py</h3>
<p><strong>What</strong>: Transform <code>fluent_gui.py</code> into a thin wrapper that imports from new modules and provides backward-compatible API.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Zero breaking changes for existing code</li>
<li>Gradual migration path for developers</li>
<li>Maintains existing entry point (<code>python fluent_gui.py</code>)</li>
</ul>
<p><strong>Alternatives considered</strong>:</p>
<ul>
<li><strong>Delete fluent_gui.py entirely</strong>: Rejected because it breaks existing imports</li>
<li><strong>Keep both implementations</strong>: Rejected because it creates maintenance burden</li>
<li><strong>Deprecate immediately</strong>: Rejected because it forces rushed migration</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Import all classes from new modules</li>
<li>Create type aliases (e.g., <code>TopTableModel = ResultsTableModel</code>)</li>
<li>Wrapper functions for functions that need config (load global config internally)</li>
<li>Deprecation comment directing to new structure</li>
<li>Characterization tests ensure compatibility</li>
</ul>

<h3>Decision 5: Characterization Tests Before Refactoring</h3>
<p><strong>What</strong>: Write comprehensive tests that capture current behavior before making any changes.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Safety net to detect regressions</li>
<li>Documents expected behavior</li>
<li>Validates compatibility wrapper</li>
<li>Enables confident refactoring</li>
</ul>
<p><strong>Alternatives considered</strong>:</p>
<ul>
<li><strong>Rely on existing tests</strong>: Rejected because coverage is incomplete</li>
<li><strong>Manual testing only</strong>: Rejected because it's not repeatable</li>
<li><strong>Skip characterization tests</strong>: Rejected because risk is too high</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Create <code>tests/test_fluent_gui_legacy.py</code></li>
<li>Test all exported symbols are importable</li>
<li>Test MainWindow can be instantiated</li>
<li>Test entry point execution</li>
<li>Run before and after refactoring to ensure identical behavior</li>
</ul>

<h2>Risks / Trade-offs</h2>

<h3>Risk: Increased Initial Complexity</h3>
<p><strong>Description</strong>: DI and manager classes add more files and indirection.</p>
<p><strong>Mitigation</strong>:</p>
<ul>
<li>Clear documentation and examples</li>
<li>Gradual rollout with compatibility wrapper</li>
<li>Training/code review for team</li>
</ul>
<p><strong>Trade-off</strong>: Short-term complexity for long-term maintainability</p>

<h3>Risk: Performance Overhead from DI</h3>
<p><strong>Description</strong>: Creating and passing config objects might add overhead.</p>
<p><strong>Mitigation</strong>:</p>
<ul>
<li>Config objects are created once at startup</li>
<li>Negligible impact compared to UI rendering and analysis</li>
<li>Profile if concerns arise</li>
</ul>
<p><strong>Trade-off</strong>: Minimal performance cost for massive testability gain</p>

<h3>Risk: Breaking Changes Despite Wrapper</h3>
<p><strong>Description</strong>: Subtle behavior differences might break existing code.</p>
<p><strong>Mitigation</strong>:</p>
<ul>
<li>Comprehensive characterization tests</li>
<li>Thorough manual testing</li>
<li>Gradual rollout with monitoring</li>
</ul>
<p><strong>Trade-off</strong>: Accept small risk for architectural improvement</p>

<h3>Risk: Maintenance of Two Code Paths</h3>
<p><strong>Description</strong>: Compatibility wrapper needs maintenance alongside new code.</p>
<p><strong>Mitigation</strong>:</p>
<ul>
<li>Wrapper is thin and mechanical</li>
<li>Plan deprecation timeline (e.g., 2 releases)</li>
<li>Document migration path</li>
</ul>
<p><strong>Trade-off</strong>: Temporary maintenance burden for smooth transition</p>

<h2>Migration Plan</h2>

<h3>Phase 1: Refactoring (This Change)</h3>
<ol>
<li>Implement new modular structure with DI</li>
<li>Create compatibility wrapper</li>
<li>Update tests</li>
<li>Validate with characterization tests</li>
<li>Deploy with both paths working</li>
</ol>

<h3>Phase 2: Migration (Future Change)</h3>
<ol>
<li>Update internal code to use new imports</li>
<li>Add deprecation warnings to wrapper</li>
<li>Update documentation</li>
<li>Communicate migration timeline</li>
</ol>

<h3>Phase 3: Cleanup (Future Change)</h3>
<ol>
<li>Remove compatibility wrapper</li>
<li>Remove legacy tests</li>
<li>Finalize documentation</li>
</ol>

<h2>Rollback Plan</h2>
<p>If critical issues are discovered:</p>
<ol>
<li>Revert to pre-refactoring commit</li>
<li>Compatibility wrapper ensures no code changes needed</li>
<li>Investigate issues in development environment</li>
<li>Fix and redeploy</li>
</ol>

<h2>Open Questions</h2>

<ol>
<li><strong>Q</strong>: Should we use Pydantic or dataclasses for config models?
   <strong>A</strong>: Start with dataclasses for simplicity. Migrate to Pydantic if validation becomes important.</li>
<li><strong>Q</strong>: How long should we maintain the compatibility wrapper?
   <strong>A</strong>: At least 2 releases (or 6 months), then deprecate with warnings.</li>
<li><strong>Q</strong>: Should AnalysisWorkerManager be a singleton?
   <strong>A</strong>: No, MainWindow owns its instance. Allows multiple windows in future if needed.</li>
<li><strong>Q</strong>: Should we refactor settings_page.py similarly?
   <strong>A</strong>: Defer to separate change. It's already modular and doesn't violate SOLID as severely.</li>
<li><strong>Q</strong>: How to handle theme.py functions that need config?
   <strong>A</strong>: Accept config as parameter. Wrapper functions in fluent_gui.py load global config for legacy callers.
</li></ol>

``n
### openspec\changes\archive\2025-10-19-refactor-presentation-layer\proposal.md

``n## Why
Soubor `fluent_gui.py` (~1161 řádků) je monolitický a obsahuje veškerou logiku prezentační vrstvy: konstanty, pomocné funkce, exportní logiku, threading workers, datové modely tabulek, hlavní okno, dialog nastavení a spouštěcí kód aplikace. Tato struktura ztěžuje údržbu, testování a budoucí rozšíření (např. `redesign-gz-media-ui`). Jednotlivé komponenty nelze snadno testovat izolovaně a změny v jedné části často vyžadují úpravy v nesouvisejících částech kódu.

Další problémy:
- **Porušení Dependency Inversion Principle (DIP)**: Komponenty přímo importují globální `config.cfg`, což snižuje testovatelnost
- **Porušení Single Responsibility Principle (SRP)**: `MainWindow` přímo řídí životní cyklus vláken a workerů
- **Nízká testovatelnost**: Těsné vazby na globální stav znemožňují izolované unit testy
- **Rigidní konfigurace**: Pevně zakódované cesty a závislosti

## What Changes
- **Vytvoření modulární struktury `ui/` balíčku** s podbalíčky pro modely, workers, dialogy a utility
- **Rozdělení `fluent_gui.py`** na samostatné moduly s jasně oddělenými zodpovědnostmi
- **Zavedení Dependency Injection (DI)**:
  - Vytvoření konfiguračních abstrakcí (`ui/config_models.py`) pomocí Pydantic/dataclass
  - Injektování konfigurace do konstruktorů komponent místo přímých importů
  - `MainWindow` a `app.py` načítají konfiguraci a předávají relevantní části komponentám
- **Vytvoření AnalysisWorkerManager** (`ui/workers/worker_manager.py`):
  - Zapouzdření správy životního cyklu QThread a AnalysisWorker
  - Odstranění detailů správy vláken z `MainWindow`
  - Delegace operací workerů přes manažera
- **Parametrizace vstupního bodu** (`app.py`):
  - Flexibilní cesty ke konfiguračním souborům
  - Podpora environmentálních proměnných
- **Characterization Tests**:
  - Testy pro ověření zpětné kompatibility před refaktoringem
  - Validace všech exportovaných symbolů z `fluent_gui.py`
- **Explicitní exporty** v `ui/__init__.py` s `__all__`

## Impact
- **Affected specs:** `specs/ui/spec.md` (přidání požadavků na DI, modulární architekturu, worker management)
- **Affected code:**
  - `fluent_gui.py` - transformace na compatibility wrapper
  - Nové soubory v `ui/` balíčku včetně `config_models.py` a `worker_manager.py`
  - `services/export_service.py` - přesun exportní logiky
  - Testy - nové characterization testy + aktualizace existujících
  - `README.md` - dokumentace nové struktury a DI vzorů
- **Benefits:**
  - **Výrazně lepší testovatelnost**: Komponenty lze testovat izolovaně s mock závislostmi
  - **SOLID principy**: DIP, SRP, OCP dodrženy v celé UI vrstvě
  - **Snadnější údržba**: Jasné oddělení zodpovědností
  - **Flexibilita**: Parametrizovatelná konfigurace
  - **Příprava pro redesign**: Čistá architektura pro `redesign-gz-media-ui`
  - **Žádná změna funkčnosti**: Pouze reorganizace a architektonické vylepšení

``n
### openspec\changes\archive\2025-10-19-refactor-presentation-layer\specs\ui\spec.md

``n## MODIFIED Requirements

### Requirement: Main Window Interface
The application SHALL provide a main window using pure PyQt6 components (QMainWindow, QTableView, QPushButton) with GZ Media branding and intuitive controls for cue sheet analysis. The UI SHALL be organized into modular, reusable components within a `ui/` package structure with dependency injection for configuration and services.

#### Scenario: Application startup
- **WHEN** the application starts
- **THEN** it displays the main window with GZ Media logo, control buttons, and dual table layout using standard PyQt6 widgets
- **AND** the UI components are loaded from modular packages (`ui.models`, `ui.workers`, `ui.dialogs`, `ui.main_window`)
- **AND** all components receive their dependencies via constructor injection

#### Scenario: Component reusability
- **WHEN** a developer needs to modify or test a UI component
- **THEN** they can work with isolated modules (e.g., `ResultsTableModel`, `AnalysisWorker`) without touching unrelated code
- **AND** each component has clear dependencies and can be unit tested independently with mock dependencies

#### Scenario: File opening
- **WHEN** user clicks on PDF or ZIP file icons in the top table
- **THEN** the corresponding file opens in the default system application

### Requirement: File Analysis Controls
The application SHALL provide controls for running analysis via a service layer that orchestrates domain operations, with worker lifecycle managed by a dedicated manager.

#### Scenario: Analysis execution
- **WHEN** user clicks "Run analysis" button
- **THEN** the MainWindow delegates to `AnalysisWorkerManager` which creates and manages the worker thread
- **AND** the worker invokes `AnalysisService` which coordinates file discovery, extraction, and comparison

#### Scenario: Progress reporting
- **WHEN** analysis is running
- **THEN** the worker manager forwards progress signals from the service to the GUI
- **AND** the GUI updates the status bar and progress indicator

#### Scenario: Worker cleanup
- **WHEN** analysis completes or the window closes
- **THEN** the worker manager safely terminates the worker thread and cleans up resources
- **AND** no memory leaks or zombie threads remain

## ADDED Requirements

### Requirement: Dependency Injection Architecture
The UI layer SHALL use dependency injection for all configuration and service dependencies, eliminating direct imports of global configuration objects.

#### Scenario: Configuration injection
- **WHEN** a UI component needs configuration values
- **THEN** it receives a specific configuration object (e.g., `ToleranceSettings`, `ExportSettings`) via constructor parameter
- **AND** the component does not directly import or access global `config.cfg`

#### Scenario: Service injection
- **WHEN** MainWindow needs worker management
- **THEN** it receives an `AnalysisWorkerManager` instance via constructor
- **AND** the MainWindow does not directly create or manage QThread instances

#### Scenario: Testability with mocks
- **WHEN** a developer writes unit tests for a UI component
- **THEN** they can inject mock configuration and service objects
- **AND** the component can be tested in isolation without global state

### Requirement: Configuration Abstractions
The application SHALL provide typed configuration models that represent specific subsets of configuration needed by components.

#### Scenario: Tolerance settings
- **WHEN** TracksTableModel needs tolerance values for match calculation
- **THEN** it receives a `ToleranceSettings` object with `warn_tolerance` and `fail_tolerance` fields
- **AND** the model uses these values without accessing global configuration

#### Scenario: Export settings
- **WHEN** ExportService needs to determine export behavior
- **THEN** it receives an `ExportSettings` object with `auto_export` and `export_dir` fields
- **AND** uses the injected settings for export behavior
- **AND** returns the export path to the UI for status display

#### Scenario: Theme settings
- **WHEN** ResultsTableModel needs status colors
- **THEN** it receives a `ThemeSettings` object with `status_colors` dictionary
- **AND** the model uses these colors for cell background rendering

### Requirement: Worker Lifecycle Management
The application SHALL encapsulate all worker and thread lifecycle management in a dedicated manager class, separating this concern from the main window.

#### Scenario: Worker creation
- **WHEN** analysis needs to start
- **THEN** AnalysisWorkerManager creates a new QThread and AnalysisWorker
- **AND** connects all necessary signals
- **AND** starts the thread

#### Scenario: Worker monitoring
- **WHEN** the UI needs to check if analysis is running
- **THEN** it queries `worker_manager.is_running()`
- **AND** receives accurate state without accessing thread internals

#### Scenario: Worker termination
- **WHEN** analysis completes or user closes the window
- **THEN** AnalysisWorkerManager safely stops the worker
- **AND** waits for thread completion with timeout
- **AND** cleans up all resources

### Requirement: Modular UI Architecture
The UI layer SHALL be organized into separate packages for models, workers, dialogs, and utilities, with each module having a single, well-defined responsibility.

#### Scenario: Table model isolation
- **WHEN** the results table needs modification
- **THEN** developers work only with `ui/models/results_table_model.py`
- **AND** changes do not affect other UI components

#### Scenario: Worker thread isolation
- **WHEN** analysis threading logic needs updates
- **THEN** developers work only with `ui/workers/analysis_worker.py` or `ui/workers/worker_manager.py`
- **AND** the worker can be tested independently with mock services

#### Scenario: Theme management
- **WHEN** GZ Media branding needs updates
- **THEN** developers modify only `ui/theme.py`
- **AND** theme changes apply consistently across all UI components

#### Scenario: Constants centralization
- **WHEN** UI strings or constants need updates
- **THEN** developers modify only `ui/constants.py`
- **AND** changes propagate to all components that import them

### Requirement: Export Service Separation
Export functionality SHALL be moved from the presentation layer to the service layer with dependency injection for configuration.

#### Scenario: JSON export with injected settings
- **WHEN** analysis results need to be exported
- **THEN** the `export_results_to_json` function in `services/export_service.py` receives results and `ExportSettings`
- **AND** uses the injected settings for export behavior
- **AND** returns the export path to the UI for status display

#### Scenario: Export configuration
- **WHEN** auto-export is enabled in settings
- **THEN** the export service checks `export_settings.auto_export`
- **AND** creates timestamped JSON files in `export_settings.export_dir`

### Requirement: Parametrized Application Entry Point
The application SHALL support flexible configuration paths via parameters and environment variables.

#### Scenario: Default configuration
- **WHEN** the application starts without parameters
- **THEN** it loads configuration from default `settings.json` path
- **AND** initializes all components with loaded settings

#### Scenario: Custom configuration path
- **WHEN** the application is started with `main(config_path=Path('custom.json'))`
- **THEN** it loads configuration from the specified path
- **AND** initializes all components with custom settings

#### Scenario: Environment variable configuration
- **WHEN** `TRACKLIST_CONFIG` environment variable is set
- **THEN** the application uses that path for configuration
- **AND** overrides the default path

### Requirement: Backward Compatibility
The refactored codebase SHALL maintain backward compatibility with existing imports from `fluent_gui.py` through a compatibility wrapper.

#### Scenario: Legacy imports
- **WHEN** existing code imports classes from `fluent_gui`
- **THEN** the imports continue to work via the compatibility wrapper
- **AND** wrapper functions handle global config access for legacy callers

#### Scenario: Entry point compatibility
- **WHEN** the application is started via `python fluent_gui.py`
- **THEN** it launches correctly by delegating to `app.main()`
- **AND** the behavior is identical to running `python app.py`

#### Scenario: Characterization test validation
- **WHEN** characterization tests run against the refactored code
- **THEN** all tests pass with identical behavior to pre-refactoring baseline
- **AND** all previously exported symbols remain accessible

### Requirement: Explicit Package Exports
The `ui` package SHALL explicitly define its public API through `__init__.py` with clear exports and `__all__` definition.

#### Scenario: Public API definition
- **WHEN** a developer imports from `ui` package
- **THEN** they have access to all public classes and functions listed in `__all__`
- **AND** the imports are explicit and documented

#### Scenario: IDE autocomplete support
- **WHEN** a developer types `from ui import`
- **THEN** their IDE shows all available exports from `__all__`
- **AND** provides accurate type hints for imported symbols

``n
### openspec\changes\archive\2025-10-19-refactor-presentation-layer\tasks.md

``n## Fáze 0: Příprava a Characterization Tests
- [x] 0.1 Vytvořit `tests/test_fluent_gui_legacy.py` pro characterization testing
  - Importovat všechny třídy a funkce z `fluent_gui.py`
  - Ověřit dostupnost: `MainWindow`, `TopTableModel`, `BottomTableModel`, `AnalysisWorker`, `SettingsDialog`, všech konstant
  - Test minimální instance `MainWindow` (bez exec)
  - Test spuštění `python fluent_gui.py` (subprocess)
- [x] 0.2 Spustit characterization testy a zdokumentovat baseline chování
- [x] 0.3 Vytvořit seznam všech symbolů exportovaných z `fluent_gui.py` pro wrapper

## Fáze 1: Příprava struktury, konstanty a konfigurační abstrakce
- [x] 1.1 Vytvořit `ui/` balíček s `__init__.py`
- [x] 1.2 Vytvořit `ui/constants.py` se všemi UI konstantami z `fluent_gui.py` (řádky 36-142)
  - Konstanty aplikace: `SETTINGS_FILENAME`, `WINDOW_TITLE`
  - Stavové zprávy: `STATUS_READY`, `STATUS_ANALYZING`, `MSG_*`
  - Texty tlačítek a popisků: `BUTTON_RUN_ANALYSIS`, `LABEL_FILTER`
  - Filtry: `FILTER_ALL`, `FILTER_OK`, `FILTER_FAIL`, `FILTER_WARN`
  - Hlavičky tabulek: `TABLE_HEADERS_TOP`, `TABLE_HEADERS_BOTTOM`
  - Symboly: `SYMBOL_CHECK`, `SYMBOL_CROSS`, `PLACEHOLDER_DASH`
  - Statusy: `STATUS_OK`, `STATUS_WARN`, `STATUS_FAIL`
- [x] 1.3 Vytvořit `ui/theme.py` s pomocnými funkcemi pro témata (řádky 57-122)
  - `get_system_file_icon()` - ikona souboru z QStyle
  - `get_gz_color(color_key)` - GZ Media barvy z konfigurace (přijímá config jako parametr)
  - `load_gz_media_fonts(app, font_config)` - načtení Poppins fontu s injektovanou konfigurací
  - `load_gz_media_stylesheet(app, stylesheet_path)` - načtení QSS s parametrizovanou cestou
- [x] 1.4 Vytvořit `ui/config_models.py` s konfiguračními abstrakcemi
  - `ToleranceSettings` (dataclass/Pydantic): `warn_tolerance: int`, `fail_tolerance: int`
  - `ExportSettings` (dataclass/Pydantic): `auto_export: bool`, `export_dir: Path`
  - `PathSettings` (dataclass/Pydantic): `pdf_dir: Path`, `wav_dir: Path`
  - `ThemeSettings` (dataclass/Pydantic): `font_family: str`, `font_size: int`, `stylesheet_path: Path`, `status_colors: dict`
  - `WorkerSettings` (dataclass/Pydantic): `pdf_dir: Path`, `wav_dir: Path`
  - Funkce `load_tolerance_settings(cfg) -> ToleranceSettings` pro konverzi z globální konfigurace
  - Funkce `load_export_settings(cfg) -> ExportSettings`
  - Funkce `load_path_settings(cfg) -> PathSettings`
  - Funkce `load_theme_settings(cfg) -> ThemeSettings`
  - Funkce `load_worker_settings(cfg) -> WorkerSettings`

## Fáze 2: Datové modely s Dependency Injection
- [x] 2.1 Vytvořit `ui/models/` balíček s `__init__.py`
- [x] 2.2 Přesunout `TopTableModel` do `ui/models/results_table_model.py` (řádky 259-404)
  - Přejmenovat na `ResultsTableModel`
  - **DI**: Konstruktor přijímá `theme_settings: ThemeSettings` místo přímého importu `config`
  - Použít `theme_settings.status_colors` pro mapování barev
  - Importovat závislosti z `ui.constants`
  - Zachovat všechny metody: `add_result`, `get_result`, `clear`, `all_results`, `set_filter`
- [x] 2.3 Přesunout `BottomTableModel` do `ui/models/tracks_table_model.py` (řádky 406-576)
  - Přejmenovat na `TracksTableModel`
  - **DI**: Konstruktor přijímá `tolerance_settings: ToleranceSettings` místo přímého importu `config.cfg`
  - Použít `tolerance_settings.warn_tolerance` pro výpočet match symbolů
  - Importovat závislosti z `ui.constants`
  - Zachovat metody: `update_data`, `get_track_row_data`, `get_total_row_data`

## Fáze 3: Workers a Worker Manager
- [x] 3.1 Vytvořit `ui/workers/` balíček s `__init__.py`
- [x] 3.2 Přesunout `AnalysisWorker` do `ui/workers/analysis_worker.py` (řádky 233-258)
  - **DI**: Konstruktor přijímá `worker_settings: WorkerSettings` místo přímých Path parametrů
  - Zachovat signály: `progress`, `result_ready`, `finished`
  - Importovat `AnalysisService` ze `services/`
- [x] 3.3 Vytvořit `ui/workers/worker_manager.py` s třídou `AnalysisWorkerManager`
  - **Zodpovědnost**: Správa životního cyklu QThread a AnalysisWorker
  - Konstruktor přijímá `worker_settings: WorkerSettings`
  - Metody:
    - `start_analysis()` - vytvoří worker a thread, propojí signály, spustí
    - `is_running() -> bool` - vrací stav běhu
    - `stop_analysis()` - bezpečně ukončí worker a thread
    - `cleanup()` - vyčistí resources
  - Signály (přeposílané z workera): `progress`, `result_ready`, `finished`
  - Interní správa QThread a AnalysisWorker instancí
  - Automatické cleanup při dokončení

## Fáze 4: Dialogy s Dependency Injection
- [x] 4.1 Vytvořit `ui/dialogs/` balíček s `__init__.py`
- [x] 4.2 Přesunout `SettingsDialog` do `ui/dialogs/settings_dialog.py` (řádky 1077-1113)
  - **DI**: Konstruktor přijímá `settings_filename: Path` místo přímého importu `SETTINGS_FILENAME`
  - Importovat `SettingsPage` z `settings_page`
  - Importovat `save_config` z `config`
  - Zachovat metodu `_on_save()` s parametrizovanou cestou

## Fáze 5: Hlavní okno s Dependency Injection
- [x] 5.1 Vytvořit `ui/main_window.py` s třídou `MainWindow` (řádky 578-1075)
  - **DI**: Konstruktor přijímá:
    - `tolerance_settings: ToleranceSettings`
    - `export_settings: ExportSettings`
    - `theme_settings: ThemeSettings`
    - `worker_manager: AnalysisWorkerManager`
    - `settings_filename: Path`
  - Vytvořit modely s injektovanými nastaveními:
    - `ResultsTableModel(theme_settings)`
    - `TracksTableModel(tolerance_settings)`
  - Použít `worker_manager` pro správu analýzy místo přímé správy QThread
  - Zachovat všechny metody:
    - `__init__()` - inicializace s DI, toolbar, tabulky, signály
    - `setup_menu_bar()`, `setup_tables()`, `connect_signals()`
    - `run_analysis()` - delegace na `worker_manager.start_analysis()`
    - `on_analysis_finished()` - volání `export_service.export_results_to_json(results, export_settings)`
    - `on_filter_changed()`, `on_top_row_selected()`, `on_top_cell_clicked()`, `on_bottom_cell_clicked()`
    - `open_settings()` - vytvoření `SettingsDialog(settings_filename, self)`
    - `_set_status()`, `_set_analysis_state()`
    - `_update_gz_logo()`, `_update_gz_claim_visibility()`
    - Event handlery: `showEvent()`, `eventFilter()`, `closeEvent()` - volání `worker_manager.cleanup()`
  - Zahrnout vnořené funkce pro auto-resize hlaviček

## Fáze 6: Servisní vrstva s Dependency Injection
- [x] 6.1 Vytvořit `services/export_service.py`
  - Přesunout `_export_results_to_json` (řádky 156-228)
  - Přejmenovat na `export_results_to_json` (veřejná funkce)
  - **DI**: Signatura `export_results_to_json(results: List[SideResult], export_settings: ExportSettings) -> Optional[Path]`
  - Použít `export_settings.auto_export` a `export_settings.export_dir` místo přímého čtení z `config.cfg`
  - Importovat závislosti z `core.models.analysis`

## Fáze 7: Vstupní bod s parametrizací
- [x] 7.1 Vytvořit `app.py` jako nový vstupní bod (řádky 1115-1160)
  - Pre-QApplication DPI setup s parametrizovatelnou cestou
  - Funkce `main(config_path: Optional[Path] = None)`:
    - Parametr `config_path` s defaultem `Path('settings.json')` nebo z env proměnné `TRACKLIST_CONFIG`
    - Načtení konfigurace z `config_path`
    - Vytvoření konfiguračních objektů pomocí `ui.config_models.load_*_settings(cfg)`
    - Vytvoření `AnalysisWorkerManager` s `WorkerSettings`
    - Načtení fontů a stylů s injektovanými `ThemeSettings`
    - Vytvoření `MainWindow` s všemi injektovanými závislostmi
    - Zobrazení okna a spuštění event loop
  - `if __name__ == '__main__': main()`

## Fáze 8: Kompatibilita a explicitní exporty
- [x] 8.1 Aktualizovat `ui/__init__.py` pro explicitní exporty
  - Importovat a exportovat:
    - Z `ui.constants`: všechny konstanty (nebo `*`)
    - Z `ui.theme`: všechny funkce
    - Z `ui.models`: `ResultsTableModel`, `TracksTableModel`
    - Z `ui.workers`: `AnalysisWorker`, `AnalysisWorkerManager`
    - Z `ui.dialogs`: `SettingsDialog`
    - Z `ui.main_window`: `MainWindow`
    - Z `ui.config_models`: všechny settings třídy a load funkce
  - Definovat `__all__` seznam pro explicitní veřejné API
- [x] 8.2 Transformovat `fluent_gui.py` na compatibility wrapper
  - Zachovat hlavičku souboru
  - Importovat všechny třídy a funkce z nové struktury
  - Aliasy pro zpětnou kompatibilitu:
    - `TopTableModel = ResultsTableModel`
    - `BottomTableModel = TracksTableModel`
  - Pro funkce vyžadující config vytvořit wrapper funkce, které načtou globální config:
    ```python
    from config import cfg
    from ui.theme import get_gz_color as _get_gz_color
    def get_gz_color(color_key):
        from ui.config_models import load_theme_settings
        theme_settings = load_theme_settings(cfg)
        return _get_gz_color(color_key, theme_settings)
    ```
  - Zachovat `if __name__ == '__main__': main()`
  - Přidat deprecation komentář s doporučením použít `app.py` a `ui/` package

## Fáze 9: Testy a dokumentace
- [x] 9.1 Spustit characterization testy z Fáze 0 pro ověření wrapperu
- [x] 9.2 Vytvořit unit testy pro nové komponenty s DI:
  - `tests/test_results_table_model.py` - test s mock `ThemeSettings`
  - `tests/test_tracks_table_model.py` - test s mock `ToleranceSettings`
  - `tests/test_analysis_worker.py` - test s mock `WorkerSettings` a `AnalysisService`
  - `tests/test_worker_manager.py` - test správy životního cyklu
  - `tests/test_export_service.py` - test s mock `ExportSettings`
- [x] 9.3 Aktualizovat existující testy:
  - `tests/test_gui_minimal.py` - import z `ui.main_window`, vytvoření s mock závislostmi
  - `tests/test_gui_simple.py` - importy z `ui.models`, `ui.main_window`
  - `tests/test_gui_show.py` - import z `ui.main_window`
  - `tests/test_settings_dialog.py` - import z `ui.dialogs`, test s parametrizovanou cestou
- [x] 9.4 Spustit všechny testy pro ověření funkčnosti
- [x] 9.5 Aktualizovat `README.md` s dokumentací:
  - Nová modulární struktura `ui/` package
  - Dependency Injection vzory
  - Použití `AnalysisWorkerManager`
  - Parametrizace `app.py`
  - Příklady testování s mock závislostmi

## Fáze 10: Validace a dokončení
- [x] 10.1 Spustit `openspec validate refactor-presentation-layer --strict`
- [x] 10.2 Ověřit, že aplikace funguje identicky jako před refaktoringem
- [x] 10.3 Zkontrolovat, že všechny importy fungují správně (včetně legacy z `fluent_gui.py`)
- [x] 10.4 Ověřit, že `python fluent_gui.py` i `python app.py` fungují
- [x] 10.5 Připravit archivaci `refine-main-ui-layout` změny
- [x] 10.6 Zdokumentovat migrační cestu pro vývojáře (z legacy importů na nové)

``n
### openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\proposal.md

``n## Why
Phase 1 of the stabilization effort establishes a reliable baseline before diving into deeper architectural refactoring. Current quality gaps make it risky to proceed: type workarounds in `core/domain/comparison.py` (lines 57-58) hide model compatibility problems, unreachable `logging.info()` code in `adapters/filesystem/file_discovery.py` (line 100) points to missing review discipline, characterization tests are absent so behavior changes can slip by unnoticed, and we do not have automated quality gates to prevent regressions.

## What Changes
- Fix type handling in `compare_data()` so it accepts Pydantic models directly instead of dumping to dictionaries
- Remove the unreachable `logging.info()` statement that sits after the return path in `discover_and_pair_files()`
- Add characterization tests with golden JSON outputs that lock today’s observable behavior
- Create `tools/check.sh` to run pytest, coverage (≥85%), ruff, `mypy --strict`, and `openspec validate`

This change is **non-breaking** and focuses solely on internal quality improvements.

## Impact
- Affected specs: `analysis` (type safety, dead code), `extraction` (characterization tests), `export` (golden outputs)
- Affected code: `core/domain/comparison.py`, `adapters/filesystem/file_discovery.py`, new `tests/test_characterization.py`, new `tools/check.sh`
- User experience: No visible changes; stabilization only
- Dependencies: No new packages required
- Testing: Establishes regression safety net for later refactor phases

``n
### openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\analysis\spec.md

``n## MODIFIED Requirements

### Requirement: Track Comparison
The system SHALL compare PDF tracklist durations with WAV file durations using strongly-typed Pydantic models and classify mismatches based on configurable tolerances.

#### Scenario: Perfect match
- **WHEN** PDF track duration is 240s and WAV duration is 240.1s
- **THEN** the system classifies as "OK" (within tolerance)

#### Scenario: Warning threshold
- **WHEN** difference exceeds tolerance_warn (2s) but below tolerance_fail (5s)
- **THEN** the system classifies as "WARN"

#### Scenario: Failure threshold
- **WHEN** difference exceeds tolerance_fail (5s)
- **THEN** the system classifies as "FAIL"

#### Scenario: Type-safe model handling
- **WHEN** `compare_data()` receives `TrackInfo` and `WavInfo` Pydantic models
- **THEN** the system constructs `SideResult` with model instances directly
- **AND** no dictionary conversion or type casting occurs

## ADDED Requirements

### Requirement: Code Quality Standards
The system SHALL maintain zero unreachable code and pass strict type checking.

#### Scenario: No dead code
- **WHEN** static analysis tools scan the codebase
- **THEN** no unreachable statements are detected
- **AND** all code paths are executable

#### Scenario: Strict type checking
- **WHEN** mypy runs with --strict flag
- **THEN** all type annotations are valid
- **AND** no type: ignore comments are needed for core domain logic

``n
### openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\export\spec.md

``n## ADDED Requirements

### Requirement: Golden Output Generation
The system SHALL support generating reference JSON outputs for regression testing.

#### Scenario: Comparison result serialization
- **WHEN** `SideResult` objects are serialized to JSON
- **THEN** all fields are properly converted to JSON-compatible types
- **AND** Path objects are converted to strings
- **AND** Pydantic models are serialized with their schema

#### Scenario: Golden file storage
- **WHEN** characterization tests run in record mode
- **THEN** current outputs are saved to `tests/data/golden/` directory
- **AND** subsequent test runs compare against these references

#### Scenario: Floating-point tolerance
- **WHEN** comparing golden outputs with current results
- **THEN** duration fields allow small floating-point differences (≤0.01s)
- **AND** integer fields require exact matches

``n
### openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\specs\extraction\spec.md

``n## ADDED Requirements

### Requirement: Behavior Characterization
The system SHALL maintain consistent extraction behavior verified by golden reference outputs.

#### Scenario: PDF extraction consistency
- **WHEN** the same PDF cue sheet is processed multiple times
- **THEN** extracted track data matches golden JSON reference
- **AND** side assignments, positions, and durations remain stable

#### Scenario: WAV extraction consistency
- **WHEN** the same ZIP archive is processed multiple times
- **THEN** extracted WAV metadata matches golden JSON reference
- **AND** duration calculations remain deterministic

#### Scenario: Pairing consistency
- **WHEN** PDF and ZIP files are discovered and paired
- **THEN** pairing results match golden reference
- **AND** numeric ID extraction follows configured rules consistently

``n
### openspec\changes\archive\2025-10-21-refactor-phase1-stabilization\tasks.md

``n## 1. Type System Fixes
- [x] 1.1 Analyze `SideResult` model in `core/models/analysis.py` - fields `pdf_tracks` and `wav_tracks` expect `List[TrackInfo]` and `List[WavInfo]` respectively
- [x] 1.2 Remove `model_dump()` calls on lines 57-58 in `core/domain/comparison.py`
- [x] 1.3 Pass `pdf_tracks` and `wav_tracks` directly as Pydantic model lists to `SideResult` constructor
- [x] 1.4 Remove unnecessary `cast(Any, ...)` type suppressions
- [x] 1.5 Run `mypy --strict core/domain/comparison.py` and verify no errors

## 2. Dead Code Removal
- [x] 2.1 Locate unreachable `logging.info()` on line 100 in `adapters/filesystem/file_discovery.py`
- [x] 2.2 Delete the unreachable statement (appears after `return` on line 99)
- [x] 2.3 Run `ruff check adapters/filesystem/file_discovery.py` to confirm no unreachable code warnings

## 3. Characterization Tests
- [x] 3.1 Create `tests/test_characterization.py` for behavior locking
- [x] 3.2 Add test for `discover_and_pair_files()` with known PDF/ZIP fixtures - capture pairs dictionary as golden output
- [x] 3.3 Add test for `compare_data()` with sample PDF tracks and WAV files - capture `SideResult` list as golden JSON
- [x] 3.4 Create `tests/data/golden/` directory for reference outputs
- [x] 3.5 Store golden JSON files: `golden_pairs.json`, `golden_comparison.json`
- [x] 3.6 Implement JSON comparison logic with tolerance for floating-point durations
- [x] 3.7 Run `pytest tests/test_characterization.py -v` and verify all pass

## 4. Quality Tooling
- [x] 4.1 Create `tools/` directory if it doesn't exist
- [x] 4.2 Create `tools/check.sh` bash script with shebang `#!/usr/bin/env bash` and `set -euo pipefail`
- [x] 4.3 Add pytest execution (N/A – covered by coverage run)
- [x] 4.4 Add coverage check: `coverage run -m pytest && coverage report --fail-under=85`
- [x] 4.5 Add ruff linting: `python -m ruff check .`
- [x] 4.6 Add mypy type checking: `mypy --strict core adapters services`
- [x] 4.7 Add OpenSpec validation: `openspec validate refactor-phase1-stabilization --strict`
- [x] 4.8 Add success message: `echo "All checks passed"`
- [x] 4.9 Make script executable: `chmod +x tools/check.sh`
- [x] 4.10 Run `tools/check.sh` locally and verify all gates pass

## 5. Validation and Documentation
- [x] 5.1 Run `openspec validate refactor-phase1-stabilization --strict` and fix any issues
- [x] 5.2 Verify all delta specs have at least one `#### Scenario:` per requirement
- [x] 5.3 Confirm `proposal.md` clearly explains non-breaking nature
- [x] 5.4 Update `tasks.md` checkboxes as work progresses
- [x] 5.5 Final quality gate: all checks in `tools/check.sh` pass

``n
### openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\proposal.md

``n## Why

The current codebase uses a global `cfg` singleton from `config.py` (line 661: `cfg = AppConfig()`) that is imported in 11 files across domain, adapter, UI, and test layers. This creates hidden dependencies that make functions harder to test, reduces reusability, and violates dependency inversion principle. Domain logic in `core/domain/comparison.py` (lines 44-45) and adapter logic in `adapters/filesystem/file_discovery.py` (lines 19-30) directly access global state instead of receiving configuration as parameters. While entry points like `app.py` already use dependency injection pattern with settings dataclasses (`ToleranceSettings`, `ExportSettings` from `ui/config_models.py`), this pattern hasn't been extended to lower layers. Phase 2 completes the DI transformation by eliminating global config access from domain/adapter layers, making functions pure and testable.

## What Changes

- Create `IdExtractionSettings` dataclass in `ui/config_models.py` with fields: `min_digits: int`, `max_digits: int`, `ignore_numbers: list[str]`
- Add `load_id_extraction_settings(cfg: AppConfig) -> IdExtractionSettings` loader function in `ui/config_models.py`
- Introduce `WaveformSettings` dataclass and loader in `ui/config_models.py` to encapsulate viewer/editor configuration
- Update `compare_data()` in `core/domain/comparison.py` to accept `ToleranceSettings` parameter instead of accessing `cfg.analysis_tolerance_warn/fail`
- Update `extract_numeric_id()` and `discover_and_pair_files()` in `adapters/filesystem/file_discovery.py` to accept `IdExtractionSettings` parameter
- Remove `from config import cfg` from 9 non-entry-point files: `core/domain/comparison.py`, `adapters/filesystem/file_discovery.py`, `waveform_viewer.py`, and test files
- Keep `cfg` imports only in entry points: `app.py`, `fluent_gui.py`, `settings_page.py`
- Update `AnalysisWorker` in `ui/workers/analysis_worker.py` to receive and pass settings to domain functions
- Update tests to use parametrized settings fixtures instead of mutating global `cfg`

Mark as **non-breaking** - internal refactoring only, no public API changes.

## Impact

- Affected specs: `analysis` (settings injection), `extraction` (ID extraction settings), `export` (settings propagation)
- Affected code: `core/domain/comparison.py`, `adapters/filesystem/file_discovery.py`, `ui/config_models.py`, `ui/workers/analysis_worker.py`, `ui/workers/worker_manager.py`, `services/analysis_service.py`, `waveform_viewer.py`, entry points, and tests
- User Experience: No visible changes
- Dependencies: No new dependencies
- Testing: Improved testability through explicit dependencies; tests can inject different settings without global state mutation
- Migration: Existing code continues to work; refactoring is internal only

``n
### openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\analysis\spec.md

``n## MODIFIED Requirements

### Requirement: Track Comparison
The system SHALL compare PDF tracklist durations with WAV file durations using injected tolerance settings together with strongly-typed Pydantic models and classify mismatches based on configurable tolerances.

#### Scenario: Perfect match
- **WHEN** PDF track duration is 240s and WAV duration is 240.1s
- **THEN** the system classifies as "OK" (within tolerance)

#### Scenario: Warning threshold
- **WHEN** difference exceeds tolerance_warn (2s) but below tolerance_fail (5s)
- **THEN** the system classifies as "WARN"

#### Scenario: Failure threshold
- **WHEN** difference exceeds tolerance_fail (5s)
- **THEN** the system classifies as "FAIL"

#### Scenario: Type-safe model handling
- **WHEN** `compare_data()` receives `TrackInfo` and `WavInfo` Pydantic models
- **THEN** the system constructs `SideResult` with model instances directly
- **AND** no dictionary conversion or type casting occurs

#### Scenario: Injected tolerance settings
- **WHEN** `compare_data()` is called with `ToleranceSettings(warn_tolerance=2, fail_tolerance=5)`
- **THEN** the provided thresholds drive warning and failure classification
- **AND** no global configuration is accessed inside the function

### Requirement: Numeric ID Extraction
The system SHALL extract numeric IDs from filenames using injected ID extraction settings that specify digit length and ignore list constraints.

#### Scenario: ID filtering by length
- **WHEN** filename is "test_12345_master.zip" and min_digits=3, max_digits=6
- **THEN** the system extracts ID 12345

#### Scenario: Ignored numbers
- **WHEN** filename contains "2024" and ignore_numbers includes "2024"
- **THEN** the system excludes 2024 from extracted IDs

#### Scenario: Injected ID extraction settings
- **WHEN** different `IdExtractionSettings` objects are supplied to `extract_numeric_id()`
- **THEN** the function filters IDs according to those settings
- **AND** behavior remains deterministic without relying on global config

## ADDED Requirements

### Requirement: Configuration Dependency Injection
The system SHALL inject configuration settings as explicit parameters to domain and adapter functions instead of accessing global state.

#### Scenario: Domain layer purity
- **WHEN** domain functions in `core/domain/` are invoked
- **THEN** all configuration is received via function parameters
- **AND** no global `cfg` imports exist in domain layer

#### Scenario: Adapter layer purity
- **WHEN** adapter functions in `adapters/` are invoked
- **THEN** all configuration is received via function parameters
- **AND** no global `cfg` imports exist in adapter layer

#### Scenario: Entry point responsibility
- **WHEN** application entry points (`app.py`, `fluent_gui.py`) start
- **THEN** they load configuration from global `cfg`
- **AND** construct settings dataclasses
- **AND** inject settings into lower layers

``n
### openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\export\spec.md

``n## MODIFIED Requirements

### Requirement: Auto Export Analysis Results
The system SHALL automatically export analysis results to JSON after each analysis run when `export.auto` is true, using injected export settings.

#### Scenario: Success
- WHEN an analysis run completes with one or more `SideResult` items
- AND `export.auto` is true
- THEN the app writes a JSON file to `export.default_dir`
- AND the filename matches `analysis_YYYYMMDD_HHMMSS.json`
- AND each `SideResult` entry contains string paths and numeric durations

#### Scenario: Disabled
- GIVEN `export.auto` is false
- WHEN an analysis run completes
- THEN no JSON export is written

#### Scenario: Directory Creation
- GIVEN `export.default_dir` does not exist
- WHEN an analysis run completes and export is enabled
- THEN the directory is created automatically
- AND the JSON export is written

#### Scenario: Write Failure
- GIVEN the app cannot write to `export.default_dir`
- WHEN an analysis run completes and export is enabled
- THEN the app logs an error and continues without crashing

#### Scenario: Injected export settings
- **WHEN** `ExportSettings(auto_export=True, export_dir=Path("exports"))` is provided
- **THEN** export decisions rely solely on the injected settings object
- **AND** no global configuration is accessed during export

## ADDED Requirements

### Requirement: Export Settings Dataclass
The system SHALL use `ExportSettings` dataclass to encapsulate export configuration.

#### Scenario: Settings construction
- **WHEN** entry point loads configuration
- **THEN** it constructs `ExportSettings(auto_export=bool, export_dir=Path)` from global config
- **AND** passes settings to export service

#### Scenario: Settings validation
- **WHEN** `ExportSettings` is constructed with invalid values
- **THEN** validation occurs at construction time
- **AND** errors are caught early in entry point

``n
### openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\specs\extraction\spec.md

``n## ADDED Requirements

### Requirement: Settings Propagation in Extraction Pipeline
The system SHALL propagate configuration settings through the extraction pipeline from entry points to domain functions.

#### Scenario: Worker receives settings
- **WHEN** `AnalysisWorker` is constructed
- **THEN** it receives `ToleranceSettings` and `IdExtractionSettings` as constructor parameters
- **AND** stores them for use during analysis

#### Scenario: Settings passed to file discovery
- **WHEN** worker calls `discover_and_pair_files()`
- **THEN** it passes `IdExtractionSettings` as parameter
- **AND** file discovery uses injected settings for ID extraction

#### Scenario: Settings passed to comparison
- **WHEN** worker calls `compare_data()`
- **THEN** it passes `ToleranceSettings` as parameter
- **AND** comparison uses injected settings for threshold classification

#### Scenario: No global config in extraction flow
- **WHEN** extraction pipeline executes from file discovery through comparison
- **THEN** no function accesses global `cfg` object
- **AND** all configuration flows through explicit parameters

``n
### openspec\changes\archive\2025-10-21-refactor-phase2-dependency-injection\tasks.md

``n## 1. Create Settings Dataclasses
- [x] 1.1 Add `IdExtractionSettings` dataclass to `ui/config_models.py` with fields: `min_digits: int`, `max_digits: int`, `ignore_numbers: list[str]`
- [x] 1.2 Create `load_id_extraction_settings(cfg: AppConfig) -> IdExtractionSettings` helper in `ui/config_models.py` that reads `cfg.analysis_min_id_digits.value`, `cfg.analysis_max_id_digits.value`, `cfg.analysis_ignore_numbers.value`
- [x] 1.3 Verify existing `ToleranceSettings` and `ExportSettings` dataclasses are sufficient (no changes needed)
- [x] 1.4 Add type hints and docstrings to new dataclass and loader function
- [x] 1.5 Introduce `WaveformSettings` dataclass and loader in `ui/config_models.py` to replace direct waveform configuration access

## 2. Refactor Domain Layer (core/domain/)
- [x] 2.1 Update `compare_data()` signature in `core/domain/comparison.py` to accept `tolerance_settings: ToleranceSettings` parameter
- [x] 2.2 Replace `cfg.analysis_tolerance_warn.value` (line 44) with `tolerance_settings.warn_tolerance`
- [x] 2.3 Replace `cfg.analysis_tolerance_fail.value` (line 45) with `tolerance_settings.fail_tolerance`
- [x] 2.4 Remove `from config import cfg` import (line 7)
- [x] 2.5 Update function docstring to document new parameter
- [x] 2.6 Run `mypy --strict core/domain/comparison.py` to verify type safety

## 3. Refactor Adapter Layer (adapters/filesystem/)
- [x] 3.1 Update `extract_numeric_id()` signature in `adapters/filesystem/file_discovery.py` to accept `settings: IdExtractionSettings` parameter
- [x] 3.2 Replace `cfg.analysis_min_id_digits.value` (line 19) with `settings.min_digits`
- [x] 3.3 Replace `cfg.analysis_max_id_digits.value` (line 23) with `settings.max_digits`
- [x] 3.4 Replace `cfg.analysis_ignore_numbers.value` (line 30) with `settings.ignore_numbers`
- [x] 3.5 Update `discover_and_pair_files()` signature to accept `settings: IdExtractionSettings` parameter
- [x] 3.6 Pass `settings` to `extract_numeric_id()` calls (lines 60, 69)
- [x] 3.7 Remove `from config import cfg` import (line 7)
- [x] 3.8 Update function docstrings to document new parameters
- [x] 3.9 Run `mypy --strict adapters/filesystem/file_discovery.py` to verify type safety

## 4. Update Service Layer and Workers
- [x] 4.1 Locate `AnalysisWorker` class in `ui/workers/analysis_worker.py`
- [x] 4.2 Update worker constructor to accept `tolerance_settings: ToleranceSettings` and `id_extraction_settings: IdExtractionSettings`
- [x] 4.3 Pass settings to `discover_and_pair_files()` and `compare_data()` calls within worker
- [x] 4.4 Update `AnalysisWorkerManager` in `ui/workers/worker_manager.py` to construct workers with settings
- [x] 4.5 Verify `app.py` entry point (lines 73-76) already loads settings and can pass them to worker manager
- [x] 4.6 Update `fluent_gui.py` if it directly calls domain functions (search for `compare_data` and `discover_and_pair_files` calls)

## 5. Update Entry Points
- [x] 5.1 In `app.py`, add `id_extraction_settings = load_id_extraction_settings(cfg)` after line 73
- [x] 5.2 Pass `id_extraction_settings` to `AnalysisWorkerManager` constructor (line 78)
- [x] 5.3 Verify `fluent_gui.py` entry point constructs and injects settings appropriately
- [x] 5.4 Keep `from config import cfg` imports in entry points (`app.py`, `fluent_gui.py`, `settings_page.py`) - these are the only files that should access global config

## 6. Refactor Tests
- [x] 6.1 Update `tests/test_characterization.py` to create settings objects instead of mutating `cfg` (lines 51-54, 84-87)
- [x] 6.2 Create pytest fixtures in `tests/conftest.py`: `@pytest.fixture def tolerance_settings()`, `@pytest.fixture def id_extraction_settings()`
- [x] 6.3 Update test functions to accept settings fixtures as parameters
- [x] 6.4 Remove direct `cfg` usage from characterization and export tests while leaving configuration-focused suites (`test_config.py`, `test_settings_dialog.py`) unchanged
- [x] 6.5 Parametrize tests to verify different settings combinations (e.g., different tolerance thresholds, different ID digit ranges)
- [x] 6.6 Keep `cfg` import in `test_config.py` since it tests the config system itself

## 7. Remove Remaining Global Config Imports
- [x] 7.1 Update `waveform_viewer.py` (line 38) to receive waveform settings via constructor instead of importing `cfg`
- [x] 7.2 Verify no other non-entry-point files import `cfg` by running: `rg "from config import cfg" --type py | grep -v "app.py\|fluent_gui.py\|settings_page.py\|test_config.py"`
- [x] 7.3 Document in code comments which files are allowed to import `cfg` (entry points only)

## 8. Validation and Quality Gates
- [x] 8.1 Run `tools/check.sh` and verify all checks pass (pytest, coverage ≥85%, ruff, mypy --strict, openspec validate)
- [x] 8.2 Run characterization tests and verify golden outputs still match (no behavior changes)
- [x] 8.3 Verify `mypy --strict` passes for refactored modules: `mypy --strict core/ adapters/ ui/config_models.py waveform_viewer.py`
- [x] 8.4 Run `openspec validate refactor-phase2-dependency-injection --strict` and fix any issues
- [x] 8.5 Verify all delta specs have at least one `#### Scenario:` per requirement
- [x] 8.6 Confirm proposal.md clearly explains non-breaking nature
- [x] 8.7 Update tasks.md checkboxes as work progresses
- [x] 8.8 Final smoke test: run application and perform analysis to verify functionality unchanged

``n
### openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\proposal.md

``n## Why
The current domain layer in `core/domain/extraction.py` violates hexagonal architecture principles by directly performing file I/O operations. The `extract_wav_durations_sf` function (lines 13-45) imports and uses `zipfile`, `tempfile`, and `shutil` to read ZIP archives, create temporary directories, and extract WAV files. This creates tight coupling between domain logic and infrastructure, making the code harder to test (requires real file system), harder to reuse (cannot swap I/O implementations), and violates the dependency inversion principle established in Phase 2. Domain functions should work with data objects, not perform I/O. Phase 3 completes the architectural layering by moving all file I/O operations to the adapter layer, keeping the domain pure and focused on business logic.

## What Changes
- Create `adapters/audio/` directory for audio-related adapters
- Create `adapters/audio/__init__.py` for package initialization
- Create `adapters/audio/wav_reader.py` with `ZipWavFileReader` class that encapsulates ZIP reading and WAV extraction logic
- Move ZIP opening, WAV file enumeration, temporary file creation, and duration extraction from `core/domain/extraction.py` to the new adapter
- Update `extract_wav_durations_sf` in `core/domain/extraction.py` to become a thin wrapper that delegates to `ZipWavFileReader`, or deprecate it entirely
- Remove imports of `zipfile`, `tempfile`, and `shutil` from `core/domain/extraction.py`
- Update `services/analysis_service.py` to instantiate `ZipWavFileReader` and use it directly instead of calling `extract_wav_durations_sf`
- Update `scripts/smoke_test.py` to use the new adapter
- Create unit tests for `ZipWavFileReader` covering: valid ZIP with WAVs, corrupted ZIP, empty ZIP, corrupted WAV files, missing WAV files, and soundfile/wave fallback scenarios
- Ensure `core/domain/` has no `open()`, `os`, `zipfile`, `tempfile`, or `shutil` imports after refactoring

## Impact
- Affected specs: `extraction` (I/O adapter layer introduction)
- Affected code: `core/domain/extraction.py`, new `adapters/audio/wav_reader.py`, `services/analysis_service.py`, `scripts/smoke_test.py`, new test files
- User Experience: No visible changes
- Dependencies: No new dependencies (uses existing `soundfile`, `wave`, `zipfile`)
- Testing: Improved testability through adapter pattern; can inject fake readers for unit tests without file system
- Architecture: Completes hexagonal architecture pattern with clear separation between domain and infrastructure layers
- Classification: Non-breaking; internal refactor only

``n
### openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\specs\extraction\spec.md

``n## ADDED Requirements

### Requirement: WAV File I/O Adapter
The system SHALL use an adapter layer to isolate ZIP and WAV file I/O operations from domain logic.

#### Scenario: ZIP reading via adapter
- **WHEN** the system needs to extract WAV files from a ZIP archive
- **THEN** it uses `ZipWavFileReader` adapter from `adapters.audio.wav_reader`
- **AND** domain layer receives `list[WavInfo]` objects without performing I/O

#### Scenario: Adapter error handling
- **WHEN** ZIP file cannot be opened or is corrupted
- **THEN** the adapter logs appropriate error messages
- **AND** returns empty list without crashing
- **AND** domain layer handles empty results gracefully

#### Scenario: Temporary file management
- **WHEN** adapter extracts WAV files for duration probing
- **THEN** it creates temporary directory for extraction
- **AND** cleans up temporary files after processing
- **AND** domain layer is unaware of temporary file operations

### Requirement: Domain Layer Purity
The system SHALL maintain domain layer free of file I/O operations and infrastructure dependencies.

#### Scenario: No I/O imports in domain
- **WHEN** domain modules in `core/domain/` are inspected
- **THEN** they contain no imports of `zipfile`, `tempfile`, `shutil`, `os.path`, or `open()`
- **AND** all file operations are delegated to adapter layer

#### Scenario: Domain receives data objects
- **WHEN** domain functions need WAV metadata
- **THEN** they receive `WavInfo` objects from adapters
- **AND** do not access file system directly
- **AND** remain testable without real files

#### Scenario: Adapter instantiation at service layer
- **WHEN** service layer orchestrates extraction workflow
- **THEN** it instantiates `ZipWavFileReader` adapter
- **AND** passes results to domain functions
- **AND** domain functions remain pure and side-effect free

## MODIFIED Requirements

### Requirement: WAV Duration Extraction
The system SHALL extract WAV file durations from ZIP archives using adapter layer that encapsulates wave module and soundfile fallback logic.

#### Scenario: Standard WAV extraction
- **WHEN** ZIP contains valid WAV files
- **THEN** the system reads frame count and sample rate to calculate duration

#### Scenario: Corrupted WAV fallback
- **WHEN** wave module fails to read WAV header
- **THEN** the system attempts soundfile extraction via temporary file

#### Scenario: Side inference from filename
- **WHEN** WAV filename is "A1_track.wav"
- **THEN** the system infers side="A" and position=1

#### Scenario: Adapter-based extraction
- **WHEN** `ZipWavFileReader.read_wav_files()` is called with ZIP path
- **THEN** the adapter opens ZIP, extracts WAV files to temporary directory
- **AND** probes each WAV using `get_wav_duration` from `audio_utils`
- **AND** returns `list[WavInfo]` with filename and duration_sec populated
- **AND** cleans up temporary files automatically

#### Scenario: Service layer integration
- **WHEN** `AnalysisService` processes a PDF-ZIP pair
- **THEN** it uses `ZipWavFileReader` instance to extract WAV metadata
- **AND** passes resulting `list[WavInfo]` to domain comparison logic
- **AND** domain layer performs no file I/O operations

``n
### openspec\changes\archive\2025-10-21-refactor-phase3-io-modularization\tasks.md

``n## 1. Create Adapter Infrastructure
- [x] 1.1 Create `adapters/audio/` directory
- [x] 1.2 Create `adapters/audio/__init__.py` with package initialization
- [x] 1.3 Verify directory structure matches existing `adapters/filesystem/` pattern
- [x] 1.4 **Git commit**: `git commit -m "refactor(phase3): create adapters/audio infrastructure"`

## 2. Implement ZipWavFileReader Adapter
- [ ] 2.1 Create `adapters/audio/wav_reader.py` file
- [ ] 2.2 Define `ZipWavFileReader` class with `__init__(self)` constructor
- [ ] 2.3 Implement `read_wav_files(self, zip_path: Path) -> list[WavInfo]` method
- [ ] 2.4 Move ZIP opening logic (currently inside `extract_wav_durations_sf` in `core/domain/extraction.py`) into the adapter
- [ ] 2.5 Move WAV member enumeration from `extract_wav_durations_sf` into the adapter
- [ ] 2.6 Move temporary directory handling from `extract_wav_durations_sf` into the adapter
- [ ] 2.7 Move WAV extraction loop from `extract_wav_durations_sf` into the adapter
- [ ] 2.8 Preserve the existing logging and error handling used in `extract_wav_durations_sf`
- [ ] 2.9 Import `get_wav_duration` from `audio_utils` (use `rg "get_wav_duration" core/domain/extraction.py` to locate the existing import)
- [ ] 2.10 Import `WavInfo` from `core.models.analysis` (see current usage in `core/domain/extraction.py`)
- [x] 2.11 Add comprehensive docstring explaining adapter's responsibility
- [ ] 2.12 Add type hints for all parameters and return values
- [ ] 2.13 **Git commit**: `git commit -m "refactor(phase3): implement ZipWavFileReader adapter with I/O logic"`

## 3. Refactor Domain Layer
- [ ] 3.1 Update `core/domain/extraction.py` to remove I/O operations
- [ ] 3.2 Option A: Keep `extract_wav_durations_sf` as thin wrapper that instantiates `ZipWavFileReader` and delegates (choose only if adapter indirection is required)
- [ ] 3.3 Option B: Deprecate `extract_wav_durations_sf` entirely and update all callers to use adapter directly
- [ ] 3.4 Remove `zipfile` import from `core/domain/extraction.py`
- [ ] 3.5 Remove `tempfile` import from `core/domain/extraction.py`
- [ ] 3.6 Remove `shutil` import from `core/domain/extraction.py`
- [ ] 3.7 Verify no `open()`, `os`, or other I/O operations remain in `core/domain/extraction.py`
- [ ] 3.8 Run `rg "import (zipfile|tempfile|shutil|os)" core/domain/` to confirm no I/O imports in domain layer
- [x] 3.9 Update module docstring to reflect new pure domain responsibility
- [ ] 3.10 **Git commit**: `git commit -m "refactor(phase3): remove I/O operations from domain layer"`

## 4. Update Service Layer
- [ ] 4.1 Update `services/analysis_service.py` to import `ZipWavFileReader` from `adapters.audio.wav_reader`
- [ ] 4.2 Add `ZipWavFileReader` instantiation in `AnalysisService.__init__` or as class attribute
- [ ] 4.3 Update `AnalysisService.start_analysis` to call `self.wav_reader.read_wav_files(pair_info["zip"])` instead of `extract_wav_durations_sf(pair_info["zip"])`
- [ ] 4.4 If keeping `extract_wav_durations_sf` as wrapper, update its import path accordingly
- [ ] 4.5 Verify service layer has no direct I/O operations
- [ ] 4.6 **Git commit**: `git commit -m "refactor(phase3): integrate ZipWavFileReader in service layer"`

## 5. Update Scripts and Entry Points
- [ ] 5.1 Update `scripts/smoke_test.py` import section to use `ZipWavFileReader` from `adapters.audio.wav_reader`
- [ ] 5.2 Instantiate `ZipWavFileReader` after constructing settings in `scripts/smoke_test.py`
- [ ] 5.3 Replace calls to `extract_wav_durations_sf` in `scripts/smoke_test.py` with `wav_reader.read_wav_files`
- [ ] 5.4 Search for any other direct calls to `extract_wav_durations_sf` using `rg "extract_wav_durations_sf" --type py`
- [ ] 5.5 Update all found references to use the new adapter pattern
- [ ] 5.6 **Git commit**: `git commit -m "refactor(phase3): update scripts to use ZipWavFileReader adapter"`

## 6. Create Unit Tests for Adapter
- [ ] 6.1 Create `tests/test_wav_reader.py` for adapter tests
- [ ] 6.2 Add test for valid ZIP with multiple WAV files: `test_read_wav_files_success`
- [ ] 6.3 Add test for corrupted ZIP file: `test_read_wav_files_corrupted_zip`
- [ ] 6.4 Add test for empty ZIP (no WAV files): `test_read_wav_files_empty_zip`
- [ ] 6.5 Add test for ZIP with corrupted WAV file: `test_read_wav_files_corrupted_wav`
- [ ] 6.6 Add test for ZIP with missing WAV extension: `test_read_wav_files_no_wav_extension`
- [ ] 6.7 Add test for soundfile fallback scenario: `test_read_wav_files_soundfile_fallback`
- [ ] 6.8 Add test for complete failure (both soundfile and wave fail): `test_read_wav_files_duration_extraction_failure`
- [ ] 6.9 Use pytest fixtures from `tests/conftest.py` for temporary ZIP creation
- [ ] 6.10 Mock `get_wav_duration` where appropriate to isolate adapter logic from `audio_utils`
- [ ] 6.11 Verify all tests pass: `pytest tests/test_wav_reader.py -v`
- [ ] 6.12 **Git commit**: `git commit -m "test(phase3): add comprehensive unit tests for ZipWavFileReader"`

## 7. Update Integration Tests
- [ ] 7.1 Review `tests/test_characterization.py` to ensure it still passes with adapter changes
- [ ] 7.2 If characterization tests call `extract_wav_durations_sf` directly, update to use the adapter
- [ ] 7.3 Verify golden outputs still match (no behavior changes)
- [ ] 7.4 Run full test suite: `pytest tests/ -v`
- [ ] 7.5 **Git commit**: `git commit -m "test(phase3): update integration tests for adapter pattern"`

## 8. Validation and Quality Gates
- [ ] 8.1 Run `tools/check.sh` and verify all checks pass (pytest, coverage ≥85%, ruff, mypy --strict, openspec validate)
- [ ] 8.2 Run `mypy --strict adapters/audio/` to verify new adapter has proper type hints
- [ ] 8.3 Run `rg "import (zipfile|tempfile|shutil|os\\.path|open\\()" core/domain/` to confirm no I/O in domain layer
- [ ] 8.4 Verify `core/domain/extraction.py` has no direct file operations
- [ ] 8.5 Run `openspec validate refactor-phase3-io-modularization --strict` and fix any issues
- [ ] 8.6 Verify all delta specs have at least one `#### Scenario:` per requirement
- [ ] 8.7 Confirm proposal.md clearly explains non-breaking nature
- [ ] 8.8 Update tasks.md checkboxes as work progresses
- [ ] 8.9 Final smoke test: run `scripts/smoke_test.py` and verify functionality unchanged
- [ ] 8.10 Verify coverage for new adapter code meets 85% threshold
- [ ] 8.11 **Git commit**: `git commit -m "refactor(phase3): complete I/O modularization - all quality gates passed"`

**Note**: Each git commit command creates an atomic checkpoint. If issues arise, you can revert to the last successful commit. Use `git log --oneline` to view commit history and `git revert <commit-hash>` if rollback is needed.

``n
### openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\proposal.md

``n## Why

The UI currently displays incorrect symbols (black arrows ►) in the "Match" and "Waveform" columns of the tracks table. This is caused by:
1. Font fallback issue: Poppins font is referenced in QSS but not physically present (only DejaVu fonts available)
2. Unicode symbols ✓/✗ render as arrows in the fallback font
3. System icon `QStyle.StandardPixmap.SP_MediaPlay` renders as an arrow on Windows

This creates visual inconsistency and reduces usability, as the meaning of the symbols is not immediately clear. Users cannot distinguish between match/mismatch states or understand the waveform action.

## What Changes

- **Introduce custom icon infrastructure**: Create `ui/theme.py::get_custom_icon()` function to load and cache SVG icons from `assets/icons/`
- **Create SVG icons**: Add three custom icons aligned with GZ Media branding:
  - `check.svg` (16x16, green #10B981) for successful matches
  - `cross.svg` (16x16, red #EF4444) for failed matches
  - `play.svg` (16x16, blue #3B82F6) for waveform view action
- **Replace text symbols with icons**: Modify `TracksTableModel` to return icons via `DecorationRole` instead of text via `DisplayRole`
- **Update tests**: Modify tests to check for `QIcon` in `DecorationRole` instead of text in `DisplayRole`
- **Deprecate old constants**: Mark `SYMBOL_CHECK` and `SYMBOL_CROSS` as deprecated

## Impact

- **Affected specs**: `specs/ui/spec.md` (new requirement: Custom Iconography)
- **Affected code**:
  - `ui/theme.py` - New function `get_custom_icon()`
  - `ui/models/tracks_table_model.py` - Icon rendering in columns 6 and 7
  - `ui/constants.py` - Deprecation comments
  - `tests/test_tracks_table_model.py` - Test updates
- **New files**:
  - `assets/icons/check.svg`
  - `assets/icons/cross.svg`
  - `assets/icons/play.svg`
- **User Experience**: **Critical improvement**. Replaces ambiguous arrows with clear, universally understood icons. Improves clarity, aesthetics, and cross-platform consistency.
- **Breaking changes**: None (backward compatible via deprecated constants)
``n
### openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\specs\ui\spec.md

``n## ADDED Requirements

### Requirement: Custom Iconography
The application SHALL use custom SVG icons for key status indicators and actions to ensure visual consistency, brand alignment, and cross-platform compatibility.

#### Scenario: Consistent Match symbols
- **WHEN** the tracks table is displayed
- **THEN** the "Match" column (column 6) SHALL render a custom green SVG checkmark icon for successful matches
- **AND** SHALL render a custom red SVG cross icon for failed matches
- **AND** SHALL NOT display text symbols like '✓', '✗', or arrows
- **AND** the icons SHALL be loaded from `assets/icons/check.svg` and `assets/icons/cross.svg`

#### Scenario: Consistent Waveform action icon
- **WHEN** the tracks table is displayed
- **THEN** the "Waveform" column (column 7) SHALL render a custom blue SVG "play" icon for the view waveform action
- **AND** SHALL NOT display a generic system arrow or text symbol
- **AND** the icon SHALL be loaded from `assets/icons/play.svg`

#### Scenario: Icon caching for performance
- **WHEN** icons are loaded multiple times
- **THEN** the application SHALL cache loaded icons in memory
- **AND** SHALL NOT reload the same icon from disk repeatedly

#### Scenario: Graceful fallback
- **WHEN** a custom icon file is missing or cannot be loaded
- **THEN** the application SHALL log a warning
- **AND** SHALL fall back to system icons or empty icons
- **AND** SHALL NOT crash or display error dialogs
``n
### openspec\changes\archive\2025-10-22-fix-ui-critical-symbols\tasks.md

``n## P0: Critical Icon and Symbol Fixes

### 1. Asset Creation
- [x] 1.1 Create `assets/icons/` directory
- [x] 1.2 Create `assets/icons/check.svg` (16x16, green #10B981)
- [x] 1.3 Create `assets/icons/cross.svg` (16x16, red #EF4444)
- [x] 1.4 Create `assets/icons/play.svg` (16x16, blue #3B82F6)

### 2. Theme and Configuration Update
- [x] 2.1 Modify `ui/theme.py`: Create function `get_custom_icon(icon_name: str) -> QIcon`
  - Load SVG icons from `assets/icons/`
  - Implement icon caching for performance
  - Add error handling with fallback to system icons
  - Support icons: 'check', 'cross', 'play'

### 3. Model Implementation
- [x] 3.1 Modify `ui/models/tracks_table_model.py`:
  - Import `get_custom_icon` from `ui.theme`
  - Column 6 (Match): Return icon via `DecorationRole`, empty string via `DisplayRole`
  - Column 7 (Waveform): Replace `get_system_file_icon('play')` with `get_custom_icon('play')`
  - Preserve match calculation logic (tolerance check)

### 4. Test Updates
- [x] 4.1 Modify `tests/test_tracks_table_model.py`:
  - Update `test_track_match_symbol_ok`: Check `DecorationRole` for valid `QIcon`
  - Update `test_track_match_symbol_fail`: Check `DecorationRole` for valid `QIcon`
  - Add `test_track_match_display_empty`: Verify `DisplayRole` returns empty string for column 6

### 5. Cleanup
- [x] 5.1 Modify `ui/constants.py`: Add deprecation comment above `SYMBOL_CHECK` and `SYMBOL_CROSS`
``n
### openspec\changes\archive\2025-10-22-fix-waveform-path-matching\proposal.md

``n## Why
The application crashes with a `FileNotFoundError` when a user tries to open the waveform viewer for a WAV file located in a subdirectory within the ZIP archive. The current implementation incorrectly compares the full internal path of the WAV file with just its basename, causing the file lookup to fail. This is a critical regression that blocks a core user workflow.

## What Changes
- Modify the file matching logic in `waveform_viewer.py` to compare the full internal path from the ZIP archive member list against the full path stored in the `WavInfo` model.
- Add a new scenario to the `ui` specification to formalize the correct behavior and prevent future regressions.

## Impact
- **Affected specs:** `specs/ui/spec.md` (one new scenario added).
- **Affected code:** `waveform_viewer.py` (one line of code changed).
- **User Experience:** Critical bug fix. Restores the ability to view waveforms for all valid ZIP archive structures.
``n
### openspec\changes\archive\2025-10-22-fix-waveform-path-matching\specs\ui\spec.md

``n## MODIFIED Requirements

### Requirement: Table Interactions
The application SHALL provide interactive tables for browsing analysis results.

#### Scenario: Waveform viewer opens for files in ZIP subdirectories
- **WHEN** user clicks the "View" button for a WAV file located in a subdirectory of a ZIP archive
- **THEN** the `WaveformEditorDialog` opens successfully
- **AND** the correct WAV file is extracted and displayed without a `FileNotFoundError`
``n
### openspec\changes\archive\2025-10-22-fix-waveform-path-matching\tasks.md

``n## 1. Code Implementation
- [x] 1.1 Locate the incorrect comparison in `_extract_wav` method in `WaveformEditorDialog` class within `waveform_viewer.py`.
- [x] 1.2 Change the line `if Path(member).name == self._wav_filename:` to `if member == self._wav_filename:`.

## 2. Validation
- [x] 2.1 Mark all tasks as complete.
- [x] 2.2 Run `openspec validate fix-waveform-path-matching --strict` to ensure the proposal is valid.
``n
### openspec\changes\archive\2025-10-22-refactor-phase4-export-service\proposal.md

``n## Why

The export functionality is currently accessible through two paths: the canonical `services.export_service.export_results_to_json()` function and a backward-compatibility wrapper `fluent_gui._export_results_to_json()` (lines 142-146). This duplication creates confusion about the correct import path and violates the single source of truth principle. The wrapper was introduced during the transition from monolithic `fluent_gui.py` to modular architecture, but now that Phase 1-3 refactoring is complete and `fluent_gui.py` is marked deprecated (lines 3-6), the wrapper serves no purpose. The UI layer (`ui/main_window.py`) already imports from the service directly (line 27), demonstrating the correct pattern. Only `test_export_auto.py` still uses the wrapper (line 24), creating technical debt. Phase 4 completes the export consolidation by removing the wrapper and ensuring all code uses the centralized service.

## What Changes

- Remove `_export_results_to_json()` wrapper function from `fluent_gui.py` (lines 142-146)
- Remove `_export_results_to_json` from `fluent_gui.__all__` export list (line 79)
- Update `test_export_auto.py` to import `export_results_to_json` from `services.export_service` instead of `fluent_gui` (line 24)
- Update `test_export_auto.py` to import `SideResult`, `TrackInfo`, `WavInfo` from `core.models.analysis` instead of `fluent_gui` (line 24)
- Verify no other code depends on the wrapper by searching for `fluent_gui._export_results_to_json` references
- Document in `services/export_service.py` docstring that it is the single source of truth for export operations
- Add comment in `fluent_gui.py` noting that export functionality has been moved to the service layer

This change is **non-breaking** because the wrapper was an internal API only and no external code depends on it.

## Impact

- Affected specs: `export` (single source of truth documentation)
- Affected code: `fluent_gui.py` (remove wrapper), `test_export_auto.py` (update imports), `services/export_service.py` (add documentation)
- User Experience: No visible changes
- Dependencies: No new dependencies
- Testing: Tests continue to pass with updated imports; no behavior changes
- Architecture: Completes export consolidation; establishes service layer as canonical location for export logic
- Migration: No migration needed - wrapper was internal only

``n
### openspec\changes\archive\2025-10-22-refactor-phase4-export-service\specs\export\spec.md

``n## MODIFIED Requirements

### Requirement: Auto Export Analysis Results
The system SHALL automatically export analysis results to JSON after each analysis run when `export.auto` is true, using the centralized export service.

#### Scenario: Success
- WHEN an analysis run completes with one or more `SideResult` items
- AND `export.auto` is true
- THEN the app calls `export_results_to_json()` from `services.export_service`
- AND writes a JSON file to `export.default_dir`
- AND the filename matches `analysis_YYYYMMDD_HHMMSS.json`
- AND each `SideResult` entry contains string paths and numeric durations

#### Scenario: Disabled
- GIVEN `export.auto` is false
- WHEN an analysis run completes
- THEN no JSON export is written

#### Scenario: Directory Creation
- GIVEN `export.default_dir` does not exist
- WHEN an analysis run completes and export is enabled
- THEN the directory is created automatically
- AND the JSON export is written

#### Scenario: Write Failure
- GIVEN the app cannot write to `export.default_dir`
- WHEN an analysis run completes and export is enabled
- THEN the app logs an error and continues without crashing

#### Scenario: Injected export settings
- **WHEN** `ExportSettings(auto_export=True, export_dir=Path("exports"))` is provided
- **THEN** export decisions rely solely on the injected settings object
- **AND** no global configuration is accessed during export

#### Scenario: Service layer usage
- **WHEN** UI layer needs to export results
- **THEN** it imports `export_results_to_json` from `services.export_service`
- **AND** passes `results` and `export_settings` parameters
- **AND** receives `Optional[Path]` return value (exported file path or None)


``n
### openspec\changes\archive\2025-10-22-refactor-phase4-export-service\tasks.md

``n## 1. Verify Current State
- [x] 1.1 Run `rg "_export_results_to_json" --type py` to confirm only `fluent_gui.py` and `test_export_auto.py` reference the wrapper
- [x] 1.2 Verify `ui/main_window.py` imports from `services.export_service` (line 27) as the correct pattern
- [x] 1.3 Confirm `services/export_service.py` has complete implementation with all required features
- [x] 1.4 Run existing tests to establish baseline: `pytest tests/test_export_service.py tests/test_export_auto.py -v`
- [x] 1.5 **Git commit**: `git commit -m "refactor(phase4): verify baseline before export consolidation"`

## 2. Update Test Imports
- [x] 2.1 Update `tests/test_export_auto.py` line 24 to import from `services.export_service` instead of `fluent_gui`
- [x] 2.2 Change import statement from `from fluent_gui import _export_results_to_json, SideResult, TrackInfo, WavInfo` to two separate imports:
  - `from services.export_service import export_results_to_json`
  - `from core.models.analysis import SideResult, TrackInfo, WavInfo`
- [x] 2.3 Update all function calls in `test_export_auto.py` from `_export_results_to_json(...)` to `export_results_to_json(...)` (lines 63, 117, 138, 163, 183, 216, 271)
- [x] 2.4 Run `pytest tests/test_export_auto.py -v` to verify tests still pass with new imports
- [x] 2.5 **Git commit**: `git commit -m "refactor(phase4): update test imports to use export service directly"`

## 3. Remove Wrapper from fluent_gui.py
- [x] 3.1 Delete `_export_results_to_json()` function from `fluent_gui.py` (lines 142-146)
- [x] 3.2 Remove `"_export_results_to_json"` from `__all__` list (line 79)
- [x] 3.3 Add comment at the location where the function was removed: `# Export functionality moved to services/export_service.py (Phase 4 refactoring)`
- [x] 3.4 Verify no other exports in `__all__` depend on the removed function
- [x] 3.5 Run `rg "_export_results_to_json" --type py` to confirm no remaining references
- [x] 3.6 **Git commit**: `git commit -m "refactor(phase4): remove export wrapper from fluent_gui"`

## 4. Document Service as Single Source of Truth
- [x] 4.1 Update `services/export_service.py` module docstring (add at top of file after imports) to state: "Centralized export service - single source of truth for all analysis result exports. All export operations should use export_results_to_json() from this module."
- [x] 4.2 Update `export_results_to_json()` function docstring to include usage example showing correct import path
- [x] 4.3 Add docstring section explaining the function is the canonical export implementation used by UI layer and tests
- [x] 4.4 **Git commit**: `git commit -m "docs(phase4): document export service as single source of truth"`

## 5. Verify No Regressions
- [x] 5.1 Run full test suite: `pytest tests/ -v`
- [x] 5.2 Specifically verify export tests pass: `pytest tests/test_export_service.py tests/test_export_auto.py -v`
- [x] 5.3 Run `rg "from fluent_gui import.*export" --type py` to confirm no remaining fluent_gui export imports
- [x] 5.4 Run `rg "fluent_gui\._export" --type py` to confirm no attribute access to the removed wrapper
- [x] 5.5 Verify `ui/main_window.py` still works correctly (imports from service, line 27)
- [x] 5.6 **Git commit**: `git commit -m "test(phase4): verify no regressions after export consolidation"`

## 6. Update Related Documentation
- [x] 6.1 Check if `README.md` or other documentation mentions export functionality
- [x] 6.2 Update any documentation to reference `services/export_service.py` as the export implementation
- [x] 6.3 Verify `fluent_gui.py` deprecation notice (lines 3-6) is still accurate
- [x] 6.4 Consider adding note to deprecation warning that export has been moved to service layer
- [x] 6.5 **Git commit**: `git commit -m "docs(phase4): update documentation for export consolidation"`

## 7. Validation and Quality Gates
- [x] 7.1 Run `tools/check.sh` and verify all checks pass (pytest, coverage ≥85%, ruff, mypy --strict, openspec validate)
- [x] 7.2 Run `mypy --strict services/export_service.py` to verify type safety
- [x] 7.3 Run `ruff check fluent_gui.py tests/test_export_auto.py services/export_service.py` to verify no linting issues
- [x] 7.4 Verify test coverage for export service remains ≥85%: `coverage run -m pytest tests/test_export_service.py tests/test_export_auto.py && coverage report`
- [x] 7.5 Run `openspec validate refactor-phase4-export-service --strict` and fix any issues
- [x] 7.6 Verify all delta specs have at least one `#### Scenario:` per requirement
- [x] 7.7 Confirm proposal.md clearly explains non-breaking nature
- [x] 7.8 Update tasks.md checkboxes as work progresses
- [x] 7.9 Final smoke test: run application and perform analysis with auto-export enabled to verify functionality unchanged
- [x] 7.10 **Git commit**: `git commit -m "refactor(phase4): complete export consolidation - all quality gates passed"`

``n
### openspec\changes\archive\2025-10-22-refactor-phase4-export-service\VERIFICATION_COMPLETE.md

``n# Phase 4 Verification Complete: Export Service Consolidation

**Date**: 2025-10-22  
**Status**: ✅ COMPLETE AND VERIFIED  
**Verification Method**: Systematic file-by-file verification against specification plan

---

## Executive Summary

Phase 4 (Export Service Consolidation) has been **fully implemented, tested, and verified**. All 41 tasks across 7 sections are marked complete in `tasks.md`. The verification confirms:

- ✅ Centralized export service properly implemented as single source of truth
- ✅ Wrapper function removed from `fluent_gui.py` with explanatory comment
- ✅ All test imports updated to use canonical export service
- ✅ UI layer correctly uses dependency injection pattern
- ✅ Analysis service maintains proper separation of concerns
- ✅ All quality gates pass (pytest, coverage, ruff, mypy, openspec)
- ✅ 100% of Phase 4 objectives achieved

---

## Verification Results by File

### 1. [`services/export_service.py`](services/export_service.py)

**Status**: ✅ VERIFIED - Single Source of Truth

**Verification Checklist**:
- [x] **Module docstring** (lines 11-12): States "Centralized export service - single source of truth for all analysis result exports. All export operations should use export_results_to_json() from this module."
- [x] **Function signature** (line 23): `export_results_to_json(results: list[SideResult], export_settings: ExportSettingsType) -> Path | None` uses dependency injection pattern
- [x] **Function docstring** (lines 24-32): Includes:
  - Clear purpose description
  - Usage example with correct import path (lines 27-28)
  - Statement that this is canonical implementation (line 30)
  - Return value documentation (line 31)
- [x] **Implementation completeness** (lines 33-71):
  - Auto-export check (line 33)
  - Directory creation with error handling (lines 37-41)
  - Timestamp-based filename generation (line 43)
  - JSON payload construction with proper serialization (lines 44-54)
  - Unique filename generation with collision handling (lines 56-68)
  - Comprehensive error logging (lines 40, 67, 70)
- [x] **Type safety**: `ExportSettingsProtocol` (lines 15-17) defines required interface

**Conclusion**: Export service is properly implemented as the canonical, centralized export implementation.

---

### 2. [`fluent_gui.py`](fluent_gui.py)

**Status**: ✅ VERIFIED - Wrapper Removed, Deprecation Clear

**Verification Checklist**:
- [x] **Wrapper function removal** (line 151): Comment "# Export functionality moved to services/export_service.py (Phase 4 refactoring)" confirms removal location
- [x] **Export list cleanup** (lines 77-129): `__all__` list does NOT include `"_export_results_to_json"` or any export-related symbols. Contains only:
  - UI components (MainWindow, SettingsDialog, table models, workers)
  - Models (SideResult, TrackInfo, WavInfo)
  - Constants (ICON_OPEN_QICON, BUTTON_RUN_ANALYSIS, COLOR_WHITE, etc.)
  - Theme functions (get_gz_color, load_gz_media_fonts, load_gz_media_stylesheet)
- [x] **Deprecation notice** (lines 2-6): Clearly states:
  - "DEPRECATION WARNING"
  - "This file is a backward-compatibility wrapper"
  - "New development should use the modular components from the `ui/` package"
  - "Export helpers moved to services/export_service.py" (line 6)
- [x] **No export imports**: File does NOT import `export_results_to_json` from `services.export_service`
- [x] **Remaining functionality**: File still provides:
  - `MainWindow` wrapper class (lines 163-196)
  - `SettingsDialog` wrapper class (lines 154-161)
  - Theme helper functions (lines 136-149)
  - Re-exports of UI components and constants

**Conclusion**: Wrapper properly removed with clear deprecation notice. Backward compatibility maintained for legacy code.

---

### 3. [`tests/test_export_auto.py`](tests/test_export_auto.py)

**Status**: ✅ VERIFIED - Imports Updated, All Tests Pass

**Verification Checklist**:
- [x] **Import statements** (lines 22-24):
  - `from core.models.analysis import SideResult, TrackInfo, WavInfo` (line 22)
  - `from core.models.settings import ExportSettings` (line 23)
  - `from services.export_service import export_results_to_json` (line 24)
  - NO import from `fluent_gui`
- [x] **Function calls**: All test methods call `export_results_to_json()` (not `_export_results_to_json()`):
  - `test_export_success` (line 64)
  - `test_export_disabled` (line 118)
  - `test_export_directory_creation` (line 139)
  - `test_export_write_failure` (line 164)
  - `test_export_empty_results` (line 184)
  - `test_export_json_structure_validation` (line 217)
  - `test_export_open_failure` (line 272)
- [x] **Test coverage**: All Phase 4 scenarios tested:
  - ✅ Success: auto_export=True creates JSON file (lines 52-105)
  - ✅ Disabled: auto_export=False creates no file (lines 106-123)
  - ✅ Directory Creation: non-existent directory is created (lines 124-147)
  - ✅ Write Failure: permission errors are logged (lines 148-174)
  - ✅ Empty Results: no export for empty list (lines 175-189)
  - ✅ JSON Structure: validates exported JSON format (lines 190-258)
  - ✅ Open Failure: file open errors are handled (lines 260-280)
- [x] **Settings usage**: Tests construct `ExportSettings` objects directly instead of mutating global config

**Test Results**: All 7 tests PASSED ✅

**Conclusion**: Test imports correctly updated to use canonical export service. All scenarios covered with passing tests.

---

### 4. [`tests/test_export_service.py`](tests/test_export_service.py)

**Status**: ✅ VERIFIED - Service Tests Complete

**Verification Checklist**:
- [x] **Import statements** (lines 8-10):
  - `from core.models.analysis import SideResult, TrackInfo, WavInfo` (line 8)
  - `from core.models.settings import ExportSettings` (line 9)
  - `from services.export_service import export_results_to_json` (line 10)
- [x] **Fixtures** (lines 13-35):
  - `export_settings` fixture (lines 13-15): Creates `ExportSettings` with `auto_export=True` and `tmp_path` directory
  - `sample_results` fixture (lines 18-35): Creates sample `SideResult` with PDF/WAV tracks
- [x] **Test methods**: Core functionality tests:
  - `test_export_results_creates_file` (lines 38-45): Confirms file creation and JSON structure
  - `test_export_respects_auto_export_disabled` (lines 48-51): Confirms no export when disabled
  - `test_export_returns_none_for_empty_results` (lines 54-56): Confirms no export for empty results
- [x] **Test assertions**: Verify:
  - Export path is returned when successful (line 40)
  - File exists on disk (line 41)
  - JSON payload has correct structure (lines 43-45)
  - `None` is returned when export is disabled or results are empty (lines 50, 55)

**Test Results**: All 3 tests PASSED ✅

**Conclusion**: Service tests complement auto tests by focusing on core service behavior. All tests passing.

---

### 5. [`ui/main_window.py`](ui/main_window.py)

**Status**: ✅ VERIFIED - UI Correctly Uses Export Service

**Verification Checklist**:
- [x] **Import statement** (line 29): `from services.export_service import export_results_to_json` imports canonical function
- [x] **Settings storage** (lines 66-67): `MainWindow.__init__` receives and stores `export_settings: ExportSettings` parameter as instance attribute `self.export_settings`
- [x] **Export invocation** (lines 325-328): `on_analysis_finished` method calls export service correctly:
  ```python
  export_path = export_results_to_json(
      results=all_results,
      export_settings=self.export_settings,
  )
  ```
  - Uses keyword arguments for clarity
  - Passes `all_results` from results table model (line 321)
  - Passes injected `self.export_settings` (not global config)
  - Captures return value `export_path` for status message
- [x] **Status message handling** (lines 330-334):
  - If `export_path is not None`: shows "Exported: {filename}" in status (line 331)
  - If `export_path is None`: shows standard completion message (line 333)
- [x] **No duplicate export logic**: `MainWindow` does NOT:
  - Implement its own export logic
  - Import or use the old wrapper from `fluent_gui`
  - Access global config for export decisions

**Conclusion**: UI correctly delegates to export service with dependency injection pattern. No duplicate logic.

---

### 6. [`services/analysis_service.py`](services/analysis_service.py)

**Status**: ✅ VERIFIED - Correct Separation of Concerns

**Verification Checklist**:
- [x] **Import statements** (lines 1-12): `AnalysisService` does NOT import:
  - `export_results_to_json` from `services.export_service`
  - `ExportSettings` from `core.models.settings`
  - Any export-related functionality
- [x] **Constructor** (lines 23-31): Only accepts:
  - `tolerance_settings: ToleranceSettings` (line 25)
  - `id_extraction_settings: IdExtractionSettings` (line 26)
  - `wav_reader: WavReader | None` (line 27)
  - NO `export_settings` parameter
- [x] **Analysis workflow** (lines 33-96): `start_analysis` method:
  - Discovers and pairs files (lines 44-46)
  - Extracts PDF and WAV data (lines 61-62)
  - Compares data (lines 65-70)
  - Emits results via callback (lines 73-74)
  - Does NOT perform export operations
- [x] **Callback pattern**: Service uses callbacks for results:
  - `result_callback` (line 38) emits individual `SideResult` objects (line 74)
  - UI layer is responsible for collecting results and triggering export
  - Service remains pure orchestrator without side effects
- [x] **Separation of concerns**: Architecture correctly separates:
  - **AnalysisService**: Orchestrates analysis workflow, emits results
  - **ExportService**: Handles export logic when called by UI
  - **MainWindow**: Collects results, calls export service after analysis completes

**Conclusion**: Service focuses only on analysis. Correct separation of concerns maintained.

---

### 7. Archived Tasks Documentation

**Status**: ✅ VERIFIED - All 41 Tasks Complete

**Section Completion**:
- [x] **Section 1: Verify Current State** (5 tasks) - All complete
- [x] **Section 2: Update Test Imports** (5 tasks) - All complete
- [x] **Section 3: Remove Wrapper from fluent_gui.py** (6 tasks) - All complete
- [x] **Section 4: Document Service as Single Source of Truth** (4 tasks) - All complete
- [x] **Section 5: Verify No Regressions** (6 tasks) - All complete
- [x] **Section 6: Update Related Documentation** (5 tasks) - All complete
- [x] **Section 7: Validation and Quality Gates** (10 tasks) - All complete

**Total**: 41/41 tasks marked complete ✅

---

## Quality Gates Verification

**Execution**: `bash tools/check.sh`  
**Exit Code**: 0 (Success)

### Test Results
```
47 passed, 79 deselected, 8 warnings in 4.84s
```

**Export-Specific Tests**:
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_success` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_disabled` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_directory_creation` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_write_failure` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_empty_results` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_json_structure_validation` PASSED
- ✅ `tests/test_export_auto.py::TestExportAuto::test_export_open_failure` PASSED
- ✅ `tests/test_export_service.py::test_export_results_creates_file` PASSED
- ✅ `tests/test_export_service.py::test_export_respects_auto_export_disabled` PASSED
- ✅ `tests/test_export_service.py::test_export_returns_none_for_empty_results` PASSED

### Coverage
```
Name                         Stmts   Miss  Cover
------------------------------------------------
core\domain\__init__.py          0      0   100%
core\domain\comparison.py       37      0   100%
services\__init__.py             0      0   100%
services\export_service.py      36      2    94%
------------------------------------------------
TOTAL                           73      2    97%
```

**Result**: ✅ 97% coverage (exceeds 85% threshold)

### Linting
```
Running Ruff lint checks...
All checks passed!
```

**Result**: ✅ No linting issues

### Type Safety
```
Running mypy in strict mode...
Success: no issues found in 15 source files
```

**Result**: ✅ Type-safe implementation

---

## Phase 4 Strategic Plan Objectives

**Phase 4 Goal** (from strategic plan): "Export jako služba" - Export as a service

**Objective**: "Jednotné místo pro export, snadná konfigurace, žádná logika v UI" - Single place for export, easy configuration, no logic in UI

### Required Steps - Verification

1. ✅ **Create `services/export_service.py`**
   - File exists with unified `export_results_to_json()` function
   - Function signature: `export_results_to_json(results: list[SideResult], settings: ExportSettings) -> Optional[Path]`
   - Proper documentation as single source of truth

2. ✅ **UI and AnalysisService call only this service**
   - UI (`ui/main_window.py`) correctly calls export service (lines 325-328)
   - AnalysisService does NOT call export (correct - not its responsibility)
   - Correct pattern: Service emits results → UI collects → UI calls export

3. ✅ **Tests for: auto export, directory creation, write failure**
   - `test_export_auto.py` has 7 comprehensive test methods
   - `test_export_service.py` has 3 additional tests
   - All scenarios covered: success, disabled, directory creation, write failure, empty results, JSON structure, open failure

### Expected Result - Verification

**"Centralizovaný, testovatelný export, žádné duplicity"** - Centralized, testable export, no duplicates

- ✅ **Centralized**: Single `export_results_to_json()` function in `services/export_service.py`
- ✅ **Testable**: 10 test methods across 2 test files, all passing
- ✅ **No duplicates**: Wrapper removed from `fluent_gui.py`, no other export implementations exist

### Success Metrics - Verification

**"Jediná funkce `export_results_to_json`, 100 % test pass"** - Single function `export_results_to_json`, 100% test pass

- ✅ **Single function**: Confirmed
- ✅ **100% test pass**: All export tests passing (10/10)

---

## Architecture Verification

### Dependency Injection Pattern

**Before Phase 4** (Anti-pattern):
```python
# fluent_gui.py
def _export_results_to_json(results):
    # Access global config
    export_settings = cfg.export_settings
    # ... export logic
```

**After Phase 4** (Correct pattern):
```python
# ui/main_window.py
export_path = export_results_to_json(
    results=all_results,
    export_settings=self.export_settings,  # Injected
)
```

**Verification**: ✅ Dependency injection properly implemented

### Separation of Concerns

```
┌─────────────────────────────────────────────────────────┐
│ UI Layer (ui/main_window.py)                            │
│ - Collects analysis results                             │
│ - Calls export service after analysis completes         │
│ - Displays export status to user                        │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│ Export Service (services/export_service.py)             │
│ - Single source of truth for export logic               │
│ - Handles file I/O, JSON serialization                  │
│ - Returns export path or None                           │
└─────────────────────────────────────────────────────────┘
                          ↑
┌─────────────────────────────────────────────────────────┐
│ Analysis Service (services/analysis_service.py)         │
│ - Pure orchestrator for analysis workflow               │
│ - Emits results via callbacks                           │
│ - Does NOT handle export                               │
└─────────────────────────────────────────────────────────┘
```

**Verification**: ✅ Clean separation of concerns maintained

---

## Conclusion

**Phase 4 (Export Service Consolidation) is COMPLETE and VERIFIED.**

All objectives have been achieved:
- ✅ Centralized export service implemented as single source of truth
- ✅ Wrapper function removed from `fluent_gui.py`
- ✅ All test imports updated to use canonical export service
- ✅ UI layer correctly uses dependency injection pattern
- ✅ Analysis service maintains proper separation of concerns
- ✅ All quality gates pass (pytest, coverage, ruff, mypy, openspec)
- ✅ 100% of Phase 4 objectives achieved
- ✅ 41/41 tasks marked complete in archived tasks.md

**Ready for Phase 5 (AI Port - Optional).**

---

**Verification Date**: 2025-10-22  
**Verified By**: Automated verification plan execution  
**Status**: ✅ COMPLETE

``n
### openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\proposal.md

``n# Phase 5: AI Port (Optional)

## Why

The current domain layer in `core/domain/comparison.py` violates hexagonal architecture principles by directly importing AI detection logic from `wav_extractor_wave.py` (lines 9-14). This standalone script contains infrastructure code (OpenAI/OpenRouter API clients, external HTTP calls) that creates tight coupling between domain logic and external services. The module-level variables `_detect` and `_normalize` (lines 13-14) are cast from functions in the standalone script, making the domain layer dependent on AI availability and API credentials. This makes testing difficult (requires mocking external APIs), prevents swapping detection strategies, and violates the dependency inversion principle established in Phase 2-3. Domain functions should depend on abstractions (ports), not concrete implementations (adapters). Phase 5 completes the hexagonal architecture by isolating all AI logic behind a port interface, making the domain pure and the system testable without external dependencies.

## What Changes

- Create `core/ports.py` with `AudioModeDetector` Protocol defining the detection interface
- Create `adapters/audio/ai_mode_detector.py` with `AiAudioModeDetector` class that wraps existing `detect_audio_mode_with_ai` and `normalize_positions` functions from `wav_extractor_wave.py`
- Create `adapters/audio/fake_mode_detector.py` with `FakeAudioModeDetector` class for tests (deterministic, no external API calls)
- Update `core/domain/comparison.py` to remove direct imports from `wav_extractor_wave.py` (lines 9, 13-14)
- Update `detect_audio_mode()` function signature to accept `detector: AudioModeDetector` parameter
- Update `compare_data()` function signature to accept `detector: AudioModeDetector` parameter
- Update `services/analysis_service.py` to instantiate `AiAudioModeDetector` in constructor (like `wav_reader` from Phase 3)
- Update `services/analysis_service.py` to pass detector to `compare_data()` calls
- Update `scripts/smoke_test.py` to instantiate and use detector
- Update `tests/conftest.py` to add `audio_mode_detector` fixture using `FakeAudioModeDetector`
- Update `tests/test_characterization.py` to accept detector fixture and pass to `compare_data()`
- Ensure `core/domain/` has no imports from `wav_extractor_wave.py` after refactoring
- Mark Phase 5 as **OPTIONAL** in proposal - system works without it, but architecture is cleaner with it

This is a **non-breaking** change - internal refactoring only, behavior remains identical.

## Impact

- **Affected specs**: `analysis` (AI port introduction, domain layer purity)
- **Affected code**: `core/ports.py` (new), `adapters/audio/ai_mode_detector.py` (new), `adapters/audio/fake_mode_detector.py` (new), `core/domain/comparison.py`, `services/analysis_service.py`, `scripts/smoke_test.py`, test files
- **User Experience**: No visible changes
- **Dependencies**: No new dependencies (uses existing `wav_extractor_wave` functions)
- **Testing**: Dramatically improved testability - tests use fake detector with no external API calls, deterministic results, faster execution
- **Architecture**: Completes hexagonal architecture pattern with all infrastructure dependencies isolated behind ports
- **Optional**: System functions correctly without this change, but architecture is significantly cleaner with it
- **Classification**: Non-breaking; internal refactor only
``n
### openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\specs\analysis\spec.md

``n# Analysis Capability - Phase 5 Delta Spec

## ADDED Requirements

### Requirement: Audio Mode Detection Port
The system SHALL use a port interface to isolate AI-based audio mode detection from domain logic.

#### Scenario: Detection via port
- **WHEN** the system needs to detect side and position from WAV filenames
- **THEN** it uses `AudioModeDetector` port from `core.ports`
- **AND** domain layer receives normalized results without knowing detection strategy

#### Scenario: Port interface definition
- **WHEN** `AudioModeDetector` Protocol is defined
- **THEN** it specifies `detect(wavs: list[WavInfo]) -> dict[str, list[WavInfo]]` method
- **AND** output guarantees normalized positions (sequential 1, 2, 3... per side)
- **AND** output guarantees no gaps or duplicates in positions

#### Scenario: Real AI adapter
- **WHEN** `AiAudioModeDetector` is instantiated
- **THEN** it wraps existing `detect_audio_mode_with_ai` and `normalize_positions` functions
- **AND** provides strict parsing → AI fallback → deterministic fallback → normalization
- **AND** requires OpenAI/OpenRouter API credentials for AI fallback

#### Scenario: Fake test adapter
- **WHEN** `FakeAudioModeDetector` is instantiated
- **THEN** it uses deterministic filename parsing with no external API calls
- **AND** guarantees consistent results for same inputs
- **AND** enables fast test execution without mocking external services

#### Scenario: Service layer integration
- **WHEN** `AnalysisService` is constructed
- **THEN** it accepts `audio_mode_detector: AudioModeDetector | None` parameter
- **AND** defaults to `AiAudioModeDetector()` if not provided
- **AND** passes detector to `compare_data()` function

#### Scenario: Test integration
- **WHEN** tests verify comparison behavior
- **THEN** they use `FakeAudioModeDetector` via pytest fixture
- **AND** avoid external API calls for deterministic, fast execution
- **AND** can test different detection scenarios by configuring fake detector

### Requirement: Complete Domain Layer Purity
The system SHALL maintain domain layer completely free of infrastructure dependencies including AI services.

#### Scenario: No AI imports in domain
- **WHEN** domain modules in `core/domain/` are inspected
- **THEN** they contain no imports from `wav_extractor_wave` or AI libraries
- **AND** all AI detection is delegated to adapter layer via port interface

#### Scenario: Domain depends on abstractions
- **WHEN** `compare_data()` function needs audio mode detection
- **THEN** it receives `AudioModeDetector` port via parameter
- **AND** calls `detector.detect(wavs)` without knowing implementation
- **AND** remains testable with any detector implementation

#### Scenario: No module-level infrastructure
- **WHEN** domain modules are loaded
- **THEN** they contain no module-level variables referencing infrastructure
- **AND** no module-level function casts to external implementations
- **AND** all dependencies are explicit via function parameters

## MODIFIED Requirements

### Requirement: Track Comparison
The system SHALL compare PDF tracklist durations with WAV file durations using injected tolerance settings and audio mode detector together with strongly-typed Pydantic models and classify mismatches based on configurable tolerances.

#### Scenario: Perfect match
- **WHEN** PDF track duration is 240s and WAV duration is 240.1s
- **THEN** the system classifies as "OK" (within tolerance)

#### Scenario: Warning threshold
- **WHEN** difference exceeds tolerance_warn (2s) but below tolerance_fail (5s)
- **THEN** the system classifies as "WARN"

#### Scenario: Failure threshold
- **WHEN** difference exceeds tolerance_fail (5s)
- **THEN** the system classifies as "FAIL"

#### Scenario: Type-safe model handling
- **WHEN** `compare_data()` receives `TrackInfo` and `WavInfo` Pydantic models
- **THEN** the system constructs `SideResult` with model instances directly
- **AND** no dictionary conversion or type casting occurs

#### Scenario: Injected tolerance settings
- **WHEN** `compare_data()` is called with `ToleranceSettings(warn_tolerance=2, fail_tolerance=5)`
- **THEN** the provided thresholds drive warning and failure classification
- **AND** no global configuration is accessed inside the function

#### Scenario: Injected audio mode detector
- **WHEN** `compare_data()` is called with `audio_mode_detector` parameter
- **THEN** the system uses the provided detector for side/position detection
- **AND** no direct imports from `wav_extractor_wave` occur
- **AND** detection strategy can be swapped without changing domain code

#### Scenario: Detector returns normalized results
- **WHEN** detector processes WAV files
- **THEN** returned `dict[str, list[WavInfo]]` has normalized positions per side
- **AND** positions are sequential (1, 2, 3...) with no gaps
- **AND** domain layer does not need to perform additional normalization

## REMOVED Requirements

None. Phase 5 adds capabilities without removing existing functionality.

## Migration Notes

Phase 5 is **optional** but recommended for architectural completeness:
- **Before**: Domain layer imports AI functions directly from `wav_extractor_wave.py`
- **After**: Domain layer depends on `AudioModeDetector` port, adapters implement detection strategies
- **Benefits**: (1) Domain layer is pure with zero infrastructure dependencies, (2) Tests run faster without external API calls, (3) Detection strategy can be swapped (e.g., rule-based, ML model, external service), (4) Hexagonal architecture is complete
- **No breaking changes**: All existing functionality preserved, only internal architecture improved
``n
### openspec\changes\archive\2025-10-22-refactor-phase5-ai-port\tasks.md

``n# Phase 5: AI Port - Implementation Tasks

**Status**: Implementation complete, pending final validation (Section 9)

## 1. Create Port Interface
- [x] 1.1 Create `core/ports.py` file (new file in core package)
- [x] 1.2 Add module docstring: "Port interfaces for hexagonal architecture - domain depends on these abstractions, adapters implement them."
- [x] 1.3 Define `AudioModeDetector` Protocol with `from typing import Protocol`
- [x] 1.4 Add method signature: `def detect(self, wavs: list[WavInfo]) -> dict[str, list[WavInfo]]: ...`
- [x] 1.5 Add comprehensive docstring explaining: (a) Protocol purpose - detect side/position from WAV filenames, (b) Input: list of WavInfo with filename and duration_sec populated, (c) Output: dict mapping side (e.g., "A", "B") to list of WavInfo with side and position populated and normalized, (d) Normalization: positions must be sequential (1, 2, 3...) with no gaps or duplicates
- [x] 1.6 Import `WavInfo` from `core.models.analysis`
- [x] 1.7 Add type hints for all parameters and return values
- [x] 1.8 Run `mypy --strict core/ports.py` to verify type safety
- [x] 1.9 **Git commit**: `git commit -m "refactor(phase5): create AudioModeDetector port interface"`

## 2. Implement Real AI Adapter
- [x] 2.1 Create `adapters/audio/ai_mode_detector.py` file
- [x] 2.2 Import `AudioModeDetector` from `core.ports`
- [x] 2.3 Import `detect_audio_mode_with_ai` and `normalize_positions` from `wav_extractor_wave`
- [x] 2.4 Import `WavInfo` from `core.models.analysis`
- [x] 2.5 Define `AiAudioModeDetector` class implementing `AudioModeDetector` Protocol
- [x] 2.6 Implement `detect(self, wavs: list[WavInfo]) -> dict[str, list[WavInfo]]` method
- [x] 2.7 Method implementation: (a) Call `side_map = detect_audio_mode_with_ai(wavs)` to get initial detection, (b) Call `normalize_positions(side_map)` to ensure sequential positions, (c) Return normalized `side_map`
- [x] 2.8 Add comprehensive docstring explaining: "Real AI-backed audio mode detector using OpenAI/OpenRouter APIs. Wraps existing wav_extractor_wave functions for strict parsing → AI fallback → deterministic fallback → normalization."
- [x] 2.9 Add type hints for all parameters and return values
- [x] 2.10 Handle edge cases: empty input list, all detection failures
- [x] 2.11 Run `mypy --strict adapters/audio/ai_mode_detector.py` to verify type safety
- [x] 2.12 **Git commit**: `git commit -m "refactor(phase5): implement AiAudioModeDetector adapter"`

## 3. Implement Fake Test Adapter
- [x] 3.1 Create `adapters/audio/fake_mode_detector.py` file
- [x] 3.2 Import `AudioModeDetector` from `core.ports`
- [x] 3.3 Import `WavInfo` from `core.models.analysis`
- [x] 3.4 Import `re` for filename parsing
- [x] 3.5 Define `FakeAudioModeDetector` class implementing `AudioModeDetector` Protocol
- [x] 3.6 Implement `detect(self, wavs: list[WavInfo]) -> dict[str, list[WavInfo]]` method with deterministic logic
- [x] 3.7 Deterministic detection logic: (a) Parse side from filename using regex `r"Side[_-]?([A-Za-z]+)"` (case-insensitive), (b) Parse position from filename using regex `r"^0*([1-9][0-9]?)\b"` or `r"([A-Za-z]+)0*([1-9][0-9]?)"`, (c) Default to side="A" if not found, (d) Group by side, (e) Sort by position (or filename if position missing), (f) Renumber positions sequentially (1, 2, 3...) per side
- [x] 3.8 Add comprehensive docstring: "Fake audio mode detector for tests. Uses deterministic filename parsing with no external API calls. Guarantees consistent results for same inputs."
- [x] 3.9 Add type hints for all parameters and return values
- [x] 3.10 Ensure no external dependencies (no OpenAI, no HTTP calls)
- [x] 3.11 Run `mypy --strict adapters/audio/fake_mode_detector.py` to verify type safety
- [x] 3.12 **Git commit**: `git commit -m "refactor(phase5): implement FakeAudioModeDetector for tests"`

## 4. Refactor Domain Layer
- [x] 4.1 Update `core/domain/comparison.py` to import `AudioModeDetector` from `core.ports` (add after line 8)
- [x] 4.2 Remove import from `wav_extractor_wave` (delete line 9: `from wav_extractor_wave import detect_audio_mode_with_ai, normalize_positions`)
- [x] 4.3 Remove module-level type aliases and casts (delete lines 11-14: `DetectFn`, `NormalizeFn`, `_detect`, `_normalize`)
- [x] 4.4 Update `detect_audio_mode()` function signature (line 16) to accept `detector: AudioModeDetector` parameter: `def detect_audio_mode(wavs: list[WavInfo], detector: AudioModeDetector) -> tuple[dict[str, str], dict[str, list[WavInfo]]]:`
- [x] 4.5 Update function body (line 24) to call detector: `side_map = detector.detect(wavs)` (replaces `_detect(wavs)` and `_normalize(side_map)` calls)
- [x] 4.6 Remove line 25 `_normalize(side_map)` since detector returns normalized results
- [x] 4.7 Update `compare_data()` function signature (line 35) to accept `detector: AudioModeDetector` parameter after `tolerance_settings`
- [x] 4.8 Update `detect_audio_mode()` call (line 43) to pass detector: `modes, wavs_by_side = detect_audio_mode(wav_data, detector)`
- [x] 4.9 Update function docstrings to document new `detector` parameter
- [x] 4.10 Run `rg "wav_extractor_wave" core/domain/` to confirm no remaining imports
- [x] 4.11 Run `mypy --strict core/domain/comparison.py` to verify type safety
- [x] 4.12 **Git commit**: `git commit -m "refactor(phase5): remove AI dependencies from domain layer"`

## 5. Update Service Layer
- [x] 5.1 Update `services/analysis_service.py` to import `AudioModeDetector` from `core.ports` (add after line 10)
- [x] 5.2 Import `AiAudioModeDetector` from `adapters.audio.ai_mode_detector` (add after line 7)
- [x] 5.3 Update `__init__` method signature (line 23) to accept `audio_mode_detector: AudioModeDetector | None = None` parameter after `wav_reader`
- [x] 5.4 Store detector as instance attribute (after line 31): `self._audio_mode_detector = audio_mode_detector or AiAudioModeDetector()`
- [x] 5.5 Update `compare_data()` call (line 65) to pass detector: `side_results = compare_data(pdf_data, wav_data, pair_info, self._tolerance_settings, self._audio_mode_detector)`
- [x] 5.6 Update class docstring (lines 16-21) to mention detector injection
- [x] 5.7 Run `mypy --strict services/analysis_service.py` to verify type safety
- [x] 5.8 **Git commit**: `git commit -m "refactor(phase5): integrate AudioModeDetector in service layer"`

## 6. Update Entry Points and Scripts
- [x] 6.1 Update `scripts/smoke_test.py` to import `AiAudioModeDetector` from `adapters.audio.ai_mode_detector` (add after line 8)
- [x] 6.2 Instantiate detector after line 28: `audio_mode_detector = AiAudioModeDetector()`
- [x] 6.3 Update `compare_data()` call (line 38) to pass detector: `side_results = compare_data(pdf_data, wav_data, pair_info, tolerance_settings, audio_mode_detector)`
- [x] 6.4 Verify `app.py` doesn't need changes (it only instantiates `AnalysisWorkerManager`, which instantiates `AnalysisService` with default detector)
- [x] 6.5 Run `rg "from wav_extractor_wave import" --type py` to confirm only `adapters/audio/ai_mode_detector.py` imports from it
- [x] 6.6 **Git commit**: `git commit -m "refactor(phase5): update scripts to use AudioModeDetector"`

## 7. Update Test Infrastructure
- [x] 7.1 Update `tests/conftest.py` to import `FakeAudioModeDetector` from `adapters.audio.fake_mode_detector` (add after line 16)
- [x] 7.2 Add `audio_mode_detector` fixture after line 121: `@pytest.fixture\ndef audio_mode_detector() -> FakeAudioModeDetector:\n    """Provide fake audio mode detector for tests (no external API calls)."""\n    return FakeAudioModeDetector()`
- [x] 7.3 Update `tests/test_characterization.py` to accept `audio_mode_detector` fixture in test functions
- [x] 7.4 Update `test_compare_data_matches_golden` (line 81) to accept fixture: `def test_compare_data_matches_golden(tmp_path, tolerance_settings, audio_mode_detector) -> None:`
- [x] 7.5 Update `compare_data()` call (line 100) to pass detector: `results = compare_data(pdf_data, wav_data, pair_info, tolerance_settings, audio_mode_detector)`
- [x] 7.6 Update `test_compare_data_respects_injected_tolerances` (line 121) to accept fixture: `def test_compare_data_respects_injected_tolerances(tmp_path: Path, warn_tolerance: int, fail_tolerance: int, expected_status: str, audio_mode_detector) -> None:`
- [x] 7.7 Update `compare_data()` call (line 147) to pass detector: `results = compare_data(pdf_data, wav_data, pair_info, tolerance, audio_mode_detector)`
- [x] 7.8 Run `pytest tests/test_characterization.py -v` to verify tests pass with fake detector
- [x] 7.9 Verify tests run faster (no external API calls)
- [x] 7.10 **Git commit**: `git commit -m "test(phase5): update tests to use FakeAudioModeDetector"`

## 8. Create Unit Tests for Adapters
- [x] 8.1 Create `tests/test_ai_mode_detector.py` for adapter tests
- [x] 8.2 Add test for `AiAudioModeDetector` with valid WAV filenames: `test_ai_detector_with_valid_filenames`
- [x] 8.3 Add test for `AiAudioModeDetector` with ambiguous filenames (triggers AI fallback): `test_ai_detector_with_ambiguous_filenames`
- [x] 8.4 Add test for `AiAudioModeDetector` with empty input: `test_ai_detector_with_empty_input`
- [x] 8.5 Add test for `FakeAudioModeDetector` with Side_A/Side_B filenames: `test_fake_detector_with_side_prefixes`
- [x] 8.6 Add test for `FakeAudioModeDetector` with A1/B1 prefixes: `test_fake_detector_with_letter_number_prefixes`
- [x] 8.7 Add test for `FakeAudioModeDetector` with ambiguous filenames (defaults to side A): `test_fake_detector_with_ambiguous_filenames`
- [x] 8.8 Add test for `FakeAudioModeDetector` position normalization: `test_fake_detector_normalizes_positions`
- [x] 8.9 Add test verifying `FakeAudioModeDetector` is deterministic (same input → same output): `test_fake_detector_is_deterministic`
- [x] 8.10 Mock external API calls in `AiAudioModeDetector` tests to avoid real API usage
- [x] 8.11 Run `pytest tests/test_ai_mode_detector.py -v` to verify all tests pass
- [x] 8.12 **Git commit**: `git commit -m "test(phase5): add unit tests for audio mode detectors"`

## 9. Validation and Quality Gates
- [x] 9.1 Run `tools/check.sh` and verify all checks pass (pytest, coverage ≥85%, ruff, mypy --strict, openspec validate)
- [x] 9.2 Run `mypy --strict core/ports.py adapters/audio/ai_mode_detector.py adapters/audio/fake_mode_detector.py` to verify type safety
- [x] 9.3 Run `rg "from wav_extractor_wave import" --type py` to confirm only `adapters/audio/ai_mode_detector.py` imports from it
- [x] 9.4 Run `rg "import wav_extractor_wave" core/domain/` to confirm no domain imports
- [x] 9.5 Verify `core/domain/comparison.py` has no infrastructure dependencies
- [x] 9.6 Run `openspec validate refactor-phase5-ai-port --strict` and fix any issues
- [x] 9.7 Verify all delta specs have at least one `#### Scenario:` per requirement
- [x] 9.8 Confirm proposal.md clearly explains optional nature and non-breaking changes
- [x] 9.9 Update tasks.md checkboxes as work progresses
- [x] 9.10 Final smoke test: run `scripts/smoke_test.py` and verify functionality unchanged
- [x] 9.11 Verify test suite runs faster (no external API calls in tests)
- [x] 9.12 Verify coverage for new adapter code meets 85% threshold
- [x] 9.13 **Git commit**: `git commit -m "refactor(phase5): complete AI port - all quality gates passed"`

**Note**: Each git commit command creates an atomic checkpoint. If issues arise, you can revert to the last successful commit. Use `git log --oneline` to view commit history and `git revert <commit-hash>` if rollback is needed.

**Optional Nature**: Phase 5 is marked as optional in the strategic plan. The system functions correctly without this change, but completing it provides significant architectural benefits: (1) domain layer becomes pure with zero infrastructure dependencies, (2) tests run faster without external API calls, (3) detection strategy can be swapped without changing domain code, (4) hexagonal architecture is complete.
``n
### openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\design.md

``n# Design Document: Unified Audit Refactoring

## Context

This refactoring is based on a unified audit identifying architectural code smells (Large Class/Module, Duplicate Code, Primitive Obsession, Overly Broad Exception Handling). While the previous 5-phase refactoring established clean layered architecture, this change applies specific design patterns and techniques to refine implementation within those layers.

## Goals / Non-Goals

### Goals
- Improve maintainability and readability
- Increase type safety
- Formalize orchestration logic using established patterns
- Enhance testability through smaller components
- Eliminate code duplication

### Non-Goals
- No new user-facing features
- No changes to external behavior
- No modifications to service layer public API

## Decisions

### Decision 1: Chain of Responsibility for Audio Mode Detection

**What**: Implement Chain of Responsibility pattern for AudioModeDetector. Create orchestrator ChainedAudioModeDetector that processes list of detection strategies (StrictParserStep, AiParserStep, DeterministicFallbackStep)

**Why**: Current logic in wav_extractor_wave.py (function detect_audio_mode_with_ai) is an implicit chain. This pattern makes orchestration explicit, configurable, and extensible. Each step is self-contained and testable. Complements existing Strategy pattern defined in core/ports.py

**Alternatives considered**: Complex if/elif/else structure within single class. Rejected as less flexible and harder to maintain

### Decision 2: Extract Class for Filename Parsing

**What**: Create domain service class StrictFilenameParser to centralize all regex-based parsing logic for side and position

**Why**: Logic duplicated in fake_mode_detector.py (method _parse_filename) and wav_extractor_wave.py (function strict_from_path). Dedicated class adheres to SRP and DRY principles, provides single source of truth

**Alternatives considered**: Simple utility function. Rejected in favor of class to allow future extension and state management

### Decision 3: Replace Primitive with Object for File Pairing

**What**: Introduce @dataclass class FilePair(pdf: Path, zip: Path) and refactor discover_and_pair_files in adapters/filesystem/file_discovery.py to return dict[int, FilePair]

**Why**: Current use of dict[str, dict[str, Path]] is classic Primitive Obsession. Dedicated FilePair object improves type safety, code clarity, and self-documentation. Allows consistent use of int for IDs

**Alternatives considered**: Using TypedDict. Rejected because dataclass provides more features (methods) for future use

### Decision 4: Decompose Monolithic Modules

**What**: Break down wav_extractor_wave.py and pdf_extractor.py into smaller, single-responsibility components

**Why**: These modules violate Single Responsibility Principle and are difficult to test and maintain (Large Class/Module code smell)

**Implementation**:
- wav_extractor_wave.py: Logic distributed among StrictFilenameParser and Chain of Responsibility steps
- pdf_extractor.py: Break into PdfImageRenderer (Adapter), VlmClient (Adapter), and TracklistParser (Domain Service)

## Migration Plan

Execution order to minimize risk:

1. **Foundation**: Implement StrictFilenameParser and FilePair. Update callers
2. **Architecture**: Implement Chain of Responsibility pattern for audio detection
3. **Decomposition**: Decompose monolithic modules, replacing internal logic with new components
4. **Hardening**: Refine exception handling by replacing broad except Exception with specific exceptions
``n
### openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\proposal.md

``n# Refactor Unified Audit Plan

## Why

The unified audit has identified several architectural weaknesses in the current implementation that violate established design principles and best practices:

### Architectural Weaknesses Identified

**Monolithic modules**: The `wav_extractor_wave.py` (297 lines) and `pdf_extractor.py` (184 lines) violate the Single Responsibility Principle by combining multiple concerns within single files. These modules handle file parsing, data extraction, format validation, and business logic all in one place.

**Duplicate code**: Filename parsing logic is duplicated between `wav_extractor_wave.py` (function `strict_from_path`) and `adapters/audio/fake_mode_detector.py` (method `_parse_filename`). This creates maintenance issues and potential inconsistencies when changes are needed.

**Primitive obsession**: `adapters/filesystem/file_discovery.py` returns `dict[str, dict[str, Path]]` instead of proper domain objects. This makes the code harder to understand, test, and maintain, as the data structure lacks semantic meaning.

**Magic numbers**: The value 999 is used for sorting in multiple locations without named constants, making the code less readable and maintainable. These magic numbers should be replaced with well-named constants that explain their purpose.

**Overly broad exception handling**: `adapters/audio/wav_reader.py` uses `except Exception` instead of specific exceptions like `zipfile.BadZipFile`. This makes debugging difficult and can hide real issues in the codebase.

While the previous 5-phase refactoring established a clean layered architecture with proper separation of concerns, this refactoring focuses on applying specific design patterns and refactoring techniques to improve implementation quality within those established layers.

## What Changes

This refactoring implements four main steps to address the identified architectural weaknesses:

### 1. Create Foundational Building Blocks
Introduce `StrictFilenameParser` domain service and `FilePair` dataclass to eliminate code duplication and primitive types. This will centralize filename parsing logic and provide type-safe data structures for file relationships.

### 2. Implement Architectural Patterns
Formalize audio mode detection using the Chain of Responsibility pattern with `ChainedAudioModeDetector` orchestrator. This will create a more flexible and extensible system for handling different audio detection strategies.

### 3. Decompose Monolithic Modules
Break down `wav_extractor_wave.py` and `pdf_extractor.py` into smaller, single-responsibility components. Each component will have a clear, focused purpose following the Single Responsibility Principle.

### 4. Final Cleanup and Hardening
Refine exception handling throughout the codebase and plan deprecation of legacy components. This includes replacing broad exception catches with specific exception types and establishing a clear migration path for deprecated functionality.

**Note**: This is marked as a non-breaking change focused purely on internal architecture improvements.

## Impact

### Affected Specs
- **analysis**: Requirements will be modified to reflect new architectural patterns and domain services
- **extraction**: Requirements will be updated to incorporate the new modular extraction components

### Affected Code
- `wav_extractor_wave.py` - Will be decomposed into smaller components
- `pdf_extractor.py` - Will be refactored following single responsibility principle
- `adapters/audio/fake_mode_detector.py` - Will use centralized filename parsing
- `adapters/filesystem/file_discovery.py` - Will return domain objects instead of primitive types
- `adapters/audio/wav_reader.py` - Will implement specific exception handling
- New domain services and orchestrators will be created

### User Experience
No visible changes to end users. All improvements are internal architectural enhancements.

### Dependencies
No new dependencies will be introduced. This refactoring works within the existing technology stack.

### Testing
The refactoring enables more isolated and robust unit testing by:
- Creating smaller, focused components that are easier to test in isolation
- Eliminating code duplication that previously required testing the same logic in multiple places
- Providing type-safe domain objects that make test setup and assertions clearer
- Implementing specific exception handling that allows for more precise testing of error conditions
``n
### openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\specs\analysis\spec.md

``n## MODIFIED Requirements

### Requirement: File Discovery and Pairing
The system SHALL discover PDF and ZIP files in configured directories and pair them by a numeric ID, returning a structured FilePair object for each match.

#### Scenario: Successful pairing
- **WHEN** PDF directory contains `12345_tracklist.pdf` and ZIP directory contains `12345_masters.zip`
- **THEN** the system creates a pair with ID `12345` (as `int`)
- **AND** the result for this ID is a `FilePair` object containing the `Path` objects for both files

#### Scenario: Ambiguous pairing
- **WHEN** multiple PDFs or ZIPs share the same numeric ID
- **THEN** the system logs a warning and skips the ambiguous pair

#### Scenario: Type-safe pairing structure
- **WHEN** `discover_and_pair_files()` returns paired files
- **THEN** the return type is `dict[int, FilePair]` instead of `dict[str, dict[str, Path]]`
- **AND** all ID keys are integers for consistent type handling
- **AND** each value is a `FilePair` dataclass with `pdf: Path` and `zip: Path` attributes

#### Scenario: No matches
- **WHEN** no PDF-ZIP pairs share numeric IDs
- **THEN** the system returns an empty pairs dictionary

### Requirement: Audio Mode Detection Port
The system SHALL use a port interface and a `Chain of Responsibility` pattern to isolate and orchestrate AI-based audio mode detection from domain logic.

#### Scenario: Chain of Responsibility orchestration
- **WHEN** the `AudioModeDetector` is invoked
- **THEN** it processes a sequence of detection strategies (e.g., strict parsing, AI fallback, deterministic fallback)
- **AND** each strategy attempts to resolve the side and position
- **AND** the process stops once a definitive result is found or all strategies are exhausted

#### Scenario: Centralized filename parsing
- **WHEN** strict parsing step needs to extract side and position from filename
- **THEN** it uses `StrictFilenameParser` domain service
- **AND** no duplicate parsing logic exists across adapters
- **AND** parsing behavior is consistent and testable in isolation

#### Scenario: Real AI adapter
- **WHEN** `AiAudioModeDetector` is instantiated
- **THEN** it acts as one step in the detection chain
- **AND** requires OpenAI/OpenRouter API credentials for its operation

#### Scenario: Fake test adapter
- **WHEN** `FakeAudioModeDetector` is instantiated
- **THEN** it uses a centralized, deterministic `StrictFilenameParser` for its logic
- **AND** guarantees consistent results for the same inputs
- **AND** contains no duplicate parsing implementation

#### Scenario: Port interface definition
- **WHEN** `AudioModeDetector` Protocol is defined
- **THEN** it specifies `detect(wavs: list[WavInfo]) -> dict[str, list[WavInfo]]` method
- **AND** output guarantees normalized positions (sequential 1, 2, 3... per side)
- **AND** output guarantees no gaps or duplicates in positions

#### Scenario: Service layer integration
- **WHEN** `AnalysisService` is constructed
- **THEN** it accepts `audio_mode_detector: AudioModeDetector | None` parameter
- **AND** defaults to `AiAudioModeDetector()` if not provided
- **AND** passes detector to `compare_data()` function

#### Scenario: Test integration
- **WHEN** tests verify comparison behavior
- **THEN** they use `FakeAudioModeDetector` via pytest fixture
- **AND** avoid external API calls for deterministic, fast execution
- **AND** can test different detection scenarios by configuring fake detector

#### Scenario: Detection via port
- **WHEN** the system needs to detect side and position from WAV filenames
- **THEN** it uses `AudioModeDetector` port from `core.ports`
- **AND** domain layer receives normalized results without knowing detection strategy
``n
### openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\specs\extraction\spec.md

``n# Extraction Capability Delta Specification

## Purpose
This delta specification defines MODIFIED and ADDED requirements for the extraction capability as part of the refactor-unified-audit-plan.

## MODIFIED Requirements

### Requirement: WAV File I/O Adapter
The system SHALL use an adapter layer to isolate ZIP and WAV file I/O operations from domain logic, with specific and narrowed exception handling.

#### Scenario: ZIP reading via adapter
- **WHEN** the system needs to extract WAV files from a ZIP archive
- **THEN** it uses `ZipWavFileReader` adapter from `adapters.audio.wav_reader`
- **AND** domain layer receives `list[WavInfo]` objects without performing I/O

#### Scenario: Adapter error handling
- **WHEN** a ZIP file is corrupted
- **THEN** the adapter catches a specific `zipfile.BadZipFile` exception
- **AND** logs an appropriate error message
- **AND** returns an empty list without crashing

#### Scenario: Specific exception types
- **WHEN** adapter encounters I/O errors during WAV extraction
- **THEN** it catches specific exceptions (`zipfile.BadZipFile`, `IOError`, `OSError`) instead of broad `Exception`
- **AND** each exception type is handled with appropriate logging and recovery
- **AND** no generic `except Exception` clauses exist in production code paths

## ADDED Requirements

### Requirement: PDF Extraction Module Decomposition
**ADDED:** The system SHALL decompose PDF extraction logic into single-responsibility components following adapter and domain service patterns.

#### Scenario: PDF rendering isolation
- **WHEN** the system needs to render PDF pages to images
- **THEN** it uses `PdfImageRenderer` adapter that encapsulates PyMuPDF operations
- **AND** rendering logic is isolated from VLM communication and parsing

#### Scenario: VLM client isolation
- **WHEN** the system needs to call Vision LLM API
- **THEN** it uses `VlmClient` adapter that encapsulates API communication
- **AND** API logic is isolated from rendering and parsing

#### Scenario: Tracklist parsing isolation
- **WHEN** the system needs to parse and consolidate track data from VLM response
- **THEN** it uses `TracklistParser` domain service
- **AND** parsing logic is isolated from I/O operations
- **AND** parser is testable with mock VLM responses
``n
### openspec\changes\archive\2025-10-24-refactor-unified-audit-plan\tasks.md

``n# Implementační Checklist - Refaktor Unified Audit Plan

## Krok 1: Vytvoření Základních Stavebních Bloků (Vysoká priorita)

- [x] **1.1: Refaktorovat Parsování Názvů Souborů**
  - [x] 1.1.1 Vytvořit třídu `StrictFilenameParser` (doménová služba) pro centralizaci logiky parsování `side` a `position`
  - [x] 1.1.2 Nahradit logiku v `FakeAudioModeDetector` (method `_parse_filename`) a `wav_extractor_wave.py` (function `strict_from_path`) voláním této nové třídy
  - [x] 1.1.3 Odstranit magická čísla (např. 999 v `fake_mode_detector.py` lines 58, 118) a nahradit je pojmenovanými konstantami

- [x] **1.2: Zavést Doménové Objekty pro Párování Souborů**
  - [x] 1.2.1 Vytvořit `@dataclass class FilePair: pdf: Path; zip: Path` v `core/domain/` nebo `core/models/`
  - [x] 1.2.2 Upravit funkci `discover_and_pair_files` v `adapters/filesystem/file_discovery.py`, aby vracela `dict[int, FilePair]` místo `dict[str, dict[str, Path]]`
  - [x] 1.2.3 Zajistit konzistentní použití `int` pro ID v celém procesu párování (aktuálně používá string klíče na line 75)

## Krok 2: Implementace Architektonických Vzorů (Vysoká priorita)

- [x] **2.1: Implementovat Chain of Responsibility pro Detekci Režimu Audia**
  - [x] 2.1.1 Vytvořit orchestrátor `ChainedAudioModeDetector`, který přijímá seznam detekčních kroků
  - [x] 2.1.2 Definovat společný protokol/rozhraní pro každý krok řetězu (např. `DetectionStep` Protocol)
  - [x] 2.1.3 Implementovat jednotlivé kroky:
    - `StrictParserStep`: Používá `StrictFilenameParser` z kroku 1.1
    - `AiParserStep`: Obaluje logiku z `wav_extractor_wave.py` functions `ai_parse_batch` a `merge_ai_results`
    - `DeterministicFallbackStep`: Obaluje logiku z `wav_extractor_wave.py` function `_fallback_assign_when_all_unknown`
  - [x] 2.1.4 Integrovat `ChainedAudioModeDetector` do `AnalysisService` jako výchozí implementaci `AudioModeDetector` portu z `core/ports.py`

## Krok 3: Dekompozice Monolitických Modulů (Střední priorita)

- [ ] **3.1: Rozdělit `wav_extractor_wave.py`**
  - [x] 3.1.1 Přesunout logiku parsování do `StrictFilenameParser` (viz 1.1)
  - [x] 3.1.2 Přesunout logiku volání AI do `AiParserStep` (viz 2.1.3)
  - [x] 3.1.3 Přesunout normalizační logiku (function `normalize_positions`) do orchestrátoru nebo samostatné utility
  - [x] 3.1.4 Deprecate/odstranit `wav_extractor_wave.py` a nahradit všechny jeho použití novou architekturou

- [x] **3.2: Rozdělit `pdf_extractor.py`**
  - [x] 3.2.1 Vytvořit `PdfImageRenderer` (adapter pro PyMuPDF) - obaluje function `_render_pdf_to_images`
  - [x] 3.2.2 Vytvořit `VlmClient` (adapter pro VLM API) - obaluje functions `_call_vlm_json` a `_to_data_url`
  - [x] 3.2.3 Vytvořit `TracklistParser` (doménová služba pro parsování JSONu) - obaluje function `_consolidate_and_parse_tracks`
  - [x] 3.2.4 Nahradit stávající funkce v `pdf_extractor.py` orchestrací těchto nových tříd v function `extract_pdf_tracklist`

## Krok 4: Finální Vyčištění a Zpevnění (Nízká priorita)

- [x] **4.1: Zpřesnit Zpracování Výjimek**
  - [x] 4.1.1 Projít `ZipWavFileReader` v `adapters/audio/wav_reader.py`
  - [x] 4.1.2 Nahradit `except Exception:` (lines 71, 78) specifickými výjimkami (`zipfile.BadZipFile`, `IOError`, `OSError`)

- [ ] **4.2: Plánované Odstranění `fluent_gui.py`**
  - [x] 4.2.1 Vytvořit ticket v projektovém managementu pro budoucí odstranění `fluent_gui.py` (pokud je stále relevantní)  
        (Ticket: docs/pm/fluent_gui-removal.md)
  - [x] 4.2.2 Ověřit, že deprecation notice v souboru je stále platná a srozumitelná
``n
### openspec\project.md

``n# Project Context

## Purpose
- Desktop tool to extract vinyl release tracklists from PDF cue sheets using a Vision LLM, compare them with mastered WAV durations, and surface mismatches in a "Final Cue Sheet Checker" GUI.
- Produces per-side summaries and optional JSON exports to aid mastering/QA before release.

## Tech Stack
- Language: Python 3.11 (CPython)
- GUI: PyQt6 (pure Qt6 widgets)
- Imaging/PDF: PyMuPDF (`fitz`), Pillow (`PIL`)
- LLM client: OpenRouter (preferred) and OpenAI via `openai` package
- Configuration: QSettings (platform-native persistence via settings.json) with optional .env
- Tooling: `black` (format), `ruff` (lint), `mypy` (types), `pytest` (tests)

## Project Conventions

### Code Style
- Follow PEP 8; prefer explicit, descriptive names.
- Format with `black` (default settings). Lint with `ruff` before commit.
- Type hints required in new/modified code; run `mypy` locally.
- Avoid I/O in pure logic functions; keep extractors deterministic and testable.
- Logging over prints for operational messages; user-facing feedback via GUI components.

### Architecture Patterns
- Single-process desktop app with clear separation of concerns:
  - `fluent_gui.py`: Main window and presentation logic (tables, theme, actions).
  Note: The UI relies on standard PyQt6 widgets. Custom components like `FolderSettingCard` in `settings_page.py` are built on this foundation without additional GUI frameworks.
  - `settings_page.py`: Settings UI backed by `QSettings` groups/keys defined in `config.py`.
  - `config.py`: Centralized configuration schema and defaults (LLM, image render, UI, analysis tolerances, paths).
  - `pdf_extractor.py`: PDF rendering (PyMuPDF) and Vision LLM JSON extraction; consolidates tracks by side.
  - `wav_extractor_wave.py`: Reads WAV durations from ZIPs; infers `side`/`position` strictly from filenames, then AI fallback, then deterministic fallback; normalizes positions and emits JSON-ready payloads.
- Environment and secrets via `.env` (loaded early) and `settings.json` (persisted app config).
- Keep AI calls isolated and mockable; prefer pure transformation helpers around them.

### Testing Strategy
- Framework: `pytest` (see `requirements.txt`).
- Unit tests focus on pure logic:
  - PDF track consolidation and time parsing in `pdf_extractor.py` (mock LLM responses).
  - WAV filename parsing, strict inference, normalization in `wav_extractor_wave.py`.
- Do not hit external LLMs in tests; mock `OpenAI` client or guard with env flags.
- Optional smoke tests for GUI construction (no rendering assertions) to catch import regressions.

### Git Workflow
- Feature branches off `main`; small, focused PRs.
- Require passing lint/format/type checks (`ruff`, `black`, `mypy`) before merge.
- Commit messages: concise, imperative (optionally Conventional Commits for clarity).

## Domain Context
- Track identification is anchored by a parsable duration (e.g., `MM:SS`). Titles are the meaningful text visually associated with that duration; multi-line titles should be combined.
- Side context comes from headers like `Side A`, `SIDE B` or filename patterns such as `A1`, `AA02`. Positions reset per side.
- Non-tracks (notes, totals, ISRCs, credits) must be ignored.
- WAV masters are provided in ZIPs; durations are computed from audio data and used to validate the PDF cue sheet.
- Analysis tolerances are configurable: soft warning (`analysis.tolerance_warn`) and hard failure (`analysis.tolerance_fail`).

## Important Constraints
- Privacy: PDF page images and filenames may be sent to external LLMs. Obtain consent and avoid sending sensitive content.
- Determinism: Parsing/normalization logic should remain deterministic; AI is a best-effort helper with strict JSON outputs and must be optional.
- Platform: Primary development environment is Windows (Fluent look-and-feel); keep code portable where feasible.
- Performance: Prefer single-pass parsing and avoid heavy image operations; render PDF pages at configured DPI only once per page.

## External Dependencies
- OpenRouter API (preferred) and/or OpenAI API via `openai` client.
  - Environment: `OPENROUTER_API_KEY` (preferred), `OPENAI_API_KEY` (optional); optional `OPENROUTER_MODEL`, `OPENAI_MODEL`.
  - Base URL defaults to `https://openrouter.ai/api/v1`.
- PyMuPDF (`fitz`) for PDF rendering; Pillow for image conversion.
- PyQt6 for UI and configuration storage.
- Configuration files and paths:
  - App config file: `settings.json` (persisted by `QSettings`).
  - Input folders: `input.pdf_dir`, `input.wav_dir` (set in `settings.json`).
  - Exports folder: `export.default_dir` for generated reports.

``n
### openspec\specs\analysis\spec.md

``n# analysis Specification

## Purpose
Defines expected behavior, interfaces, and stability rules for the respective module.
## Requirements
### Requirement: File Discovery and Pairing
The system SHALL discover PDF and ZIP files in configured directories and pair them by a numeric ID, returning a structured FilePair object for each match.

#### Scenario: Successful pairing
- **WHEN** PDF directory contains `12345_tracklist.pdf` and ZIP directory contains `12345_masters.zip`
- **THEN** the system creates a pair with ID `12345` (as `int`)
- **AND** the result for this ID is a `FilePair` object containing the `Path` objects for both files

#### Scenario: Ambiguous pairing
- **WHEN** multiple PDFs or ZIPs share the same numeric ID
- **THEN** the system logs a warning and skips the ambiguous pair

#### Scenario: Type-safe pairing structure
- **WHEN** `discover_and_pair_files()` returns paired files
- **THEN** the return type is `dict[int, FilePair]` instead of `dict[str, dict[str, Path]]`
- **AND** all ID keys are integers for consistent type handling
- **AND** each value is a `FilePair` dataclass with `pdf: Path` and `zip: Path` attributes

#### Scenario: No matches
- **WHEN** no PDF-ZIP pairs share numeric IDs
- **THEN** the system returns an empty pairs dictionary

### Requirement: Numeric ID Extraction
The system SHALL extract numeric IDs from filenames using injected ID extraction settings that specify digit length and ignore list constraints.

#### Scenario: ID filtering by length
- **WHEN** filename is "test_12345_master.zip" and min_digits=3, max_digits=6
- **THEN** the system extracts ID 12345

#### Scenario: Ignored numbers
- **WHEN** filename contains "2024" and ignore_numbers includes "2024"
- **THEN** the system excludes 2024 from extracted IDs

#### Scenario: Injected ID extraction settings
- **WHEN** different `IdExtractionSettings` objects are supplied to `extract_numeric_id()`
- **THEN** the function filters IDs according to those settings
- **AND** behavior remains deterministic without relying on global config

### Requirement: Track Comparison
The system SHALL compare PDF tracklist durations with WAV file durations using injected tolerance settings and audio mode detector together with strongly-typed Pydantic models and classify mismatches based on configurable tolerances.

#### Scenario: Perfect match
- **WHEN** PDF track duration is 240s and WAV duration is 240.1s
- **THEN** the system classifies as "OK" (within tolerance)

#### Scenario: Warning threshold
- **WHEN** difference exceeds tolerance_warn (2s) but below tolerance_fail (5s)
- **THEN** the system classifies as "WARN"

#### Scenario: Failure threshold
- **WHEN** difference exceeds tolerance_fail (5s)
- **THEN** the system classifies as "FAIL"

#### Scenario: Type-safe model handling
- **WHEN** `compare_data()` receives `TrackInfo` and `WavInfo` Pydantic models
- **THEN** the system constructs `SideResult` with model instances directly
- **AND** no dictionary conversion or type casting occurs

#### Scenario: Injected tolerance settings
- **WHEN** `compare_data()` is called with `ToleranceSettings(warn_tolerance=2, fail_tolerance=5)`
- **THEN** the provided thresholds drive warning and failure classification
- **AND** no global configuration is accessed inside the function

#### Scenario: Injected audio mode detector
- **WHEN** `compare_data()` is called with `audio_mode_detector` parameter
- **THEN** the system uses the provided detector for side/position detection
- **AND** no direct imports from `wav_extractor_wave` occur
- **AND** detection strategy can be swapped without changing domain code

#### Scenario: Detector returns normalized results
- **WHEN** detector processes WAV files
- **THEN** returned `dict[str, list[WavInfo]]` has normalized positions per side
- **AND** positions are sequential (1, 2, 3...) with no gaps
- **AND** domain layer does not need to perform additional normalization

### Requirement: Code Quality Standards
The system SHALL maintain zero unreachable code and pass strict type checking.

#### Scenario: No dead code
- **WHEN** static analysis tools scan the codebase
- **THEN** no unreachable statements are detected
- **AND** all code paths are executable

#### Scenario: Strict type checking
- **WHEN** mypy runs with --strict flag
- **THEN** all type annotations are valid
- **AND** no type: ignore comments are needed for core domain logic

### Requirement: Configuration Dependency Injection
The system SHALL inject configuration settings as explicit parameters to domain and adapter functions instead of accessing global state.

#### Scenario: Domain layer purity
- **WHEN** domain functions in `core/domain/` are invoked
- **THEN** all configuration is received via function parameters
- **AND** no global `cfg` imports exist in domain layer

#### Scenario: Adapter layer purity
- **WHEN** adapter functions in `adapters/` are invoked
- **THEN** all configuration is received via function parameters
- **AND** no global `cfg` imports exist in adapter layer

#### Scenario: Entry point responsibility
- **WHEN** application entry points (`app.py`, `fluent_gui.py`) start
- **THEN** they load configuration from global `cfg`
- **AND** construct settings dataclasses
- **AND** inject settings into lower layers

### Requirement: Audio Mode Detection Port
The system SHALL use a port interface and a `Chain of Responsibility` pattern to isolate and orchestrate AI-based audio mode detection from domain logic.

#### Scenario: Chain of Responsibility orchestration
- **WHEN** the `AudioModeDetector` is invoked
- **THEN** it processes a sequence of detection strategies (e.g., strict parsing, AI fallback, deterministic fallback)
- **AND** each strategy attempts to resolve the side and position
- **AND** the process stops once a definitive result is found or all strategies are exhausted

#### Scenario: Centralized filename parsing
- **WHEN** strict parsing step needs to extract side and position from filename
- **THEN** it uses `StrictFilenameParser` domain service
- **AND** no duplicate parsing logic exists across adapters
- **AND** parsing behavior is consistent and testable in isolation

#### Scenario: Real AI adapter
- **WHEN** `AiAudioModeDetector` is instantiated
- **THEN** it acts as one step in the detection chain
- **AND** requires OpenAI/OpenRouter API credentials for its operation

#### Scenario: Fake test adapter
- **WHEN** `FakeAudioModeDetector` is instantiated
- **THEN** it uses a centralized, deterministic `StrictFilenameParser` for its logic
- **AND** guarantees consistent results for the same inputs
- **AND** contains no duplicate parsing implementation

#### Scenario: Port interface definition
- **WHEN** `AudioModeDetector` Protocol is defined
- **THEN** it specifies `detect(wavs: list[WavInfo]) -> dict[str, list[WavInfo]]` method
- **AND** output guarantees normalized positions (sequential 1, 2, 3... per side)
- **AND** output guarantees no gaps or duplicates in positions

#### Scenario: Service layer integration
- **WHEN** `AnalysisService` is constructed
- **THEN** it accepts `audio_mode_detector: AudioModeDetector | None` parameter
- **AND** defaults to `AiAudioModeDetector()` if not provided
- **AND** passes detector to `compare_data()` function

#### Scenario: Test integration
- **WHEN** tests verify comparison behavior
- **THEN** they use `FakeAudioModeDetector` via pytest fixture
- **AND** avoid external API calls for deterministic, fast execution
- **AND** can test different detection scenarios by configuring fake detector

#### Scenario: Detection via port
- **WHEN** the system needs to detect side and position from WAV filenames
- **THEN** it uses `AudioModeDetector` port from `core.ports`
- **AND** domain layer receives normalized results without knowing detection strategy

### Requirement: Complete Domain Layer Purity
The system SHALL maintain domain layer completely free of infrastructure dependencies including AI services.

#### Scenario: No AI imports in domain
- **WHEN** domain modules in `core/domain/` are inspected
- **THEN** they contain no imports from `wav_extractor_wave` or AI libraries
- **AND** all AI detection is delegated to adapter layer via port interface

#### Scenario: Domain depends on abstractions
- **WHEN** `compare_data()` function needs audio mode detection
- **THEN** it receives `AudioModeDetector` port via parameter
- **AND** calls `detector.detect(wavs)` without knowing implementation
- **AND** remains testable with any detector implementation

#### Scenario: No module-level infrastructure
- **WHEN** domain modules are loaded
- **THEN** they contain no module-level variables referencing infrastructure
- **AND** no module-level function casts to external implementations
- **AND** all dependencies are explicit via function parameters


``n
### openspec\specs\export\spec.md

``n# export Specification

## Purpose
Defines expected behavior, interfaces, and stability rules for the respective module.
## Requirements
### Requirement: Auto Export Analysis Results
The system SHALL automatically export analysis results to JSON after each analysis run when `export.auto` is true, using the centralized export service.

#### Scenario: Success
- WHEN an analysis run completes with one or more `SideResult` items
- AND `export.auto` is true
- THEN the app calls `export_results_to_json()` from `services.export_service`
- AND writes a JSON file to `export.default_dir`
- AND the filename matches `analysis_YYYYMMDD_HHMMSS.json`
- AND each `SideResult` entry contains string paths and numeric durations

#### Scenario: Disabled
- GIVEN `export.auto` is false
- WHEN an analysis run completes
- THEN no JSON export is written

#### Scenario: Directory Creation
- GIVEN `export.default_dir` does not exist
- WHEN an analysis run completes and export is enabled
- THEN the directory is created automatically
- AND the JSON export is written

#### Scenario: Write Failure
- GIVEN the app cannot write to `export.default_dir`
- WHEN an analysis run completes and export is enabled
- THEN the app logs an error and continues without crashing

#### Scenario: Injected export settings
- **WHEN** `ExportSettings(auto_export=True, export_dir=Path("exports"))` is provided
- **THEN** export decisions rely solely on the injected settings object
- **AND** no global configuration is accessed during export

#### Scenario: Service layer usage
- **WHEN** UI layer needs to export results
- **THEN** it imports `export_results_to_json` from `services.export_service`
- **AND** passes `results` and `export_settings` parameters
- **AND** receives `Optional[Path]` return value (exported file path or None)

### Requirement: Golden Output Generation
The system SHALL support generating reference JSON outputs for regression testing.

#### Scenario: Comparison result serialization
- **WHEN** `SideResult` objects are serialized to JSON
- **THEN** all fields are properly converted to JSON-compatible types
- **AND** Path objects are converted to strings
- **AND** Pydantic models are serialized with their schema

#### Scenario: Golden file storage
- **WHEN** characterization tests run in record mode
- **THEN** current outputs are saved to `tests/data/golden/` directory
- **AND** subsequent test runs compare against these references

#### Scenario: Floating-point tolerance
- **WHEN** comparing golden outputs with current results
- **THEN** duration fields allow small floating-point differences (≤0.01s)
- **AND** integer fields require exact matches

### Requirement: Export Settings Dataclass
The system SHALL use `ExportSettings` dataclass to encapsulate export configuration.

#### Scenario: Settings construction
- **WHEN** entry point loads configuration
- **THEN** it constructs `ExportSettings(auto_export=bool, export_dir=Path)` from global config
- **AND** passes settings to export service

#### Scenario: Settings validation
- **WHEN** `ExportSettings` is constructed with invalid values
- **THEN** validation occurs at construction time
- **AND** errors are caught early in entry point

### Requirement: Centralized Export Service
The system SHALL provide export functionality exclusively through `services.export_service` module as the single source of truth.

#### Scenario: Canonical import path
- **WHEN** code needs to export analysis results
- **THEN** it imports `export_results_to_json` from `services.export_service`
- **AND** no other modules provide export functionality

#### Scenario: UI layer integration
- **WHEN** UI components need to export results
- **THEN** they import from `services.export_service` directly
- **AND** do not use wrapper functions or indirect imports

#### Scenario: Test integration
- **WHEN** tests verify export functionality
- **THEN** they import from `services.export_service` directly
- **AND** test the canonical implementation, not wrappers

#### Scenario: No duplicate implementations
- **WHEN** searching codebase for export implementations
- **THEN** only `services/export_service.py` contains export logic
- **AND** no wrapper functions or duplicates exist in other modules

### Requirement: Export Service Documentation
The system SHALL document `services.export_service` as the authoritative export implementation.

#### Scenario: Module docstring clarity
- **WHEN** developers read `services/export_service.py` module docstring
- **THEN** it clearly states this is the single source of truth for exports
- **AND** provides guidance on correct import path

#### Scenario: Function docstring with usage example
- **WHEN** developers read `export_results_to_json()` docstring
- **THEN** it includes usage example showing correct import
- **AND** explains this is the canonical implementation


``n
### openspec\specs\extraction\spec.md

``n# extraction Specification

## Purpose
Defines expected behavior, interfaces, and stability rules for the respective module.
## Requirements
### Requirement: PDF Tracklist Extraction
The system SHALL extract track information from PDF cue sheets using Vision LLM and consolidate by side.

#### Scenario: Multi-page PDF extraction
- **WHEN** PDF contains multiple pages with track listings
- **THEN** the system renders each page, sends to LLM, and consolidates tracks by side

#### Scenario: Side detection
- **WHEN** PDF contains headers like "Side A" or "SIDE B"
- **THEN** the system correctly assigns tracks to their respective sides

### Requirement: WAV Duration Extraction
The system SHALL extract WAV file durations from ZIP archives using adapter layer that encapsulates wave module and soundfile fallback logic.

#### Scenario: Standard WAV extraction
- **WHEN** ZIP contains valid WAV files
- **THEN** the system reads frame count and sample rate to calculate duration

#### Scenario: Corrupted WAV fallback
- **WHEN** wave module fails to read WAV header
- **THEN** the system attempts soundfile extraction via temporary file

#### Scenario: Side inference from filename
- **WHEN** WAV filename is "A1_track.wav"
- **THEN** the system infers side="A" and position=1

#### Scenario: Adapter-based extraction
- **WHEN** `ZipWavFileReader.read_wav_files()` is called with ZIP path
- **THEN** the adapter opens ZIP, extracts WAV files to temporary directory
- **AND** probes each WAV using `get_wav_duration` from `audio_utils`
- **AND** returns `list[WavInfo]` with filename and duration_sec populated
- **AND** cleans up temporary files automatically

#### Scenario: Service layer integration
- **WHEN** `AnalysisService` processes a PDF-ZIP pair
- **THEN** it uses `ZipWavFileReader` instance to extract WAV metadata
- **AND** passes resulting `list[WavInfo]` to domain comparison logic
- **AND** domain layer performs no file I/O operations

### Requirement: Audio Mode Detection
The system SHALL detect audio mode (stereo/mono) from WAV files with AI fallback.

#### Scenario: Stereo detection
- **WHEN** WAV file has 2 channels
- **THEN** the system reports mode as "stereo"

#### Scenario: Mono detection
- **WHEN** WAV file has 1 channel
- **THEN** the system reports mode as "mono"

### Requirement: Behavior Characterization
The system SHALL maintain consistent extraction behavior verified by golden reference outputs.

#### Scenario: PDF extraction consistency
- **WHEN** the same PDF cue sheet is processed multiple times
- **THEN** extracted track data matches golden JSON reference
- **AND** side assignments, positions, and durations remain stable

#### Scenario: WAV extraction consistency
- **WHEN** the same ZIP archive is processed multiple times
- **THEN** extracted WAV metadata matches golden JSON reference
- **AND** duration calculations remain deterministic

#### Scenario: Pairing consistency
- **WHEN** PDF and ZIP files are discovered and paired
- **THEN** pairing results match golden reference
- **AND** numeric ID extraction follows configured rules consistently

### Requirement: Settings Propagation in Extraction Pipeline
The system SHALL propagate configuration settings through the extraction pipeline from entry points to domain functions.

#### Scenario: Worker receives settings
- **WHEN** `AnalysisWorker` is constructed
- **THEN** it receives `ToleranceSettings` and `IdExtractionSettings` as constructor parameters
- **AND** stores them for use during analysis

#### Scenario: Settings passed to file discovery
- **WHEN** worker calls `discover_and_pair_files()`
- **THEN** it passes `IdExtractionSettings` as parameter
- **AND** file discovery uses injected settings for ID extraction

#### Scenario: Settings passed to comparison
- **WHEN** worker calls `compare_data()`
- **THEN** it passes `ToleranceSettings` as parameter
- **AND** comparison uses injected settings for threshold classification

#### Scenario: No global config in extraction flow
- **WHEN** extraction pipeline executes from file discovery through comparison
- **THEN** no function accesses global `cfg` object
- **AND** all configuration flows through explicit parameters

### Requirement: WAV File I/O Adapter
The system SHALL use an adapter layer to isolate ZIP and WAV file I/O operations from domain logic, with specific and narrowed exception handling.

#### Scenario: ZIP reading via adapter
- **WHEN** the system needs to extract WAV files from a ZIP archive
- **THEN** it uses `ZipWavFileReader` adapter from `adapters.audio.wav_reader`
- **AND** domain layer receives `list[WavInfo]` objects without performing I/O

#### Scenario: Adapter error handling
- **WHEN** a ZIP file is corrupted
- **THEN** the adapter catches a specific `zipfile.BadZipFile` exception
- **AND** logs an appropriate error message
- **AND** returns an empty list without crashing

#### Scenario: Specific exception types
- **WHEN** adapter encounters I/O errors during WAV extraction
- **THEN** it catches specific exceptions (`zipfile.BadZipFile`, `IOError`, `OSError`) instead of broad `Exception`
- **AND** each exception type is handled with appropriate logging and recovery
- **AND** no generic `except Exception` clauses exist in production code paths

### Requirement: Domain Layer Purity
The system SHALL maintain domain layer free of file I/O operations and infrastructure dependencies.

#### Scenario: No I/O imports in domain
- **WHEN** domain modules in `core/domain/` are inspected
- **THEN** they contain no imports of `zipfile`, `tempfile`, `shutil`, `os.path`, or `open()`
- **AND** all file operations are delegated to adapter layer

#### Scenario: Domain receives data objects
- **WHEN** domain functions need WAV metadata
- **THEN** they receive `WavInfo` objects from adapters
- **AND** do not access file system directly
- **AND** remain testable without real files

#### Scenario: Adapter instantiation at service layer
- **WHEN** service layer orchestrates extraction workflow
- **THEN** it instantiates `ZipWavFileReader` adapter
- **AND** passes results to domain functions
- **AND** domain functions remain pure and side-effect free

### Requirement: PDF Extraction Module Decomposition
**ADDED:** The system SHALL decompose PDF extraction logic into single-responsibility components following adapter and domain service patterns.

#### Scenario: PDF rendering isolation
- **WHEN** the system needs to render PDF pages to images
- **THEN** it uses `PdfImageRenderer` adapter that encapsulates PyMuPDF operations
- **AND** rendering logic is isolated from VLM communication and parsing

#### Scenario: VLM client isolation
- **WHEN** the system needs to call Vision LLM API
- **THEN** it uses `VlmClient` adapter that encapsulates API communication
- **AND** API logic is isolated from rendering and parsing

#### Scenario: Tracklist parsing isolation
- **WHEN** the system needs to parse and consolidate track data from VLM response
- **THEN** it uses `TracklistParser` domain service
- **AND** parsing logic is isolated from I/O operations
- **AND** parser is testable with mock VLM responses


``n
### openspec\specs\ui\spec.md

``n# UI Specification

## Purpose
Define the UI behavior and structure for the desktop application, including main window, controls, themes, status feedback, and table interactions.
## Requirements
### Requirement: Main Window Interface
The application SHALL provide a main window using pure PyQt6 components (QMainWindow, QTableView, QPushButton) with GZ Media branding and intuitive controls for cue sheet analysis. The UI SHALL be organized into modular, reusable components within a `ui/` package structure with dependency injection for configuration and services.

#### Scenario: Application startup
- **WHEN** the application starts
- **THEN** it displays the main window with GZ Media logo, control buttons, and dual table layout using standard PyQt6 widgets
- **AND** the UI components are loaded from modular packages (`ui.models`, `ui.workers`, `ui.dialogs`, `ui.main_window`)
- **AND** all components receive their dependencies via constructor injection

#### Scenario: Component reusability
- **WHEN** a developer needs to modify or test a UI component
- **THEN** they can work with isolated modules (e.g., `ResultsTableModel`, `AnalysisWorker`) without touching unrelated code
- **AND** each component has clear dependencies and can be unit tested independently with mock dependencies

#### Scenario: File opening
- **WHEN** user clicks on PDF or ZIP file icons in the top table
- **THEN** the corresponding file opens in the default system application

### Requirement: File Analysis Controls
The application SHALL provide controls for running analysis via a service layer that orchestrates domain operations, with worker lifecycle managed by a dedicated manager.

#### Scenario: Analysis execution
- **WHEN** user clicks "Run analysis" button
- **THEN** the MainWindow delegates to `AnalysisWorkerManager` which creates and manages the worker thread
- **AND** the worker invokes `AnalysisService` which coordinates file discovery, extraction, and comparison

#### Scenario: Progress reporting
- **WHEN** analysis is running
- **THEN** the worker manager forwards progress signals from the service to the GUI
- **AND** the GUI updates the status bar and progress indicator

#### Scenario: Worker cleanup
- **WHEN** analysis completes or the window closes
- **THEN** the worker manager safely terminates the worker thread and cleans up resources
- **AND** no memory leaks or zombie threads remain

### Requirement: Theme Management
The application SHALL support light, dark, and auto themes with GZ Media branding colors.

#### Scenario: Theme switching
- **WHEN** user selects a theme from the dropdown
- **THEN** the application applies the selected theme and saves the preference

### Requirement: Status Feedback
The application SHALL provide clear status information during operations.

#### Scenario: Operation status
- **WHEN** analysis is running or completed
- **THEN** the status bar shows current operation and results

### Requirement: Table Interactions
The application SHALL provide interactive tables for browsing analysis results.

#### Scenario: Waveform viewer opens for files in ZIP subdirectories
- **WHEN** user clicks the "View" button for a WAV file located in a subdirectory of a ZIP archive
- **THEN** the `WaveformEditorDialog` opens successfully
- **AND** the correct WAV file is extracted and displayed without a `FileNotFoundError`

### Requirement: Settings Management
The application SHALL provide a settings interface using custom PyQt6 components and QSettings for persistence.

#### Scenario: Settings dialog display
- **WHEN** user opens settings
- **THEN** the application displays a settings page with custom `FolderSettingCard` widgets implemented in pure PyQt6

#### Scenario: Settings persistence
- **WHEN** user saves settings
- **THEN** configuration is persisted via QSettings to the platform-specific location

### Requirement: Dependency Injection Architecture
The UI layer SHALL use dependency injection for all configuration and service dependencies, eliminating direct imports of global configuration objects.

#### Scenario: Configuration injection
- **WHEN** a UI component needs configuration values
- **THEN** it receives a specific configuration object (e.g., `ToleranceSettings`, `ExportSettings`) via constructor parameter
- **AND** the component does not directly import or access global `config.cfg`

#### Scenario: Service injection
- **WHEN** MainWindow needs worker management
- **THEN** it receives an `AnalysisWorkerManager` instance via constructor
- **AND** the MainWindow does not directly create or manage QThread instances

#### Scenario: Testability with mocks
- **WHEN** a developer writes unit tests for a UI component
- **THEN** they can inject mock configuration and service objects
- **AND** the component can be tested in isolation without global state

### Requirement: Configuration Abstractions
The application SHALL provide typed configuration models that represent specific subsets of configuration needed by components.

#### Scenario: Tolerance settings
- **WHEN** TracksTableModel needs tolerance values for match calculation
- **THEN** it receives a `ToleranceSettings` object with `warn_tolerance` and `fail_tolerance` fields
- **AND** the model uses these values without accessing global configuration

#### Scenario: Export settings
- **WHEN** ExportService needs to determine export behavior
- **THEN** it receives an `ExportSettings` object with `auto_export` and `export_dir` fields
- **AND** uses the injected settings for export behavior
- **AND** returns the export path to the UI for status display

#### Scenario: Theme settings
- **WHEN** ResultsTableModel needs status colors
- **THEN** it receives a `ThemeSettings` object with `status_colors` dictionary
- **AND** the model uses these colors for cell background rendering

### Requirement: Worker Lifecycle Management
The application SHALL encapsulate all worker and thread lifecycle management in a dedicated manager class, separating this concern from the main window.

#### Scenario: Worker creation
- **WHEN** analysis needs to start
- **THEN** AnalysisWorkerManager creates a new QThread and AnalysisWorker
- **AND** connects all necessary signals
- **AND** starts the thread

#### Scenario: Worker monitoring
- **WHEN** the UI needs to check if analysis is running
- **THEN** it queries `worker_manager.is_running()`
- **AND** receives accurate state without accessing thread internals

#### Scenario: Worker termination
- **WHEN** analysis completes or user closes the window
- **THEN** AnalysisWorkerManager safely stops the worker
- **AND** waits for thread completion with timeout
- **AND** cleans up all resources

### Requirement: Modular UI Architecture
The UI layer SHALL be organized into separate packages for models, workers, dialogs, and utilities, with each module having a single, well-defined responsibility.

#### Scenario: Table model isolation
- **WHEN** the results table needs modification
- **THEN** developers work only with `ui/models/results_table_model.py`
- **AND** changes do not affect other UI components

#### Scenario: Worker thread isolation
- **WHEN** analysis threading logic needs updates
- **THEN** developers work only with `ui/workers/analysis_worker.py` or `ui/workers/worker_manager.py`
- **AND** the worker can be tested independently with mock services

#### Scenario: Theme management
- **WHEN** GZ Media branding needs updates
- **THEN** developers modify only `ui/theme.py`
- **AND** theme changes apply consistently across all UI components

#### Scenario: Constants centralization
- **WHEN** UI strings or constants need updates
- **THEN** developers modify only `ui/constants.py`
- **AND** changes propagate to all components that import them

### Requirement: Export Service Separation
Export functionality SHALL be moved from the presentation layer to the service layer with dependency injection for configuration.

#### Scenario: JSON export with injected settings
- **WHEN** analysis results need to be exported
- **THEN** the `export_results_to_json` function in `services/export_service.py` receives results and `ExportSettings`
- **AND** uses the injected settings for export behavior
- **AND** returns the export path to the UI for status display

#### Scenario: Export configuration
- **WHEN** auto-export is enabled in settings
- **THEN** the export service checks `export_settings.auto_export`
- **AND** creates timestamped JSON files in `export_settings.export_dir`

### Requirement: Parametrized Application Entry Point
The application SHALL support flexible configuration paths via parameters and environment variables.

#### Scenario: Default configuration
- **WHEN** the application starts without parameters
- **THEN** it loads configuration from default `settings.json` path
- **AND** initializes all components with loaded settings

#### Scenario: Custom configuration path
- **WHEN** the application is started with `main(config_path=Path('custom.json'))`
- **THEN** it loads configuration from the specified path
- **AND** initializes all components with custom settings

#### Scenario: Environment variable configuration
- **WHEN** `TRACKLIST_CONFIG` environment variable is set
- **THEN** the application uses that path for configuration
- **AND** overrides the default path

### Requirement: Backward Compatibility
The refactored codebase SHALL maintain backward compatibility with existing imports from `fluent_gui.py` through a compatibility wrapper.

#### Scenario: Legacy imports
- **WHEN** existing code imports classes from `fluent_gui`
- **THEN** the imports continue to work via the compatibility wrapper
- **AND** wrapper functions handle global config access for legacy callers

#### Scenario: Entry point compatibility
- **WHEN** the application is started via `python fluent_gui.py`
- **THEN** it launches correctly by delegating to `app.main()`
- **AND** the behavior is identical to running `python app.py`

#### Scenario: Characterization test validation
- **WHEN** characterization tests run against the refactored code
- **THEN** all tests pass with identical behavior to pre-refactoring baseline
- **AND** all previously exported symbols remain accessible

### Requirement: Explicit Package Exports
The `ui` package SHALL explicitly define its public API through `__init__.py` with clear exports and `__all__` definition.

#### Scenario: Public API definition
- **WHEN** a developer imports from `ui` package
- **THEN** they have access to all public classes and functions listed in `__all__`
- **AND** the imports are explicit and documented

#### Scenario: IDE autocomplete support
- **WHEN** a developer types `from ui import`
- **THEN** their IDE shows all available exports from `__all__`
- **AND** provides accurate type hints for imported symbols

### Requirement: Custom Iconography
The application SHALL use custom SVG icons for key status indicators and actions to ensure visual consistency, brand alignment, and cross-platform compatibility.

#### Scenario: Consistent Match symbols
- **WHEN** the tracks table is displayed
- **THEN** the "Match" column (column 6) SHALL render a custom green SVG checkmark icon for successful matches
- **AND** SHALL render a custom red SVG cross icon for failed matches
- **AND** SHALL NOT display text symbols like '✓', '✗', or arrows
- **AND** the icons SHALL be loaded from `assets/icons/check.svg` and `assets/icons/cross.svg`

#### Scenario: Consistent Waveform action icon
- **WHEN** the tracks table is displayed
- **THEN** the "Waveform" column (column 7) SHALL render a custom blue SVG "play" icon for the view waveform action
- **AND** SHALL NOT display a generic system arrow or text symbol
- **AND** the icon SHALL be loaded from `assets/icons/play.svg`

#### Scenario: Icon caching for performance
- **WHEN** icons are loaded multiple times
- **THEN** the application SHALL cache loaded icons in memory
- **AND** SHALL NOT reload the same icon from disk repeatedly

#### Scenario: Graceful fallback
- **WHEN** a custom icon file is missing or cannot be loaded
- **THEN** the application SHALL log a warning
- **AND** SHALL fall back to system icons or empty icons
- **AND** SHALL NOT crash or display error dialogs


``n
### README.md

``nVinyl Project Tracklist Extractor

A desktop tool to extract tracklists from PDF cue sheets using a Vision LLM, compare them with mastered WAV durations, and review results in a Fluent-style PyQt GUI.

Quick Start
- Prereqs: Python 3.11 (recommended), Git
- Clone and setup
  - Windows (PowerShell):
    - `py -3.11 -m venv .venv311; .\.venv311\Scripts\Activate.ps1`
  - macOS/Linux:
    - Ensure your default `python` is 3.11, then:
    - `python -m venv .venv && source .venv/bin/activate`
  - Install deps: `
  `

Environment (.env)
- Copy `.env.example` to `.env` and set your API key:
  - `OPENROUTER_API_KEY="YOUR_API_KEY"`
- Optional overrides:
  - `OPENROUTER_MODEL` (default configured in app settings)
  - `OPENAI_API_KEY` / `OPENAI_MODEL` (fallback if you use OpenAI directly)

Run
- GUI (Final Cue Sheet Checker):
  - Windows (PowerShell):
    - `$env:QT_QPA_PLATFORM = "windows"`
    - `.\.venv\Scripts\python.exe .\app.py`
    - Alternatively: `.\.venv\Scripts\python.exe .\app.py -platform windows`
  - macOS/Linux: `python app.py`
  - In the Settings page, set:
    - `PDF input directory`: folder with tracklist PDFs
    - `WAV input directory`: folder with ZIPs containing mastered WAVs
    - `Export directory`: where reports/exports are written
  - After each analysis run, results auto-export to JSON in `export.default_dir` when `export.auto` is true (filename `analysis_YYYYMMDD_HHMMSS.json`). Use the centralized `services.export_service.export_results_to_json()` helper for all exports.
  - WAV batch utility (deprecated): `python wav_extractor_wave.py "C:\path\to\masters"` — use the AnalysisService path with the chained detector instead.
  - Headless/CI runs set `QT_QPA_PLATFORM=offscreen` automatically. To supply fonts in that mode, place `.ttf` files (e.g. DejaVuSans) into the repository `fonts/` directory and they will be loaded on startup.


Dev Commands
- Format: `black .`
- Lint: `ruff check .`
- Types: `mypy .`
- Tests: `pytest -q`

Pre-commit Hook (optional)
Enable repo-provided hook to run format/lint/types before committing:
```
git config core.hooksPath .githooks
```

Notes
- Use Python 3.11 for best compatibility with binary wheels (PyMuPDF, Qt, OpenAI deps). Newer runtimes may require building extra packages.
- The app can call external LLM APIs to parse PDF page images. Ensure you have rights to process the content before enabling extraction.
- `settings.json` and `.env` are ignored by Git; configure them locally.
## Architecture

This project follows a clean, layered architecture to separate concerns and improve testability.

- **`app.py`**: The main application entry point. Responsible for loading configuration, assembling dependencies, and launching the main window.
- **`ui/`**: A dedicated package for all presentation layer components, organized into sub-packages:
  - `ui/main_window.py`: The `MainWindow` class, which orchestrates the UI.
  - `ui/models/`: Contains `QAbstractTableModel` implementations (`ResultsTableModel`, `TracksTableModel`).
  - `ui/workers/`: Handles background processing with `AnalysisWorker` and `AnalysisWorkerManager`.
  - `ui/dialogs/`: Contains UI dialogs like `SettingsDialog`.
  - `ui/constants.py` & `ui/theme.py`: Centralized UI constants and styling helpers.
- **Dependency Injection (DI)**: The UI layer strictly uses constructor injection. Components receive their dependencies (like configuration models or services) upon creation, making them highly testable and decoupled from global state.
- **`services/`**: Contains application services, such as `AnalysisService` (orchestrates analysis) and `export_service.py` (handles JSON exports and is the single source of truth for exports). These services are pure Python and Qt-agnostic.
- **`core/`**: Contains the core domain logic and models of the application (`comparison.py`, `extraction.py`, `models/analysis.py`). This layer is completely independent of any UI or framework.
- **`fluent_gui.py`**: Now serves as a backward-compatibility wrapper to ensure old entry points and imports continue to work. New development should use `app.py` and the `ui/` package directly.
- **`adapters/`**: Contains infrastructure adapters that implement ports defined in `core/ports.py`. Adapters handle external dependencies like file I/O, AI services, and other infrastructure concerns.
- **`core/ports.py`**: Defines protocol interfaces (ports) that abstract external dependencies, enabling clean hexagonal architecture with dependency inversion.

## Refactoring Status

✅ **COMPLETED**: 5-phase strategic refactoring to hexagonal architecture

### Phase 1: Stabilization (✅ Complete)
- Type safety with strict mypy checking
- Comprehensive characterization tests
- Quality tooling (ruff, black, pytest)

### Phase 2: Dependency Injection (✅ Complete)
- Settings dataclasses instead of global config
- Constructor injection throughout the codebase
- No global `cfg` imports in domain or adapter layers

### Phase 3: I/O Modularization (✅ Complete)
- File system adapters for ZIP/WAV reading
- Infrastructure concerns isolated in adapter layer
- Domain layer completely free of I/O operations

### Phase 4: Export Service (✅ Complete)
- Centralized export in `services/export_service.py`
- Single `export_results_to_json()` function for all exports
- UI and automated tests use the same export mechanism

### Phase 5: AI Port (✅ Complete)
- `AudioModeDetector` protocol in `core/ports.py`
- `AiAudioModeDetector` wrapping wav_extractor_wave functions
- `FakeAudioModeDetector` for deterministic tests
- AI dependencies isolated in adapter layer only

## Quality Metrics

- **Test Coverage**: 97% (55 passing tests)
- **Type Safety**: mypy --strict passes
- **Code Quality**: ruff clean, zero dead code
- **Architecture**: Complete hexagonal architecture with zero infrastructure dependencies in domain layer

## Development Workflow

- **Local quality gates**: `tools/check.sh`
- **OpenSpec-driven development**: All changes validated through OpenSpec CLI
- **Git workflow**: Conventional commits with atomic checkpoints
- **Testing**: Fake adapters enable fast, deterministic test execution

``n
### tests\README.md

``n# Waveform Test Suite

## Overview

This directory contains the automated tests for the waveform viewer feature. The suite is organised into the following categories:

- **Unit tests** (`test_waveform_viewer.py`) verify the behaviour of `WaveformViewerDialog`.
- **Unit tests** (`test_waveform_editor.py`) cover `WaveformEditorDialog`, including region selection, snapping, and marker handling.
- **Integration tests** (`test_waveform_integration.py`) exercise the GUI workflow inside `fluent_gui.MainWindow`.
- **Configuration tests** (`test_waveform_config.py`) validate configuration defaults and the settings UI.
- **Shared fixtures** (`conftest.py`) provide reusable helpers for Qt applications, configuration isolation, and sample media assets.

## Running Tests

Execute the entire test suite:

```bash
pytest
```

Run a specific file:

```bash
pytest tests/test_waveform_viewer.py
```

Filter by marker:

```bash
pytest -m unit
```

Generate coverage:

```bash
pytest --cov=. --cov-report=html
```

Enable verbose output:

```bash
pytest -v
```

## Fixtures

- **`qapp`**: Session-scoped `QApplication` instance for Qt tests.
- **`isolated_config`**: Temporary configuration using in-memory QSettings.
- **`mock_wav_zip`**: Creates a ZIP archive containing a valid WAV sine wave for playback tests.
- **`empty_zip`** / **`invalid_wav_zip`**: Provide error-condition archives for robustness scenarios.

## Writing New Tests

- Use pytest-qt's `qtbot` fixture to interact with widgets and simulate user actions.
- Patch Qt signals or multimedia APIs with `unittest.mock` for deterministic behaviour.
- Group related tests inside `Test*` classes and follow the `test_*` naming convention.

## Troubleshooting

- Set `QT_QPA_PLATFORM=offscreen` when running headless (e.g. CI servers).
- Ensure optional dependencies (`pyqtgraph`, `soundfile`, Qt multimedia) are installed for waveform tests.
- If tests hang, verify a single global `QApplication` instance is active.

## Coverage Goals

- Target 80%+ coverage for `waveform_viewer.py`.
- Critical paths to exercise:
  - Both `WaveformViewerDialog` and `WaveformEditorDialog` initialization flows
  - Audio extraction from ZIP archives
  - Waveform rendering and downsampling logic
  - Playback controls (play, pause, stop, seek)
  - Region selection and snapping (editor only)
  - PDF marker visualization (editor only)
  - Volume control interactions
- Error handling for missing or invalid files
- Resource cleanup on dialog close

## Known Issues (Fixed)

The following issues were identified during code review and have been fixed:

1. **Missing `Dict` import**: Added to typing imports in `waveform_viewer.py`.
2. **Duplicate `_temp_wav` definition**: Removed the redundant assignment in `WaveformEditorDialog`.
3. **`_format_time()` inconsistency**: Standardized to use milliseconds in `WaveformViewerDialog` while keeping seconds in the editor.
4. **Position line detection bug**: Replaced the overview line search with a dedicated instance reference.
5. **Unused variables**: Removed unused `time_axis` calculations in detail view updates.
6. **Magic numbers**: Promoted waveform-related constants to named module-level values.

``n

